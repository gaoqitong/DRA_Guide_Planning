{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from graphviz import Source\n",
    "from qnetwork import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from env_sensing_error_small import *\n",
    "# from Plot_Path import *\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from dra_planning import *\n",
    "from full_prod_DRA import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, env, qnet):\n",
    "    \n",
    "    global EXPLORATION_RATE\n",
    "  \n",
    "    summary_ops, summary_vars = build_summaries()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(SUMMARY_DIR, sess.graph)\n",
    "    \n",
    "    qnet.update_target()\n",
    "    \n",
    "    replay_buffer = ReplayBuffer(BUFFER_SIZE, RANDOM_SEED)\n",
    "    \n",
    "    for num_epi in range(MAX_EPISODES):\n",
    "\n",
    "        s = env.reset()\n",
    "        s = [list(np.unravel_index(s, env.shape))]\n",
    "\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "        \n",
    "        reward_list = []\n",
    "\n",
    "        for j in range(MAX_EPISODE_LEN):\n",
    "\n",
    "            a = np.argmax(qnet.predict_q(np.reshape(s, (1, qnet.state_dim))))\n",
    "    \n",
    "            if np.random.rand(1) < EXPLORATION_RATE:\n",
    "                s2, r, terminal, info = env.step(np.random.randint(0,qnet.action_dim))\n",
    "            else:\n",
    "                s2, r, terminal, info = env.step(a)\n",
    "            \n",
    "            s2 = list(np.unravel_index(s2, env.shape))\n",
    "\n",
    "            replay_buffer.add(np.reshape(s, (qnet.state_dim,)), np.reshape(a, (1,)), r,\n",
    "                              terminal, np.reshape(s2, (qnet.state_dim,)))\n",
    "\n",
    "            # Keep adding experience to the memory until\n",
    "            # there are at least minibatch size samples\n",
    "            if replay_buffer.size() > MINIBATCH_SIZE:\n",
    "                s_batch, a_batch, r_batch, t_batch, s2_batch = replay_buffer.sample_batch(MINIBATCH_SIZE)\n",
    "\n",
    "                # Calculate targets\n",
    "                target_q = qnet.predect_target(s2_batch)\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(MINIBATCH_SIZE):\n",
    "                    if t_batch[k]:\n",
    "                        y_i.append(r_batch[k])\n",
    "                    else:\n",
    "                        y_i.append(r_batch[k] + GAMMA * np.amax(target_q[k]))\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                predicted_q_value, _ = qnet.train(s_batch, a_batch, np.reshape(y_i, (MINIBATCH_SIZE, 1)), num_epi)\n",
    "\n",
    "                ep_ave_max_q += np.amax(predicted_q_value)\n",
    "                \n",
    "                # Update target networks\n",
    "                qnet.update_target()\n",
    "\n",
    "            s = s2\n",
    "            ep_reward += r\n",
    "\n",
    "            if terminal or j == MAX_EPISODE_LEN-1:\n",
    "                \n",
    "                if EXPLORATION_RATE > 0.02 and terminal:\n",
    "                    EXPLORATION_RATE = EXPLORATION_RATE*0.98\n",
    "                    \n",
    "                reward_list += [ep_reward]\n",
    "                \n",
    "                if np.average(reward_list[-10:]) > LR_DECAY_TRUNCATION:\n",
    "                    qnet.decay_learning_rate(0.98)\n",
    "\n",
    "                summary_str = sess.run(summary_ops, feed_dict={\n",
    "                    summary_vars[0]: ep_reward,\n",
    "                    summary_vars[1]: ep_ave_max_q / float(j),\n",
    "                    summary_vars[2]: EXPLORATION_RATE,\n",
    "                    summary_vars[3]: qnet.get_learning_rate()                    \n",
    "                })\n",
    "\n",
    "                writer.add_summary(summary_str, num_epi)\n",
    "                writer.flush()\n",
    "\n",
    "                print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f} | Exploration: {:.6f} | Step: {:d} '.format(int(ep_reward), \\\n",
    "                        num_epi, (ep_ave_max_q / float(j)), EXPLORATION_RATE, j))\n",
    "                \n",
    "                f = open(\"stats.txt\", \"ab\")\n",
    "                f.write(\"| Reward: \" + str(int(ep_reward)) \n",
    "                        +\" | Episode: \" + str(num_epi) \n",
    "                        + \" | Qmax: \" + str(ep_ave_max_q / float(j)) \n",
    "                        + \" | Exploration: \" + str(EXPLORATION_RATE) + \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                f = open(SUMMARY_DIR + \"/reward.txt\", \"ab\") \n",
    "                f.write(str(int(ep_reward)))\n",
    "                f.close()\n",
    "                \n",
    "                break\n",
    "                \n",
    "        if num_epi%10 == 0:\n",
    "            state_list = []\n",
    "            action_list = []\n",
    "            world = np.zeros(env.shape)\n",
    "            for state in range(env.nS):\n",
    "                state = np.unravel_index(state, env.shape)\n",
    "                action = qnet.predict_q(np.reshape(state, (1,state_dim)))\n",
    "                action = np.argmax(action)\n",
    "                state_list.append(state)\n",
    "                action_list.append(action)\n",
    "                \n",
    "#             print np.reshape(action_list, env.shape)\n",
    "                \n",
    "            f = open(\"action.txt\",\"ab\")\n",
    "            act_string = np.array_str(np.reshape(action_list, env.shape))\n",
    "            f.write(act_string)\n",
    "            f.write(\"---------------------------\\n\")\n",
    "            f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0015\n",
    "GAMMA = 0.99\n",
    "# GAMMA = 0.7\n",
    "TAU = 0.001\n",
    "BUFFER_SIZE = 10**6\n",
    "MINIBATCH_SIZE = 64\n",
    "RANDOM_SEED = 210\n",
    "MAX_EPISODES = 50000\n",
    "MAX_EPISODE_LEN = 200\n",
    "file_appendix = time.ctime()[4:16].replace(\"  \",\"\").replace(\" \",\"_\").replace(\":\",\"-\")\n",
    "SUMMARY_DIR = './results/tf_ddqn_' + file_appendix\n",
    "SAVE_DIR = \"./saved_model/\" + file_appendix + \"/ddqn.ckpt\"\n",
    "EXPLORATION_RATE = 0.7\n",
    "LR_DECAY_TRUNCATION = -200\n",
    "RESTORE = 0\n",
    "if sys.platform == \"darwin\":\n",
    "    DEVICE = \"/device:CPU:0\"\n",
    "else:\n",
    "    DEVICE = \"/device:GPU:0\"\n",
    "\n",
    "# LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B\"\n",
    "# LTL = \"[] (p1 -> !(X p1) U (p2 || p3) ) && []<>p1\"\n",
    "# LTL = \"T && []<>A && []<>B\"\n",
    "# LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B && []!C && []!D\"\n",
    "# LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B && []!C\"\n",
    "# LTL = \"<>(A && <>(B && <> T))\"\n",
    "# LTL = \"<>(A && <>B) && <>[]T && []!C\"\n",
    "LTL = \"<>(A && <>T) && []!C\"\n",
    "# LTL = \"<>(A && <>(B && <>T)) && []<>(A||T) && []<>B && []!C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: DRA Pages: 1 -->\n",
       "<svg width=\"676pt\" height=\"133pt\"\n",
       " viewBox=\"0.00 0.00 676.25 133.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 129)\">\n",
       "<title>DRA</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-129 672.247,-129 672.247,4 -4,4\"/>\n",
       "<!-- type -->\n",
       "<g id=\"node1\" class=\"node\"><title>type</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-107\" rx=\"29.4969\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">DRA</text>\n",
       "</g>\n",
       "<!-- comment -->\n",
       "<g id=\"node2\" class=\"node\"><title>comment</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"176.247,-125 76.2474,-125 76.2474,-89 176.247,-89 176.247,-125\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.247\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Safra[NBA=2]</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node3\" class=\"node\"><title>0</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"212.247\" cy=\"-107\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.247\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.4,-108.447C239.786,-108.67 248.247,-108.188 248.247,-107 248.247,-106.276 245.106,-105.815 240.527,-105.615\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"240.421,-102.114 230.4,-105.553 240.379,-109.114 240.421,-102.114\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.747\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> !A&amp;!C&amp;!T</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.467,-108.997C260.06,-110.822 309.247,-110.156 309.247,-107 309.247,-104.189 270.232,-103.353 240.79,-104.493\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"240.282,-101.014 230.467,-105.003 240.627,-108.006 240.282,-101.014\"/>\n",
       "<text text-anchor=\"middle\" x=\"337.747\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> A&amp;!C&amp;!T</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.361,-109.373C273.699,-112.854 366.247,-112.062 366.247,-107 366.247,-102.303 286.591,-101.283 240.474,-103.939\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"240.1,-100.457 230.361,-104.627 240.575,-107.44 240.1,-100.457\"/>\n",
       "<text text-anchor=\"middle\" x=\"394.747\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> !A&amp;C&amp;!T</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.295,-109.66C285.287,-114.871 423.247,-113.984 423.247,-107 423.247,-100.411 300.473,-99.2489 240.398,-103.513\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"239.976,-100.036 230.295,-104.34 240.547,-107.013 239.976,-100.036\"/>\n",
       "<text text-anchor=\"middle\" x=\"449.747\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> A&amp;C&amp;!T</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.401,-109.922C295.395,-116.88 476.247,-115.906 476.247,-107 476.247,-98.5286 312.625,-97.2337 240.716,-103.115\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"240.033,-99.6636 230.401,-104.078 240.683,-106.633 240.033,-99.6636\"/>\n",
       "<text text-anchor=\"middle\" x=\"502.747\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> !A&amp;C&amp;T</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.263,-110.116C304.365,-118.89 529.247,-117.852 529.247,-107 529.247,-96.6041 322.855,-95.2144 240.368,-102.831\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"239.846,-99.3663 230.263,-103.884 240.572,-106.329 239.846,-99.3663\"/>\n",
       "<text text-anchor=\"middle\" x=\"553.747\" y=\"-103.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> A&amp;C&amp;T</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node4\" class=\"node\"><title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"239.247,-38 185.247,-38 185.247,-0 239.247,-0 239.247,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.247\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1</text>\n",
       "<text text-anchor=\"middle\" x=\"212.247\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> +0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.927,-96.9868C183.183,-87.6329 166.183,-72.1355 173.247,-56 174.864,-52.3071 177.068,-48.825 179.61,-45.5895\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.317,-47.8157 186.485,-38.0753 177.152,-43.0902 182.317,-47.8157\"/>\n",
       "<text text-anchor=\"middle\" x=\"201.747\" y=\"-59.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> !A&amp;!C&amp;T</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221.79,-91.2832C225.164,-85.2501 228.543,-78.0395 230.247,-71 232.121,-63.2587 230.777,-55.0479 228.141,-47.5288\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231.267,-45.9384 224.095,-38.1403 224.839,-48.709 231.267,-45.9384\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.747\" y=\"-59.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> A&amp;!C&amp;T</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;1 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>1&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M239.488,-27.2419C249.271,-27.4192 257.247,-24.6719 257.247,-19 257.247,-15.5437 254.286,-13.1734 249.758,-11.8891\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"249.811,-8.3739 239.488,-10.7581 249.045,-15.3318 249.811,-8.3739\"/>\n",
       "<text text-anchor=\"middle\" x=\"271.247\" y=\"-15.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> true</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fd554ec6350>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CurrentWorld(LTL)\n",
    "with open(\"my.dot\", \"r\") as dotfile:\n",
    "    text = dotfile.read()\n",
    "Source(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDQN Saved\n",
      "| Reward: -2500 | Episode: 0 | Qmax: 1.4805 | Exploration: 0.686000 | Step: 116 \n",
      "| Reward: -2540 | Episode: 1 | Qmax: 6.8732 | Exploration: 0.686000 | Step: 199 \n",
      "| Reward: -2720 | Episode: 2 | Qmax: 0.0476 | Exploration: 0.686000 | Step: 199 \n",
      "| Reward: -2810 | Episode: 3 | Qmax: 1.5818 | Exploration: 0.686000 | Step: 199 \n",
      "| Reward: -2720 | Episode: 4 | Qmax: -1.0546 | Exploration: 0.686000 | Step: 199 \n",
      "| Reward: -2900 | Episode: 5 | Qmax: -2.2787 | Exploration: 0.686000 | Step: 199 \n",
      "| Reward: -3440 | Episode: 6 | Qmax: -5.4519 | Exploration: 0.686000 | Step: 199 \n",
      "| Reward: -2450 | Episode: 7 | Qmax: -7.4676 | Exploration: 0.686000 | Step: 199 \n",
      "| Reward: -1480 | Episode: 8 | Qmax: -9.7153 | Exploration: 0.672280 | Step: 122 \n",
      "| Reward: -2630 | Episode: 9 | Qmax: -11.1628 | Exploration: 0.672280 | Step: 199 \n",
      "| Reward: -2090 | Episode: 10 | Qmax: -11.8967 | Exploration: 0.658834 | Step: 174 \n",
      "| Reward: -2180 | Episode: 11 | Qmax: -8.7525 | Exploration: 0.658834 | Step: 199 \n",
      "| Reward: -2000 | Episode: 12 | Qmax: -6.0356 | Exploration: 0.658834 | Step: 199 \n",
      "| Reward: -2720 | Episode: 13 | Qmax: -6.9609 | Exploration: 0.658834 | Step: 199 \n",
      "| Reward: -2990 | Episode: 14 | Qmax: -2.8177 | Exploration: 0.658834 | Step: 199 \n",
      "| Reward: -3260 | Episode: 15 | Qmax: -3.1391 | Exploration: 0.658834 | Step: 199 \n",
      "| Reward: -2620 | Episode: 16 | Qmax: -7.6774 | Exploration: 0.645658 | Step: 182 \n",
      "| Reward: -2360 | Episode: 17 | Qmax: -13.2835 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -3080 | Episode: 18 | Qmax: -14.8084 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2900 | Episode: 19 | Qmax: -19.5315 | Exploration: 0.645658 | Step: 199 \n",
      "DDQN Saved\n",
      "| Reward: -3350 | Episode: 20 | Qmax: -19.6296 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2540 | Episode: 21 | Qmax: -20.4667 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2720 | Episode: 22 | Qmax: -23.8384 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2900 | Episode: 23 | Qmax: -22.1721 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2810 | Episode: 24 | Qmax: -22.4163 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2630 | Episode: 25 | Qmax: -27.8218 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2450 | Episode: 26 | Qmax: -28.5795 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2720 | Episode: 27 | Qmax: -30.9862 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2720 | Episode: 28 | Qmax: -32.8501 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2810 | Episode: 29 | Qmax: -37.2828 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2450 | Episode: 30 | Qmax: -34.4136 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2630 | Episode: 31 | Qmax: -36.0537 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2450 | Episode: 32 | Qmax: -39.5974 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2720 | Episode: 33 | Qmax: -36.3299 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -3260 | Episode: 34 | Qmax: -44.6530 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2810 | Episode: 35 | Qmax: -44.0843 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2270 | Episode: 36 | Qmax: -45.9144 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2810 | Episode: 37 | Qmax: -49.3177 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -3530 | Episode: 38 | Qmax: -51.4887 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2540 | Episode: 39 | Qmax: -54.3432 | Exploration: 0.645658 | Step: 199 \n",
      "DDQN Saved\n",
      "| Reward: -2720 | Episode: 40 | Qmax: -53.7436 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2180 | Episode: 41 | Qmax: -53.2701 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2270 | Episode: 42 | Qmax: -56.3577 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2360 | Episode: 43 | Qmax: -61.6713 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2270 | Episode: 44 | Qmax: -60.6735 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2360 | Episode: 45 | Qmax: -60.5082 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -3080 | Episode: 46 | Qmax: -65.4889 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2810 | Episode: 47 | Qmax: -67.8145 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2090 | Episode: 48 | Qmax: -68.2495 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2450 | Episode: 49 | Qmax: -68.1511 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -3260 | Episode: 50 | Qmax: -71.5442 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -3080 | Episode: 51 | Qmax: -75.6645 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2540 | Episode: 52 | Qmax: -78.3045 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2450 | Episode: 53 | Qmax: -74.8143 | Exploration: 0.645658 | Step: 199 \n",
      "| Reward: -2300 | Episode: 54 | Qmax: -75.6697 | Exploration: 0.632745 | Step: 195 \n",
      "| Reward: -600 | Episode: 55 | Qmax: -76.4428 | Exploration: 0.620090 | Step: 70 \n",
      "| Reward: -3170 | Episode: 56 | Qmax: -70.0761 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2450 | Episode: 57 | Qmax: -72.7897 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2450 | Episode: 58 | Qmax: -75.9772 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2900 | Episode: 59 | Qmax: -79.6416 | Exploration: 0.620090 | Step: 199 \n",
      "DDQN Saved\n",
      "| Reward: -2630 | Episode: 60 | Qmax: -77.6841 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2540 | Episode: 61 | Qmax: -83.5754 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2540 | Episode: 62 | Qmax: -86.9464 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2270 | Episode: 63 | Qmax: -82.0342 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2090 | Episode: 64 | Qmax: -88.7584 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2270 | Episode: 65 | Qmax: -83.7855 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -2540 | Episode: 66 | Qmax: -85.6061 | Exploration: 0.620090 | Step: 199 \n",
      "| Reward: -870 | Episode: 67 | Qmax: -90.7916 | Exploration: 0.607688 | Step: 61 \n",
      "| Reward: -2720 | Episode: 68 | Qmax: -86.1549 | Exploration: 0.607688 | Step: 199 \n",
      "| Reward: -2360 | Episode: 69 | Qmax: -87.6025 | Exploration: 0.607688 | Step: 199 \n",
      "| Reward: -2540 | Episode: 70 | Qmax: -90.2527 | Exploration: 0.607688 | Step: 199 \n",
      "| Reward: -2000 | Episode: 71 | Qmax: -96.4075 | Exploration: 0.607688 | Step: 199 \n",
      "| Reward: -2810 | Episode: 72 | Qmax: -98.2003 | Exploration: 0.607688 | Step: 199 \n",
      "| Reward: -2450 | Episode: 73 | Qmax: -100.6687 | Exploration: 0.607688 | Step: 199 \n",
      "| Reward: -2540 | Episode: 74 | Qmax: -100.5550 | Exploration: 0.607688 | Step: 199 \n",
      "| Reward: -2270 | Episode: 75 | Qmax: -103.8205 | Exploration: 0.607688 | Step: 199 \n",
      "| Reward: -600 | Episode: 76 | Qmax: -97.7251 | Exploration: 0.595534 | Step: 70 \n",
      "| Reward: -2180 | Episode: 77 | Qmax: -97.8964 | Exploration: 0.595534 | Step: 199 \n",
      "| Reward: -2450 | Episode: 78 | Qmax: -94.8673 | Exploration: 0.595534 | Step: 199 \n",
      "| Reward: -440 | Episode: 79 | Qmax: -104.8412 | Exploration: 0.583623 | Step: 36 \n",
      "DDQN Saved\n",
      "| Reward: -2450 | Episode: 80 | Qmax: -98.6130 | Exploration: 0.583623 | Step: 199 \n",
      "| Reward: -1980 | Episode: 81 | Qmax: -102.3548 | Exploration: 0.571951 | Step: 199 \n",
      "| Reward: -2540 | Episode: 82 | Qmax: -95.1817 | Exploration: 0.571951 | Step: 199 \n",
      "| Reward: -2810 | Episode: 83 | Qmax: -97.3540 | Exploration: 0.571951 | Step: 199 \n",
      "| Reward: -2270 | Episode: 84 | Qmax: -99.4753 | Exploration: 0.571951 | Step: 199 \n",
      "| Reward: -2270 | Episode: 85 | Qmax: -99.2354 | Exploration: 0.571951 | Step: 199 \n",
      "| Reward: -2090 | Episode: 86 | Qmax: -92.6014 | Exploration: 0.571951 | Step: 199 \n",
      "| Reward: -2630 | Episode: 87 | Qmax: -103.8504 | Exploration: 0.571951 | Step: 199 \n",
      "| Reward: -2630 | Episode: 88 | Qmax: -111.8595 | Exploration: 0.571951 | Step: 199 \n",
      "| Reward: -1850 | Episode: 89 | Qmax: -108.9122 | Exploration: 0.560512 | Step: 177 \n",
      "| Reward: -2000 | Episode: 90 | Qmax: -100.6188 | Exploration: 0.560512 | Step: 199 \n",
      "| Reward: -2000 | Episode: 91 | Qmax: -105.2885 | Exploration: 0.560512 | Step: 199 \n",
      "| Reward: -2270 | Episode: 92 | Qmax: -108.5627 | Exploration: 0.560512 | Step: 199 \n",
      "| Reward: -2450 | Episode: 93 | Qmax: -114.8387 | Exploration: 0.560512 | Step: 199 \n",
      "| Reward: -1690 | Episode: 94 | Qmax: -100.2167 | Exploration: 0.549302 | Step: 143 \n",
      "| Reward: -580 | Episode: 95 | Qmax: -89.6915 | Exploration: 0.538316 | Step: 50 \n",
      "| Reward: -2540 | Episode: 96 | Qmax: -105.7083 | Exploration: 0.538316 | Step: 199 \n",
      "| Reward: -2180 | Episode: 97 | Qmax: -108.9612 | Exploration: 0.538316 | Step: 199 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2230 | Episode: 98 | Qmax: -105.6024 | Exploration: 0.527549 | Step: 179 \n",
      "| Reward: -410 | Episode: 99 | Qmax: -120.7500 | Exploration: 0.516998 | Step: 33 \n",
      "DDQN Saved\n",
      "| Reward: -1280 | Episode: 100 | Qmax: -105.2850 | Exploration: 0.506658 | Step: 138 \n",
      "| Reward: -2180 | Episode: 101 | Qmax: -102.3807 | Exploration: 0.506658 | Step: 199 \n",
      "| Reward: -2090 | Episode: 102 | Qmax: -108.9529 | Exploration: 0.506658 | Step: 199 \n",
      "| Reward: -2450 | Episode: 103 | Qmax: -105.7498 | Exploration: 0.506658 | Step: 199 \n",
      "| Reward: -1470 | Episode: 104 | Qmax: -100.8588 | Exploration: 0.496525 | Step: 121 \n",
      "| Reward: -2450 | Episode: 105 | Qmax: -102.4370 | Exploration: 0.496525 | Step: 199 \n",
      "| Reward: -2360 | Episode: 106 | Qmax: -111.0719 | Exploration: 0.496525 | Step: 199 \n",
      "| Reward: -2360 | Episode: 107 | Qmax: -109.0323 | Exploration: 0.496525 | Step: 199 \n",
      "| Reward: -1370 | Episode: 108 | Qmax: -110.7263 | Exploration: 0.486595 | Step: 147 \n",
      "| Reward: -1030 | Episode: 109 | Qmax: -112.8855 | Exploration: 0.476863 | Step: 86 \n",
      "| Reward: -1430 | Episode: 110 | Qmax: -99.6123 | Exploration: 0.467326 | Step: 153 \n",
      "| Reward: -2180 | Episode: 111 | Qmax: -103.3246 | Exploration: 0.467326 | Step: 199 \n",
      "| Reward: -2090 | Episode: 112 | Qmax: -103.5516 | Exploration: 0.467326 | Step: 199 \n",
      "| Reward: -360 | Episode: 113 | Qmax: -58.5900 | Exploration: 0.457979 | Step: 37 \n",
      "| Reward: -370 | Episode: 114 | Qmax: -83.2546 | Exploration: 0.448819 | Step: 47 \n",
      "| Reward: -880 | Episode: 115 | Qmax: -103.5314 | Exploration: 0.439843 | Step: 80 \n",
      "| Reward: -2000 | Episode: 116 | Qmax: -96.4215 | Exploration: 0.439843 | Step: 199 \n",
      "| Reward: -2000 | Episode: 117 | Qmax: -108.6068 | Exploration: 0.439843 | Step: 199 \n",
      "| Reward: -2270 | Episode: 118 | Qmax: -101.1263 | Exploration: 0.439843 | Step: 199 \n",
      "| Reward: -2720 | Episode: 119 | Qmax: -97.2455 | Exploration: 0.439843 | Step: 199 \n",
      "DDQN Saved\n",
      "| Reward: -2090 | Episode: 120 | Qmax: -91.7649 | Exploration: 0.439843 | Step: 199 \n",
      "| Reward: -930 | Episode: 121 | Qmax: -85.7703 | Exploration: 0.431046 | Step: 94 \n",
      "| Reward: -2090 | Episode: 122 | Qmax: -106.8123 | Exploration: 0.431046 | Step: 199 \n",
      "| Reward: -2090 | Episode: 123 | Qmax: -93.6365 | Exploration: 0.431046 | Step: 199 \n",
      "| Reward: -2000 | Episode: 124 | Qmax: -114.2266 | Exploration: 0.431046 | Step: 199 \n",
      "| Reward: -2180 | Episode: 125 | Qmax: -98.3058 | Exploration: 0.431046 | Step: 199 \n",
      "| Reward: -2000 | Episode: 126 | Qmax: -97.1426 | Exploration: 0.431046 | Step: 199 \n",
      "| Reward: -690 | Episode: 127 | Qmax: -106.9812 | Exploration: 0.422425 | Step: 61 \n",
      "| Reward: -2450 | Episode: 128 | Qmax: -106.4372 | Exploration: 0.422425 | Step: 199 \n",
      "| Reward: -740 | Episode: 129 | Qmax: -109.6370 | Exploration: 0.413977 | Step: 75 \n",
      "| Reward: -1770 | Episode: 130 | Qmax: -105.1365 | Exploration: 0.405697 | Step: 142 \n",
      "| Reward: -2000 | Episode: 131 | Qmax: -108.3427 | Exploration: 0.405697 | Step: 199 \n",
      "| Reward: -2000 | Episode: 132 | Qmax: -106.4479 | Exploration: 0.405697 | Step: 199 \n",
      "| Reward: -680 | Episode: 133 | Qmax: -100.6962 | Exploration: 0.397583 | Step: 60 \n",
      "| Reward: -780 | Episode: 134 | Qmax: -115.7047 | Exploration: 0.389632 | Step: 88 \n",
      "| Reward: -1950 | Episode: 135 | Qmax: -95.0017 | Exploration: 0.381839 | Step: 187 \n",
      "| Reward: -1020 | Episode: 136 | Qmax: -110.7873 | Exploration: 0.374202 | Step: 103 \n",
      "| Reward: -1630 | Episode: 137 | Qmax: -100.9370 | Exploration: 0.366718 | Step: 164 \n",
      "| Reward: -1110 | Episode: 138 | Qmax: -106.8281 | Exploration: 0.359384 | Step: 94 \n",
      "| Reward: -960 | Episode: 139 | Qmax: -87.9009 | Exploration: 0.352196 | Step: 106 \n",
      "DDQN Saved\n",
      "| Reward: -510 | Episode: 140 | Qmax: -85.3752 | Exploration: 0.345152 | Step: 61 \n",
      "| Reward: -1150 | Episode: 141 | Qmax: -90.7608 | Exploration: 0.338249 | Step: 107 \n",
      "| Reward: -1250 | Episode: 142 | Qmax: -100.2691 | Exploration: 0.331484 | Step: 117 \n",
      "| Reward: -2000 | Episode: 143 | Qmax: -86.2435 | Exploration: 0.331484 | Step: 199 \n",
      "| Reward: -240 | Episode: 144 | Qmax: -72.6048 | Exploration: 0.324855 | Step: 25 \n",
      "| Reward: -1040 | Episode: 145 | Qmax: -79.8094 | Exploration: 0.318357 | Step: 105 \n",
      "| Reward: -2000 | Episode: 146 | Qmax: -67.0697 | Exploration: 0.318357 | Step: 199 \n",
      "| Reward: -730 | Episode: 147 | Qmax: -83.3871 | Exploration: 0.311990 | Step: 74 \n",
      "| Reward: -1140 | Episode: 148 | Qmax: -85.3037 | Exploration: 0.305750 | Step: 106 \n",
      "| Reward: -2270 | Episode: 149 | Qmax: -66.7683 | Exploration: 0.305750 | Step: 199 \n",
      "| Reward: -820 | Episode: 150 | Qmax: -96.7909 | Exploration: 0.299635 | Step: 92 \n",
      "| Reward: -550 | Episode: 151 | Qmax: -79.1510 | Exploration: 0.293643 | Step: 65 \n",
      "| Reward: -470 | Episode: 152 | Qmax: -82.1441 | Exploration: 0.287770 | Step: 39 \n",
      "| Reward: -2180 | Episode: 153 | Qmax: -73.6487 | Exploration: 0.287770 | Step: 199 \n",
      "| Reward: -2000 | Episode: 154 | Qmax: -85.1992 | Exploration: 0.287770 | Step: 199 \n",
      "| Reward: -240 | Episode: 155 | Qmax: -89.1801 | Exploration: 0.282015 | Step: 25 \n",
      "| Reward: -2000 | Episode: 156 | Qmax: -80.2363 | Exploration: 0.282015 | Step: 199 \n",
      "| Reward: -2090 | Episode: 157 | Qmax: -79.1004 | Exploration: 0.282015 | Step: 199 \n",
      "| Reward: -2180 | Episode: 158 | Qmax: -76.7948 | Exploration: 0.282015 | Step: 199 \n",
      "| Reward: -2000 | Episode: 159 | Qmax: -77.6585 | Exploration: 0.282015 | Step: 199 \n",
      "DDQN Saved\n",
      "| Reward: -2180 | Episode: 160 | Qmax: -59.5798 | Exploration: 0.282015 | Step: 199 \n",
      "| Reward: -840 | Episode: 161 | Qmax: -86.0546 | Exploration: 0.276374 | Step: 94 \n",
      "| Reward: -430 | Episode: 162 | Qmax: -86.1736 | Exploration: 0.270847 | Step: 44 \n",
      "| Reward: -1140 | Episode: 163 | Qmax: -67.0615 | Exploration: 0.265430 | Step: 124 \n",
      "| Reward: -2090 | Episode: 164 | Qmax: -78.9126 | Exploration: 0.265430 | Step: 199 \n",
      "| Reward: -900 | Episode: 165 | Qmax: -84.1578 | Exploration: 0.260121 | Step: 82 \n",
      "| Reward: -1000 | Episode: 166 | Qmax: -70.0800 | Exploration: 0.254919 | Step: 101 \n",
      "| Reward: -710 | Episode: 167 | Qmax: -53.8355 | Exploration: 0.249820 | Step: 81 \n",
      "| Reward: -1020 | Episode: 168 | Qmax: -62.0009 | Exploration: 0.244824 | Step: 103 \n",
      "| Reward: -1700 | Episode: 169 | Qmax: -65.8235 | Exploration: 0.239928 | Step: 180 \n",
      "| Reward: -2000 | Episode: 170 | Qmax: -57.9943 | Exploration: 0.239928 | Step: 199 \n",
      "| Reward: -1940 | Episode: 171 | Qmax: -75.9532 | Exploration: 0.235129 | Step: 195 \n",
      "| Reward: -1290 | Episode: 172 | Qmax: -71.6196 | Exploration: 0.230426 | Step: 139 \n",
      "| Reward: -770 | Episode: 173 | Qmax: -52.4315 | Exploration: 0.225818 | Step: 78 \n",
      "| Reward: -1270 | Episode: 174 | Qmax: -66.8797 | Exploration: 0.221301 | Step: 137 \n",
      "| Reward: -890 | Episode: 175 | Qmax: -83.2361 | Exploration: 0.216875 | Step: 90 \n",
      "| Reward: -620 | Episode: 176 | Qmax: -65.8953 | Exploration: 0.212538 | Step: 72 \n",
      "| Reward: -2000 | Episode: 177 | Qmax: -60.3435 | Exploration: 0.212538 | Step: 199 \n",
      "| Reward: -1070 | Episode: 178 | Qmax: -53.0663 | Exploration: 0.208287 | Step: 108 \n",
      "| Reward: -1810 | Episode: 179 | Qmax: -46.0020 | Exploration: 0.204121 | Step: 191 \n",
      "DDQN Saved\n",
      "| Reward: -1380 | Episode: 180 | Qmax: -55.1714 | Exploration: 0.200039 | Step: 148 \n",
      "| Reward: -1450 | Episode: 181 | Qmax: -51.6432 | Exploration: 0.196038 | Step: 155 \n",
      "| Reward: -2000 | Episode: 182 | Qmax: -48.6840 | Exploration: 0.196038 | Step: 199 \n",
      "| Reward: -2000 | Episode: 183 | Qmax: -66.7387 | Exploration: 0.196038 | Step: 199 \n",
      "| Reward: -2000 | Episode: 184 | Qmax: -55.7295 | Exploration: 0.196038 | Step: 199 \n",
      "| Reward: -200 | Episode: 185 | Qmax: -45.7611 | Exploration: 0.192117 | Step: 30 \n",
      "| Reward: -2000 | Episode: 186 | Qmax: -62.4937 | Exploration: 0.192117 | Step: 199 \n",
      "| Reward: -2000 | Episode: 187 | Qmax: -60.4628 | Exploration: 0.192117 | Step: 199 \n",
      "| Reward: -910 | Episode: 188 | Qmax: -44.1868 | Exploration: 0.188275 | Step: 92 \n",
      "| Reward: -2000 | Episode: 189 | Qmax: -50.7685 | Exploration: 0.188275 | Step: 199 \n",
      "| Reward: -2000 | Episode: 190 | Qmax: -51.9143 | Exploration: 0.188275 | Step: 199 \n",
      "| Reward: -2000 | Episode: 191 | Qmax: -57.0625 | Exploration: 0.188275 | Step: 199 \n",
      "| Reward: -2000 | Episode: 192 | Qmax: -56.4360 | Exploration: 0.188275 | Step: 199 \n",
      "| Reward: -620 | Episode: 193 | Qmax: -39.8109 | Exploration: 0.184510 | Step: 63 \n",
      "| Reward: -2180 | Episode: 194 | Qmax: -58.6372 | Exploration: 0.184510 | Step: 199 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1720 | Episode: 195 | Qmax: -64.6000 | Exploration: 0.180819 | Step: 182 \n",
      "| Reward: -1640 | Episode: 196 | Qmax: -47.1878 | Exploration: 0.177203 | Step: 165 \n",
      "| Reward: -580 | Episode: 197 | Qmax: -40.1250 | Exploration: 0.173659 | Step: 68 \n",
      "| Reward: -620 | Episode: 198 | Qmax: -57.8943 | Exploration: 0.170186 | Step: 72 \n",
      "| Reward: -1940 | Episode: 199 | Qmax: -48.8633 | Exploration: 0.166782 | Step: 186 \n",
      "DDQN Saved\n",
      "| Reward: -1590 | Episode: 200 | Qmax: -50.6141 | Exploration: 0.163446 | Step: 160 \n",
      "| Reward: -1690 | Episode: 201 | Qmax: -44.1320 | Exploration: 0.160178 | Step: 179 \n",
      "| Reward: -380 | Episode: 202 | Qmax: -63.5126 | Exploration: 0.156974 | Step: 39 \n",
      "| Reward: -770 | Episode: 203 | Qmax: -23.5800 | Exploration: 0.153834 | Step: 69 \n",
      "| Reward: -2000 | Episode: 204 | Qmax: -49.1378 | Exploration: 0.153834 | Step: 199 \n",
      "| Reward: -2000 | Episode: 205 | Qmax: -55.9180 | Exploration: 0.153834 | Step: 199 \n",
      "| Reward: -100 | Episode: 206 | Qmax: -50.8581 | Exploration: 0.150758 | Step: 11 \n",
      "| Reward: -610 | Episode: 207 | Qmax: -36.4552 | Exploration: 0.147743 | Step: 71 \n",
      "| Reward: -390 | Episode: 208 | Qmax: -44.4470 | Exploration: 0.144788 | Step: 40 \n",
      "| Reward: -750 | Episode: 209 | Qmax: -43.1486 | Exploration: 0.141892 | Step: 76 \n",
      "| Reward: -120 | Episode: 210 | Qmax: -47.6857 | Exploration: 0.139054 | Step: 13 \n",
      "| Reward: -240 | Episode: 211 | Qmax: -1.5635 | Exploration: 0.136273 | Step: 25 \n",
      "| Reward: -2000 | Episode: 212 | Qmax: -47.2692 | Exploration: 0.136273 | Step: 199 \n",
      "| Reward: -1190 | Episode: 213 | Qmax: -63.4522 | Exploration: 0.133548 | Step: 120 \n",
      "| Reward: -630 | Episode: 214 | Qmax: -43.0627 | Exploration: 0.130877 | Step: 64 \n",
      "| Reward: -540 | Episode: 215 | Qmax: -36.7025 | Exploration: 0.128259 | Step: 46 \n",
      "| Reward: -2000 | Episode: 216 | Qmax: -31.2703 | Exploration: 0.128259 | Step: 199 \n",
      "| Reward: -240 | Episode: 217 | Qmax: -37.0838 | Exploration: 0.125694 | Step: 25 \n",
      "| Reward: -400 | Episode: 218 | Qmax: -43.3744 | Exploration: 0.123180 | Step: 41 \n",
      "| Reward: -1180 | Episode: 219 | Qmax: -50.4566 | Exploration: 0.120716 | Step: 119 \n",
      "DDQN Saved\n",
      "| Reward: -1770 | Episode: 220 | Qmax: -55.3651 | Exploration: 0.118302 | Step: 178 \n",
      "| Reward: -2000 | Episode: 221 | Qmax: -49.4520 | Exploration: 0.118302 | Step: 199 \n",
      "| Reward: -2000 | Episode: 222 | Qmax: -23.3001 | Exploration: 0.118302 | Step: 199 \n",
      "| Reward: -460 | Episode: 223 | Qmax: -36.8703 | Exploration: 0.115936 | Step: 47 \n",
      "| Reward: -400 | Episode: 224 | Qmax: -46.9558 | Exploration: 0.113617 | Step: 41 \n",
      "| Reward: -1350 | Episode: 225 | Qmax: -37.7153 | Exploration: 0.111345 | Step: 136 \n",
      "| Reward: -590 | Episode: 226 | Qmax: -25.2852 | Exploration: 0.109118 | Step: 60 \n",
      "| Reward: -1830 | Episode: 227 | Qmax: -47.6989 | Exploration: 0.106936 | Step: 184 \n",
      "| Reward: -370 | Episode: 228 | Qmax: -49.3326 | Exploration: 0.104797 | Step: 38 \n",
      "| Reward: -1430 | Episode: 229 | Qmax: -24.7698 | Exploration: 0.102701 | Step: 144 \n",
      "| Reward: -450 | Episode: 230 | Qmax: -42.1008 | Exploration: 0.100647 | Step: 46 \n",
      "| Reward: -880 | Episode: 231 | Qmax: -32.0232 | Exploration: 0.098634 | Step: 89 \n",
      "| Reward: -490 | Episode: 232 | Qmax: -45.6600 | Exploration: 0.096661 | Step: 50 \n",
      "| Reward: -1180 | Episode: 233 | Qmax: -15.2662 | Exploration: 0.094728 | Step: 119 \n",
      "| Reward: -260 | Episode: 234 | Qmax: -6.8944 | Exploration: 0.092834 | Step: 27 \n",
      "| Reward: -340 | Episode: 235 | Qmax: -13.0013 | Exploration: 0.090977 | Step: 35 \n",
      "| Reward: -2000 | Episode: 236 | Qmax: -29.3431 | Exploration: 0.090977 | Step: 199 \n",
      "| Reward: -500 | Episode: 237 | Qmax: -18.4939 | Exploration: 0.089157 | Step: 51 \n",
      "| Reward: -310 | Episode: 238 | Qmax: -26.6979 | Exploration: 0.087374 | Step: 32 \n",
      "| Reward: -400 | Episode: 239 | Qmax: -53.0250 | Exploration: 0.085627 | Step: 41 \n",
      "DDQN Saved\n",
      "| Reward: -370 | Episode: 240 | Qmax: -40.5224 | Exploration: 0.083914 | Step: 38 \n",
      "| Reward: -260 | Episode: 241 | Qmax: -49.7923 | Exploration: 0.082236 | Step: 27 \n",
      "| Reward: -650 | Episode: 242 | Qmax: -36.5124 | Exploration: 0.080591 | Step: 66 \n",
      "| Reward: -270 | Episode: 243 | Qmax: -17.3310 | Exploration: 0.078979 | Step: 28 \n",
      "| Reward: -420 | Episode: 244 | Qmax: -15.8918 | Exploration: 0.077400 | Step: 43 \n",
      "| Reward: -770 | Episode: 245 | Qmax: -7.2096 | Exploration: 0.075852 | Step: 78 \n",
      "| Reward: -540 | Episode: 246 | Qmax: -30.3056 | Exploration: 0.074335 | Step: 55 \n",
      "| Reward: -1540 | Episode: 247 | Qmax: -39.4406 | Exploration: 0.072848 | Step: 155 \n",
      "| Reward: -250 | Episode: 248 | Qmax: -37.4279 | Exploration: 0.071391 | Step: 26 \n",
      "| Reward: -170 | Episode: 249 | Qmax: 0.5994 | Exploration: 0.069963 | Step: 9 \n",
      "| Reward: -180 | Episode: 250 | Qmax: 14.3929 | Exploration: 0.068564 | Step: 19 \n",
      "| Reward: -990 | Episode: 251 | Qmax: -19.5908 | Exploration: 0.067193 | Step: 100 \n",
      "| Reward: -270 | Episode: 252 | Qmax: 10.0212 | Exploration: 0.065849 | Step: 28 \n",
      "| Reward: -890 | Episode: 253 | Qmax: -11.5357 | Exploration: 0.064532 | Step: 90 \n",
      "| Reward: -190 | Episode: 254 | Qmax: -33.4944 | Exploration: 0.063241 | Step: 20 \n",
      "| Reward: -260 | Episode: 255 | Qmax: 1.9715 | Exploration: 0.061977 | Step: 27 \n",
      "| Reward: -70 | Episode: 256 | Qmax: -69.0132 | Exploration: 0.060737 | Step: 8 \n",
      "| Reward: -220 | Episode: 257 | Qmax: -2.1077 | Exploration: 0.059522 | Step: 23 \n",
      "| Reward: -80 | Episode: 258 | Qmax: 0.9416 | Exploration: 0.058332 | Step: 9 \n",
      "| Reward: -70 | Episode: 259 | Qmax: -11.5977 | Exploration: 0.057165 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 260 | Qmax: 7.1981 | Exploration: 0.056022 | Step: 8 \n",
      "| Reward: -190 | Episode: 261 | Qmax: -4.1384 | Exploration: 0.054901 | Step: 20 \n",
      "| Reward: -90 | Episode: 262 | Qmax: -45.2232 | Exploration: 0.053803 | Step: 10 \n",
      "| Reward: -940 | Episode: 263 | Qmax: -17.3751 | Exploration: 0.052727 | Step: 95 \n",
      "| Reward: -390 | Episode: 264 | Qmax: -24.1055 | Exploration: 0.051673 | Step: 40 \n",
      "| Reward: -420 | Episode: 265 | Qmax: -30.4221 | Exploration: 0.050639 | Step: 43 \n",
      "| Reward: -140 | Episode: 266 | Qmax: 6.2339 | Exploration: 0.049627 | Step: 15 \n",
      "| Reward: -170 | Episode: 267 | Qmax: -27.6397 | Exploration: 0.048634 | Step: 9 \n",
      "| Reward: -170 | Episode: 268 | Qmax: 15.6604 | Exploration: 0.047661 | Step: 18 \n",
      "| Reward: -150 | Episode: 269 | Qmax: 25.1596 | Exploration: 0.046708 | Step: 16 \n",
      "| Reward: -80 | Episode: 270 | Qmax: -34.8288 | Exploration: 0.045774 | Step: 9 \n",
      "| Reward: -130 | Episode: 271 | Qmax: -19.9070 | Exploration: 0.044858 | Step: 14 \n",
      "| Reward: -70 | Episode: 272 | Qmax: 80.5168 | Exploration: 0.043961 | Step: 8 \n",
      "| Reward: -70 | Episode: 273 | Qmax: 58.7422 | Exploration: 0.043082 | Step: 8 \n",
      "| Reward: -70 | Episode: 274 | Qmax: -0.8585 | Exploration: 0.042220 | Step: 8 \n",
      "| Reward: -90 | Episode: 275 | Qmax: -28.7450 | Exploration: 0.041376 | Step: 10 \n",
      "| Reward: -110 | Episode: 276 | Qmax: -39.6411 | Exploration: 0.040548 | Step: 12 \n",
      "| Reward: -70 | Episode: 277 | Qmax: 49.3696 | Exploration: 0.039738 | Step: 8 \n",
      "| Reward: -170 | Episode: 278 | Qmax: 31.0119 | Exploration: 0.038943 | Step: 9 \n",
      "| Reward: -70 | Episode: 279 | Qmax: -0.1073 | Exploration: 0.038164 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 280 | Qmax: 46.9493 | Exploration: 0.037401 | Step: 8 \n",
      "| Reward: -70 | Episode: 281 | Qmax: 13.4038 | Exploration: 0.036653 | Step: 8 \n",
      "| Reward: -70 | Episode: 282 | Qmax: -31.1610 | Exploration: 0.035920 | Step: 8 \n",
      "| Reward: -370 | Episode: 283 | Qmax: 12.9988 | Exploration: 0.035201 | Step: 38 \n",
      "| Reward: -70 | Episode: 284 | Qmax: -1.8737 | Exploration: 0.034497 | Step: 8 \n",
      "| Reward: -380 | Episode: 285 | Qmax: -13.9431 | Exploration: 0.033807 | Step: 39 \n",
      "| Reward: -70 | Episode: 286 | Qmax: 20.5868 | Exploration: 0.033131 | Step: 8 \n",
      "| Reward: -70 | Episode: 287 | Qmax: -15.9353 | Exploration: 0.032468 | Step: 8 \n",
      "| Reward: -70 | Episode: 288 | Qmax: -0.6472 | Exploration: 0.031819 | Step: 8 \n",
      "| Reward: -70 | Episode: 289 | Qmax: -58.5816 | Exploration: 0.031183 | Step: 8 \n",
      "| Reward: -70 | Episode: 290 | Qmax: -3.2669 | Exploration: 0.030559 | Step: 8 \n",
      "| Reward: -70 | Episode: 291 | Qmax: 3.4295 | Exploration: 0.029948 | Step: 8 \n",
      "| Reward: -70 | Episode: 292 | Qmax: 10.9309 | Exploration: 0.029349 | Step: 8 \n",
      "| Reward: -70 | Episode: 293 | Qmax: -104.1956 | Exploration: 0.028762 | Step: 8 \n",
      "| Reward: -70 | Episode: 294 | Qmax: -2.8963 | Exploration: 0.028187 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 295 | Qmax: 0.3521 | Exploration: 0.027623 | Step: 8 \n",
      "| Reward: -90 | Episode: 296 | Qmax: -29.3832 | Exploration: 0.027070 | Step: 10 \n",
      "| Reward: -70 | Episode: 297 | Qmax: -32.9615 | Exploration: 0.026529 | Step: 8 \n",
      "| Reward: -70 | Episode: 298 | Qmax: 35.7983 | Exploration: 0.025999 | Step: 8 \n",
      "| Reward: -70 | Episode: 299 | Qmax: 73.8880 | Exploration: 0.025479 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -110 | Episode: 300 | Qmax: 59.9068 | Exploration: 0.024969 | Step: 12 \n",
      "| Reward: -220 | Episode: 301 | Qmax: 38.5160 | Exploration: 0.024470 | Step: 23 \n",
      "| Reward: -70 | Episode: 302 | Qmax: 34.5687 | Exploration: 0.023980 | Step: 8 \n",
      "| Reward: -70 | Episode: 303 | Qmax: 37.7447 | Exploration: 0.023501 | Step: 8 \n",
      "| Reward: -70 | Episode: 304 | Qmax: 25.8776 | Exploration: 0.023031 | Step: 8 \n",
      "| Reward: -70 | Episode: 305 | Qmax: -0.2474 | Exploration: 0.022570 | Step: 8 \n",
      "| Reward: -70 | Episode: 306 | Qmax: -6.8916 | Exploration: 0.022119 | Step: 8 \n",
      "| Reward: -70 | Episode: 307 | Qmax: -11.3045 | Exploration: 0.021676 | Step: 8 \n",
      "| Reward: -70 | Episode: 308 | Qmax: 12.1472 | Exploration: 0.021243 | Step: 8 \n",
      "| Reward: -70 | Episode: 309 | Qmax: 60.7895 | Exploration: 0.020818 | Step: 8 \n",
      "| Reward: -70 | Episode: 310 | Qmax: 26.4423 | Exploration: 0.020401 | Step: 8 \n",
      "| Reward: -110 | Episode: 311 | Qmax: -2.9014 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -70 | Episode: 312 | Qmax: -11.4619 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 313 | Qmax: 9.2243 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 314 | Qmax: -5.6458 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 315 | Qmax: -1.8672 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -210 | Episode: 316 | Qmax: 41.9160 | Exploration: 0.019993 | Step: 22 \n",
      "| Reward: -70 | Episode: 317 | Qmax: -0.2489 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 318 | Qmax: 40.0755 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 319 | Qmax: 22.0705 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 320 | Qmax: 28.5280 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 321 | Qmax: 26.1730 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 322 | Qmax: 23.8125 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -190 | Episode: 323 | Qmax: 38.9578 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -100 | Episode: 324 | Qmax: 25.4793 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 325 | Qmax: 48.7467 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 326 | Qmax: 28.2303 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 327 | Qmax: -3.6384 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 328 | Qmax: -67.7504 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 329 | Qmax: 83.1004 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 330 | Qmax: 24.1355 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 331 | Qmax: 65.4295 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 332 | Qmax: 46.4046 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 333 | Qmax: 18.9488 | Exploration: 0.019993 | Step: 18 \n",
      "| Reward: -70 | Episode: 334 | Qmax: 40.9723 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 335 | Qmax: 35.2282 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 336 | Qmax: 6.1330 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 337 | Qmax: 51.0899 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 338 | Qmax: 37.0099 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 339 | Qmax: 49.6802 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 340 | Qmax: 43.8743 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 341 | Qmax: 27.8096 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 342 | Qmax: 68.1417 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 343 | Qmax: 65.5232 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 344 | Qmax: 37.6097 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 345 | Qmax: 75.7317 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 346 | Qmax: 39.4382 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 347 | Qmax: 39.1964 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 348 | Qmax: -21.6235 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 349 | Qmax: 16.5594 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 350 | Qmax: -3.7305 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 351 | Qmax: 36.9219 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -2090 | Episode: 352 | Qmax: 30.5368 | Exploration: 0.019993 | Step: 199 \n",
      "| Reward: -70 | Episode: 353 | Qmax: -2.1701 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 354 | Qmax: 76.5950 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 355 | Qmax: 39.3141 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 356 | Qmax: 24.5507 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 357 | Qmax: 61.8363 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 358 | Qmax: 37.1670 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 359 | Qmax: 24.0971 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 360 | Qmax: 35.0965 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 361 | Qmax: 45.4775 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 362 | Qmax: 81.3392 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 363 | Qmax: 10.8592 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 364 | Qmax: 41.9582 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 365 | Qmax: 62.0005 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 366 | Qmax: -20.2539 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 367 | Qmax: 86.9396 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 368 | Qmax: 59.6489 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 369 | Qmax: 2.4403 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 370 | Qmax: 64.7084 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 371 | Qmax: 76.3287 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 372 | Qmax: 86.2688 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 373 | Qmax: 81.8117 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 374 | Qmax: 4.7132 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 375 | Qmax: 51.8061 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 376 | Qmax: 7.8343 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 377 | Qmax: 41.6013 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 378 | Qmax: 23.2400 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 379 | Qmax: 80.9860 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 380 | Qmax: 93.7751 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 381 | Qmax: 50.5616 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 382 | Qmax: 81.1739 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 383 | Qmax: 58.0077 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 384 | Qmax: 67.3182 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 385 | Qmax: 99.0475 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 386 | Qmax: 29.8543 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 387 | Qmax: 21.8238 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 388 | Qmax: 13.1994 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 389 | Qmax: 34.2178 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 390 | Qmax: 32.9557 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 391 | Qmax: -15.1445 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 392 | Qmax: 24.8302 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 393 | Qmax: 54.1201 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 394 | Qmax: 46.0762 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 395 | Qmax: 36.1213 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 396 | Qmax: 49.1124 | Exploration: 0.019993 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -90 | Episode: 397 | Qmax: 79.6298 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -80 | Episode: 398 | Qmax: 35.9589 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 399 | Qmax: 11.2225 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 400 | Qmax: 68.7092 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 401 | Qmax: 45.6989 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 402 | Qmax: 72.2492 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 403 | Qmax: 7.6878 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 404 | Qmax: 39.9351 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 405 | Qmax: 92.4657 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 406 | Qmax: 67.8223 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 407 | Qmax: 80.2934 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 408 | Qmax: 85.6167 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 409 | Qmax: 21.4786 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 410 | Qmax: 98.0689 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 411 | Qmax: 102.5961 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 412 | Qmax: 68.1080 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 413 | Qmax: 68.3507 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 414 | Qmax: 43.2815 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 415 | Qmax: 87.4986 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 416 | Qmax: 104.8370 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 417 | Qmax: 57.7028 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 418 | Qmax: 33.5854 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 419 | Qmax: 58.9032 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 420 | Qmax: 84.5501 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 421 | Qmax: 39.4900 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 422 | Qmax: 45.7835 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 423 | Qmax: 46.3412 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 424 | Qmax: 55.7714 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 425 | Qmax: 101.3643 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 426 | Qmax: 69.0855 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 427 | Qmax: 5.4815 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 428 | Qmax: 115.4576 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 429 | Qmax: -1.8821 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 430 | Qmax: 35.4110 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 431 | Qmax: 90.1069 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 432 | Qmax: 70.7901 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 433 | Qmax: 37.8833 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 434 | Qmax: 44.0270 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 435 | Qmax: 53.3145 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 436 | Qmax: 72.7383 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 437 | Qmax: 52.0800 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 438 | Qmax: 80.8180 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 439 | Qmax: 89.9208 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 440 | Qmax: 88.2720 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 441 | Qmax: 84.7660 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 442 | Qmax: 62.3750 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 443 | Qmax: 9.1111 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 444 | Qmax: 66.3863 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 445 | Qmax: 55.5218 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 446 | Qmax: 27.7276 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 447 | Qmax: 53.2496 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 448 | Qmax: 93.0723 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 449 | Qmax: 61.5737 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 450 | Qmax: 28.6540 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 451 | Qmax: 68.8896 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 452 | Qmax: 48.8703 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 453 | Qmax: 85.1437 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 454 | Qmax: 58.2908 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 455 | Qmax: 104.1144 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 456 | Qmax: 58.0878 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 457 | Qmax: 92.6588 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 458 | Qmax: 56.9528 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 459 | Qmax: 89.0238 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -840 | Episode: 460 | Qmax: 87.9790 | Exploration: 0.019993 | Step: 22 \n",
      "| Reward: -70 | Episode: 461 | Qmax: 53.3146 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 462 | Qmax: 88.1096 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 463 | Qmax: 66.3508 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -510 | Episode: 464 | Qmax: 75.1346 | Exploration: 0.019993 | Step: 16 \n",
      "| Reward: -70 | Episode: 465 | Qmax: 18.0427 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 466 | Qmax: 67.1379 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 467 | Qmax: 41.4669 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 468 | Qmax: 65.1448 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 469 | Qmax: 74.1882 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -80 | Episode: 470 | Qmax: 84.2789 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 471 | Qmax: 91.2175 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 472 | Qmax: 51.6534 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 473 | Qmax: 36.3766 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 474 | Qmax: 77.1068 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 475 | Qmax: 118.3814 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 476 | Qmax: 89.4535 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 477 | Qmax: 106.8547 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 478 | Qmax: 42.4540 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 479 | Qmax: 78.9514 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 480 | Qmax: 76.4282 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 481 | Qmax: 60.4542 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -180 | Episode: 482 | Qmax: 22.4023 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 483 | Qmax: 78.1362 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 484 | Qmax: 63.3571 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 485 | Qmax: 66.8099 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 486 | Qmax: 84.8243 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 487 | Qmax: 84.8804 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 488 | Qmax: 81.7630 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 489 | Qmax: 44.1139 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 490 | Qmax: 80.5544 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 491 | Qmax: 78.1272 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 492 | Qmax: 96.3972 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 493 | Qmax: 98.3850 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 494 | Qmax: 104.5236 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 495 | Qmax: 99.9317 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 496 | Qmax: 73.3176 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 497 | Qmax: 39.8883 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 498 | Qmax: 56.5388 | Exploration: 0.019993 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 499 | Qmax: 115.6860 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 500 | Qmax: 95.1718 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 501 | Qmax: 52.0948 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 502 | Qmax: 72.2085 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 503 | Qmax: 49.6510 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 504 | Qmax: 84.2523 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 505 | Qmax: 108.2662 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 506 | Qmax: 71.6894 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 507 | Qmax: 55.7170 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 508 | Qmax: 73.9362 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 509 | Qmax: 89.3518 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 510 | Qmax: 93.2718 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 511 | Qmax: 81.6102 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 512 | Qmax: 99.8710 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 513 | Qmax: 91.1620 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 514 | Qmax: 120.9036 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 515 | Qmax: 58.5829 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 516 | Qmax: 52.9377 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 517 | Qmax: 99.6684 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 518 | Qmax: 99.5646 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 519 | Qmax: 77.4229 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 520 | Qmax: 72.1678 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 521 | Qmax: 96.1647 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 522 | Qmax: 55.1230 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 523 | Qmax: 31.3649 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 524 | Qmax: 62.1710 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 525 | Qmax: 63.5968 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 526 | Qmax: 87.5563 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 527 | Qmax: 62.8311 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 528 | Qmax: 103.4255 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 529 | Qmax: 76.0334 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 530 | Qmax: 88.3510 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 531 | Qmax: 102.7580 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 532 | Qmax: 55.2704 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 533 | Qmax: 66.8122 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 534 | Qmax: 101.2180 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 535 | Qmax: 94.8912 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 536 | Qmax: 67.0079 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 537 | Qmax: 97.2714 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 538 | Qmax: 92.3605 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 539 | Qmax: 80.1580 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 540 | Qmax: 87.6702 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 541 | Qmax: 60.1406 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -80 | Episode: 542 | Qmax: 93.7147 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 543 | Qmax: 74.1846 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 544 | Qmax: 96.1172 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 545 | Qmax: 106.8477 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 546 | Qmax: 110.8635 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 547 | Qmax: 70.7109 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -80 | Episode: 548 | Qmax: 115.0262 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 549 | Qmax: 64.7933 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 550 | Qmax: 87.0747 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 551 | Qmax: 117.5319 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 552 | Qmax: 97.3911 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 553 | Qmax: 85.0387 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -80 | Episode: 554 | Qmax: 101.1861 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 555 | Qmax: 92.4420 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 556 | Qmax: 92.0596 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 557 | Qmax: 86.6352 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 558 | Qmax: 101.7257 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 559 | Qmax: 61.7237 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 560 | Qmax: 97.6067 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 561 | Qmax: 54.9526 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 562 | Qmax: 106.7680 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 563 | Qmax: 36.8509 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 564 | Qmax: 87.4071 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -190 | Episode: 565 | Qmax: 107.9673 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 566 | Qmax: 71.9670 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 567 | Qmax: 77.1602 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 568 | Qmax: 105.8444 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 569 | Qmax: 70.1052 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 570 | Qmax: 108.3799 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 571 | Qmax: 79.6243 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 572 | Qmax: 101.9181 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 573 | Qmax: 88.1322 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 574 | Qmax: 109.8728 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 575 | Qmax: 109.5068 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 576 | Qmax: 94.2533 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 577 | Qmax: 79.8223 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 578 | Qmax: 90.9386 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 579 | Qmax: 105.3275 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 580 | Qmax: 105.2016 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 581 | Qmax: 86.4355 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 582 | Qmax: 117.3081 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 583 | Qmax: 65.6379 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 584 | Qmax: 125.1954 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 585 | Qmax: 89.8661 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 586 | Qmax: 97.8333 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 587 | Qmax: 96.2552 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 588 | Qmax: 87.9213 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 589 | Qmax: 88.0220 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 590 | Qmax: 85.5360 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 591 | Qmax: 101.0341 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 592 | Qmax: 116.5452 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 593 | Qmax: 103.0577 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 594 | Qmax: 89.5805 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 595 | Qmax: 100.8505 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 596 | Qmax: 115.5716 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 597 | Qmax: 64.5861 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 598 | Qmax: 109.2564 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 599 | Qmax: 89.6689 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 600 | Qmax: 34.5943 | Exploration: 0.019993 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 601 | Qmax: 88.1472 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 602 | Qmax: 51.2806 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 603 | Qmax: 103.3985 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 604 | Qmax: 57.3197 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 605 | Qmax: 93.3713 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 606 | Qmax: 81.0321 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 607 | Qmax: 68.9935 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 608 | Qmax: 107.8362 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 609 | Qmax: 114.1338 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -80 | Episode: 610 | Qmax: 107.8261 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 611 | Qmax: 89.5535 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 612 | Qmax: 93.0070 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 613 | Qmax: 64.1768 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 614 | Qmax: 99.2485 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 615 | Qmax: 83.1209 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 616 | Qmax: 97.1501 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 617 | Qmax: 106.3161 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 618 | Qmax: 92.4290 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 619 | Qmax: 110.6081 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 620 | Qmax: 92.8140 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 621 | Qmax: 62.4379 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 622 | Qmax: 109.6640 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 623 | Qmax: 117.0861 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 624 | Qmax: 101.6797 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 625 | Qmax: 111.1881 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 626 | Qmax: 95.4338 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 627 | Qmax: 108.8797 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 628 | Qmax: 100.4738 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 629 | Qmax: 90.3584 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 630 | Qmax: 107.3591 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 631 | Qmax: 85.2417 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 632 | Qmax: 86.5760 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -80 | Episode: 633 | Qmax: 94.7534 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 634 | Qmax: 89.8573 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -100 | Episode: 635 | Qmax: 85.9172 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 636 | Qmax: 94.0911 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 637 | Qmax: 109.4947 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 638 | Qmax: 101.4668 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 639 | Qmax: 107.6604 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 640 | Qmax: 89.5648 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 641 | Qmax: 104.0672 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 642 | Qmax: 79.4603 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 643 | Qmax: 107.5021 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 644 | Qmax: 110.2658 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 645 | Qmax: 100.0464 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 646 | Qmax: 87.3494 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 647 | Qmax: 106.6117 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 648 | Qmax: 108.1036 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 649 | Qmax: 100.3757 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 650 | Qmax: 76.2789 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 651 | Qmax: 66.3455 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 652 | Qmax: 77.5492 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -140 | Episode: 653 | Qmax: 115.8247 | Exploration: 0.019993 | Step: 15 \n",
      "| Reward: -80 | Episode: 654 | Qmax: 99.3085 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 655 | Qmax: 101.8414 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -100 | Episode: 656 | Qmax: 90.6492 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -310 | Episode: 657 | Qmax: 85.1581 | Exploration: 0.019993 | Step: 32 \n",
      "| Reward: -70 | Episode: 658 | Qmax: 94.2966 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 659 | Qmax: 61.9894 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -80 | Episode: 660 | Qmax: 95.1873 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 661 | Qmax: 119.0909 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 662 | Qmax: 79.5875 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -100 | Episode: 663 | Qmax: 106.9532 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 664 | Qmax: 74.9496 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 665 | Qmax: 102.8231 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 666 | Qmax: 97.9599 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 667 | Qmax: 89.0001 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 668 | Qmax: 103.7508 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 669 | Qmax: 97.1919 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 670 | Qmax: 87.6434 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 671 | Qmax: 97.3003 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 672 | Qmax: 105.5173 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 673 | Qmax: 86.0676 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 674 | Qmax: 85.8823 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 675 | Qmax: 104.7632 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 676 | Qmax: 110.8737 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -100 | Episode: 677 | Qmax: 109.2952 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -170 | Episode: 678 | Qmax: 98.3204 | Exploration: 0.019993 | Step: 18 \n",
      "| Reward: -100 | Episode: 679 | Qmax: 89.9863 | Exploration: 0.019993 | Step: 11 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 680 | Qmax: 102.3805 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 681 | Qmax: 85.0563 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 682 | Qmax: 107.4955 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 683 | Qmax: 99.7267 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 684 | Qmax: 96.1552 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 685 | Qmax: 109.7459 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 686 | Qmax: 98.2901 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 687 | Qmax: 105.7779 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 688 | Qmax: 112.7698 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 689 | Qmax: 106.2895 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 690 | Qmax: 89.1812 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 691 | Qmax: 44.6574 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 692 | Qmax: 102.8907 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 693 | Qmax: 114.6342 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 694 | Qmax: 97.0455 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 695 | Qmax: 115.5437 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 696 | Qmax: 108.9922 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 697 | Qmax: 81.9550 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 698 | Qmax: 97.8864 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 699 | Qmax: 88.1225 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 700 | Qmax: 115.3969 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 701 | Qmax: 80.4629 | Exploration: 0.019993 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 702 | Qmax: 109.1648 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 703 | Qmax: 84.4839 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 704 | Qmax: 95.8909 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 705 | Qmax: 118.0004 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -160 | Episode: 706 | Qmax: 106.0781 | Exploration: 0.019993 | Step: 17 \n",
      "| Reward: -70 | Episode: 707 | Qmax: 77.2343 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 708 | Qmax: 110.3676 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 709 | Qmax: 104.3940 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 710 | Qmax: 110.6616 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -150 | Episode: 711 | Qmax: 100.4249 | Exploration: 0.019993 | Step: 16 \n",
      "| Reward: -70 | Episode: 712 | Qmax: 92.5312 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 713 | Qmax: 86.6885 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 714 | Qmax: 90.6385 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 715 | Qmax: 91.5440 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 716 | Qmax: 93.7925 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 717 | Qmax: 76.2922 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 718 | Qmax: 113.4469 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 719 | Qmax: 88.6301 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 720 | Qmax: 110.0227 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 721 | Qmax: 102.2752 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 722 | Qmax: 102.7673 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 723 | Qmax: 106.2892 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 724 | Qmax: 104.7496 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 725 | Qmax: 127.2986 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 726 | Qmax: 107.7797 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 727 | Qmax: 111.9111 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 728 | Qmax: 115.3066 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 729 | Qmax: 90.0589 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 730 | Qmax: 80.7638 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 731 | Qmax: 117.1745 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 732 | Qmax: 102.2284 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 733 | Qmax: 104.5595 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 734 | Qmax: 94.7794 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -140 | Episode: 735 | Qmax: 94.4507 | Exploration: 0.019993 | Step: 15 \n",
      "| Reward: -70 | Episode: 736 | Qmax: 126.1385 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 737 | Qmax: 97.0724 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 738 | Qmax: 81.5904 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 739 | Qmax: 110.2306 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -80 | Episode: 740 | Qmax: 99.6799 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 741 | Qmax: 110.4213 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 742 | Qmax: 77.4220 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 743 | Qmax: 102.1304 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 744 | Qmax: 102.6672 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 745 | Qmax: 103.7280 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 746 | Qmax: 109.8158 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 747 | Qmax: 73.0433 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 748 | Qmax: 105.3363 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 749 | Qmax: 111.8264 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -120 | Episode: 750 | Qmax: 82.7435 | Exploration: 0.019993 | Step: 13 \n",
      "| Reward: -70 | Episode: 751 | Qmax: 97.0840 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 752 | Qmax: 100.2749 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 753 | Qmax: 112.5766 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 754 | Qmax: 103.9743 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 755 | Qmax: 97.9452 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 756 | Qmax: 112.8524 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 757 | Qmax: 107.9102 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 758 | Qmax: 115.7763 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 759 | Qmax: 109.8900 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -80 | Episode: 760 | Qmax: 79.0164 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 761 | Qmax: 121.1569 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 762 | Qmax: 113.9867 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 763 | Qmax: 86.0129 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 764 | Qmax: 114.3643 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 765 | Qmax: 104.9500 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 766 | Qmax: 117.2633 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 767 | Qmax: 96.4481 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 768 | Qmax: 116.9804 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 769 | Qmax: 71.5029 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 770 | Qmax: 106.0644 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 771 | Qmax: 103.4142 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 772 | Qmax: 88.4955 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -180 | Episode: 773 | Qmax: 98.5419 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 774 | Qmax: 78.4060 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 775 | Qmax: 91.8963 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 776 | Qmax: 102.4481 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 777 | Qmax: 127.0136 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 778 | Qmax: 109.7590 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 779 | Qmax: 117.0033 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 780 | Qmax: 76.7471 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 781 | Qmax: 99.7872 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 782 | Qmax: 118.6157 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 783 | Qmax: 121.6116 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 784 | Qmax: 105.6703 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 785 | Qmax: 96.4755 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 786 | Qmax: 88.9072 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 787 | Qmax: 110.5570 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 788 | Qmax: 90.8330 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 789 | Qmax: 98.3467 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 790 | Qmax: 108.2317 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 791 | Qmax: 101.9806 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 792 | Qmax: 87.8272 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 793 | Qmax: 121.1351 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 794 | Qmax: 114.2117 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 795 | Qmax: 96.1412 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 796 | Qmax: 92.2428 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 797 | Qmax: 123.8904 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 798 | Qmax: 91.8041 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 799 | Qmax: 91.8094 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 800 | Qmax: 105.7959 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -330 | Episode: 801 | Qmax: 96.4499 | Exploration: 0.019993 | Step: 25 \n",
      "| Reward: -70 | Episode: 802 | Qmax: 125.5470 | Exploration: 0.019993 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 803 | Qmax: 106.1389 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 804 | Qmax: 122.8902 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 805 | Qmax: 93.2855 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 806 | Qmax: 108.8379 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 807 | Qmax: 95.5603 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 808 | Qmax: 109.8500 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 809 | Qmax: 98.1613 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 810 | Qmax: 108.1751 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 811 | Qmax: 91.5357 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 812 | Qmax: 124.0715 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 813 | Qmax: 76.8736 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 814 | Qmax: 115.3404 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 815 | Qmax: 91.7232 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 816 | Qmax: 112.9339 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 817 | Qmax: 108.9014 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 818 | Qmax: 116.2222 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 819 | Qmax: 112.2416 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 820 | Qmax: 107.5420 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -150 | Episode: 821 | Qmax: 100.0634 | Exploration: 0.019993 | Step: 16 \n",
      "| Reward: -70 | Episode: 822 | Qmax: 111.6175 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 823 | Qmax: 112.9542 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -160 | Episode: 824 | Qmax: 90.5452 | Exploration: 0.019993 | Step: 17 \n",
      "| Reward: -70 | Episode: 825 | Qmax: 108.0673 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 826 | Qmax: 109.2905 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 827 | Qmax: 110.4025 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 828 | Qmax: 96.8655 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -110 | Episode: 829 | Qmax: 107.2065 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -70 | Episode: 830 | Qmax: 110.9462 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 831 | Qmax: 112.0384 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 832 | Qmax: 112.6503 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 833 | Qmax: 97.3248 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 834 | Qmax: 115.3129 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 835 | Qmax: 108.4276 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 836 | Qmax: 74.1212 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 837 | Qmax: 107.9206 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 838 | Qmax: 109.4291 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 839 | Qmax: 107.2444 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 840 | Qmax: 104.9824 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 841 | Qmax: 107.7777 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 842 | Qmax: 110.4327 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 843 | Qmax: 117.5033 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 844 | Qmax: 117.2298 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 845 | Qmax: 102.8337 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 846 | Qmax: 104.5681 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 847 | Qmax: 114.1747 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 848 | Qmax: 117.7401 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 849 | Qmax: 121.4891 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 850 | Qmax: 108.5086 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 851 | Qmax: 107.8126 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 852 | Qmax: 92.8235 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 853 | Qmax: 116.3836 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 854 | Qmax: 73.7870 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 855 | Qmax: 95.8288 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 856 | Qmax: 109.3719 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 857 | Qmax: 106.0481 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 858 | Qmax: 92.6581 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 859 | Qmax: 101.8157 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 860 | Qmax: 83.9966 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 861 | Qmax: 115.1635 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 862 | Qmax: 109.8872 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 863 | Qmax: 111.9519 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 864 | Qmax: 127.7561 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 865 | Qmax: 125.5903 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 866 | Qmax: 86.5677 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 867 | Qmax: 103.5326 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 868 | Qmax: 97.5488 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 869 | Qmax: 114.3338 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 870 | Qmax: 98.5168 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 871 | Qmax: 88.5282 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 872 | Qmax: 108.6022 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 873 | Qmax: 106.6748 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 874 | Qmax: 117.4299 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 875 | Qmax: 115.2246 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 876 | Qmax: 128.7536 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 877 | Qmax: 109.4161 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 878 | Qmax: 109.7653 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 879 | Qmax: 120.1376 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 880 | Qmax: 92.5092 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 881 | Qmax: 114.9702 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 882 | Qmax: 101.9937 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 883 | Qmax: 117.9775 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 884 | Qmax: 100.3905 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 885 | Qmax: 123.3865 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 886 | Qmax: 111.8212 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 887 | Qmax: 117.4754 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 888 | Qmax: 90.8238 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 889 | Qmax: 120.0114 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 890 | Qmax: 73.8104 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 891 | Qmax: 129.1247 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 892 | Qmax: 111.8161 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 893 | Qmax: 104.9010 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 894 | Qmax: 114.8943 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 895 | Qmax: 96.6090 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 896 | Qmax: 97.2951 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 897 | Qmax: 109.7790 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 898 | Qmax: 113.0826 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -90 | Episode: 899 | Qmax: 100.1631 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -80 | Episode: 900 | Qmax: 107.3186 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 901 | Qmax: 101.1748 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 902 | Qmax: 113.4149 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 903 | Qmax: 99.4643 | Exploration: 0.019993 | Step: 9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 904 | Qmax: 105.0572 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 905 | Qmax: 119.0085 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 906 | Qmax: 109.2878 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 907 | Qmax: 119.7876 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 908 | Qmax: 117.8169 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 909 | Qmax: 81.0831 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 910 | Qmax: 105.4495 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 911 | Qmax: 105.6949 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 912 | Qmax: 113.1999 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 913 | Qmax: 104.4914 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 914 | Qmax: 101.1401 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 915 | Qmax: 109.3019 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 916 | Qmax: 115.6546 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 917 | Qmax: 113.0338 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 918 | Qmax: 110.0717 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 919 | Qmax: 105.2138 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 920 | Qmax: 104.9158 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 921 | Qmax: 118.8892 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 922 | Qmax: 107.4988 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 923 | Qmax: 110.4483 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 924 | Qmax: 94.2739 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 925 | Qmax: 111.0200 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 926 | Qmax: 97.6285 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 927 | Qmax: 113.1980 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 928 | Qmax: 117.8567 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 929 | Qmax: 99.7753 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 930 | Qmax: 114.2273 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -100 | Episode: 931 | Qmax: 113.8197 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 932 | Qmax: 128.5281 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 933 | Qmax: 106.8082 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 934 | Qmax: 93.8624 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 935 | Qmax: 109.7673 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 936 | Qmax: 125.9480 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 937 | Qmax: 106.4564 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 938 | Qmax: 120.2235 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 939 | Qmax: 108.1502 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 940 | Qmax: 112.7850 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 941 | Qmax: 104.4089 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 942 | Qmax: 96.8641 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -190 | Episode: 943 | Qmax: 102.6571 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 944 | Qmax: 93.9672 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -130 | Episode: 945 | Qmax: 107.2424 | Exploration: 0.019993 | Step: 14 \n",
      "| Reward: -70 | Episode: 946 | Qmax: 116.2651 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 947 | Qmax: 95.5943 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -90 | Episode: 948 | Qmax: 92.7565 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 949 | Qmax: 111.5878 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 950 | Qmax: 108.6890 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 951 | Qmax: 111.2761 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 952 | Qmax: 119.3206 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 953 | Qmax: 99.4810 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 954 | Qmax: 109.0058 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 955 | Qmax: 109.9922 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 956 | Qmax: 118.5127 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 957 | Qmax: 90.9925 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 958 | Qmax: 117.7477 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 959 | Qmax: 114.2987 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -80 | Episode: 960 | Qmax: 111.4473 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 961 | Qmax: 99.8833 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 962 | Qmax: 107.2847 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 963 | Qmax: 106.6428 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 964 | Qmax: 113.3998 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 965 | Qmax: 123.8743 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 966 | Qmax: 112.9790 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 967 | Qmax: 116.7359 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 968 | Qmax: 111.2928 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 969 | Qmax: 106.9636 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 970 | Qmax: 93.8279 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 971 | Qmax: 119.4568 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 972 | Qmax: 111.3113 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 973 | Qmax: 132.1381 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 974 | Qmax: 101.0522 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -90 | Episode: 975 | Qmax: 101.1785 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 976 | Qmax: 116.0649 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 977 | Qmax: 117.9220 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 978 | Qmax: 105.6161 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 979 | Qmax: 127.5857 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -90 | Episode: 980 | Qmax: 101.2897 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 981 | Qmax: 113.5606 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 982 | Qmax: 93.5399 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 983 | Qmax: 112.3402 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 984 | Qmax: 111.1829 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 985 | Qmax: 117.1360 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 986 | Qmax: 96.2515 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 987 | Qmax: 119.6423 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 988 | Qmax: 87.9020 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 989 | Qmax: 104.9493 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 990 | Qmax: 122.4632 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 991 | Qmax: 119.2824 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 992 | Qmax: 112.4701 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 993 | Qmax: 110.7024 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 994 | Qmax: 123.2095 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 995 | Qmax: 99.0345 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 996 | Qmax: 109.0571 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 997 | Qmax: 114.6204 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 998 | Qmax: 121.3911 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 999 | Qmax: 105.1314 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1000 | Qmax: 109.3220 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1001 | Qmax: 97.6769 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1002 | Qmax: 127.2181 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1003 | Qmax: 114.3962 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1004 | Qmax: 111.7782 | Exploration: 0.019993 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 1005 | Qmax: 114.3510 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1006 | Qmax: 103.4401 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 1007 | Qmax: 114.5819 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1008 | Qmax: 112.2486 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1009 | Qmax: 111.5760 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1010 | Qmax: 112.9781 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -180 | Episode: 1011 | Qmax: 118.5551 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1012 | Qmax: 96.2146 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1013 | Qmax: 107.1909 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1014 | Qmax: 108.1224 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1015 | Qmax: 115.3500 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1016 | Qmax: 108.7125 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1017 | Qmax: 115.9088 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1018 | Qmax: 114.8211 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1019 | Qmax: 123.4343 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1020 | Qmax: 99.8866 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1021 | Qmax: 115.3187 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1022 | Qmax: 105.1242 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1023 | Qmax: 115.1967 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1024 | Qmax: 102.7297 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1025 | Qmax: 117.1283 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1026 | Qmax: 111.4734 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -190 | Episode: 1027 | Qmax: 102.3037 | Exploration: 0.019993 | Step: 20 \n",
      "| Reward: -70 | Episode: 1028 | Qmax: 103.5504 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1029 | Qmax: 108.8168 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1030 | Qmax: 109.6831 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -110 | Episode: 1031 | Qmax: 94.4605 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -70 | Episode: 1032 | Qmax: 114.2764 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1033 | Qmax: 115.7499 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1034 | Qmax: 117.3364 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1035 | Qmax: 118.3828 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1036 | Qmax: 108.6464 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 1037 | Qmax: 99.8301 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1038 | Qmax: 108.0932 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1039 | Qmax: 111.9589 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1040 | Qmax: 111.4913 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1041 | Qmax: 124.3257 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1042 | Qmax: 105.4657 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1043 | Qmax: 110.2523 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1044 | Qmax: 85.7221 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1045 | Qmax: 102.5684 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1046 | Qmax: 111.8621 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1047 | Qmax: 110.0214 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1048 | Qmax: 101.5811 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1049 | Qmax: 119.6343 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1050 | Qmax: 105.4238 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1051 | Qmax: 111.6336 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1052 | Qmax: 100.5404 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1053 | Qmax: 116.0264 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1054 | Qmax: 105.6474 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1055 | Qmax: 106.7833 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1056 | Qmax: 123.1729 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1057 | Qmax: 112.9285 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1058 | Qmax: 123.0856 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1059 | Qmax: 100.5355 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1060 | Qmax: 114.2493 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1061 | Qmax: 119.3441 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1062 | Qmax: 117.9409 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1063 | Qmax: 116.0298 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1064 | Qmax: 107.5178 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1065 | Qmax: 95.0504 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1066 | Qmax: 101.1531 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1067 | Qmax: 111.5070 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1068 | Qmax: 114.0024 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1069 | Qmax: 94.5434 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1070 | Qmax: 114.2993 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1071 | Qmax: 102.5912 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1072 | Qmax: 102.7055 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1073 | Qmax: 111.2475 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1074 | Qmax: 97.4439 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1075 | Qmax: 108.7022 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1076 | Qmax: 121.7311 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1077 | Qmax: 120.3695 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 1078 | Qmax: 107.0298 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1079 | Qmax: 113.7454 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1080 | Qmax: 118.4735 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1081 | Qmax: 110.5870 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 1082 | Qmax: 104.8721 | Exploration: 0.019993 | Step: 18 \n",
      "| Reward: -230 | Episode: 1083 | Qmax: 107.2975 | Exploration: 0.019993 | Step: 24 \n",
      "| Reward: -70 | Episode: 1084 | Qmax: 112.4551 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1085 | Qmax: 112.6069 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1086 | Qmax: 112.4782 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1087 | Qmax: 118.4441 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1088 | Qmax: 112.2141 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1089 | Qmax: 104.6426 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -360 | Episode: 1090 | Qmax: 95.9785 | Exploration: 0.019993 | Step: 37 \n",
      "| Reward: -80 | Episode: 1091 | Qmax: 117.9518 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1092 | Qmax: 101.4824 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -210 | Episode: 1093 | Qmax: 103.3727 | Exploration: 0.019993 | Step: 22 \n",
      "| Reward: -160 | Episode: 1094 | Qmax: 105.8412 | Exploration: 0.019993 | Step: 17 \n",
      "| Reward: -180 | Episode: 1095 | Qmax: 119.3957 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1096 | Qmax: 87.1378 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -130 | Episode: 1097 | Qmax: 104.0228 | Exploration: 0.019993 | Step: 14 \n",
      "| Reward: -70 | Episode: 1098 | Qmax: 111.0390 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1099 | Qmax: 120.8947 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1100 | Qmax: 101.1415 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1101 | Qmax: 115.7521 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1102 | Qmax: 113.7723 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1103 | Qmax: 100.7492 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 1104 | Qmax: 118.3806 | Exploration: 0.019993 | Step: 9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 1105 | Qmax: 111.8600 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1106 | Qmax: 101.8245 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1107 | Qmax: 103.5347 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -110 | Episode: 1108 | Qmax: 110.5406 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -70 | Episode: 1109 | Qmax: 124.5128 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1110 | Qmax: 128.0800 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1111 | Qmax: 124.8319 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1112 | Qmax: 111.7817 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1113 | Qmax: 128.9061 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1114 | Qmax: 108.4951 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1115 | Qmax: 118.3287 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1116 | Qmax: 115.9125 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1117 | Qmax: 98.7201 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1118 | Qmax: 111.0789 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1119 | Qmax: 87.9824 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1120 | Qmax: 118.2621 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 1121 | Qmax: 115.6347 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1122 | Qmax: 118.4901 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -110 | Episode: 1123 | Qmax: 113.9309 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -70 | Episode: 1124 | Qmax: 108.7065 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1125 | Qmax: 112.3705 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1126 | Qmax: 115.9670 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1127 | Qmax: 112.9723 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1128 | Qmax: 105.4143 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1129 | Qmax: 119.6332 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1130 | Qmax: 118.8393 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1131 | Qmax: 107.0033 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1132 | Qmax: 111.9623 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1133 | Qmax: 106.7227 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -130 | Episode: 1134 | Qmax: 105.4712 | Exploration: 0.019993 | Step: 14 \n",
      "| Reward: -70 | Episode: 1135 | Qmax: 119.5211 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1136 | Qmax: 105.2527 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1137 | Qmax: 106.6164 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1138 | Qmax: 105.4096 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1139 | Qmax: 105.0712 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1140 | Qmax: 114.9938 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1141 | Qmax: 117.8117 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -110 | Episode: 1142 | Qmax: 105.6692 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -90 | Episode: 1143 | Qmax: 119.4439 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -130 | Episode: 1144 | Qmax: 100.3834 | Exploration: 0.019993 | Step: 14 \n",
      "| Reward: -70 | Episode: 1145 | Qmax: 113.0493 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -210 | Episode: 1146 | Qmax: 104.2967 | Exploration: 0.019993 | Step: 22 \n",
      "| Reward: -70 | Episode: 1147 | Qmax: 97.5675 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1148 | Qmax: 114.4403 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1149 | Qmax: 101.0669 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -180 | Episode: 1150 | Qmax: 113.5536 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1151 | Qmax: 101.4050 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1152 | Qmax: 107.6225 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1153 | Qmax: 123.3388 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1154 | Qmax: 109.3920 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1155 | Qmax: 113.9350 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1156 | Qmax: 118.9149 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1157 | Qmax: 105.3912 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 1158 | Qmax: 115.3615 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1159 | Qmax: 105.9409 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -80 | Episode: 1160 | Qmax: 118.1098 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1161 | Qmax: 115.5803 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1162 | Qmax: 118.2715 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1163 | Qmax: 108.6958 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1164 | Qmax: 113.1888 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1165 | Qmax: 112.8549 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1166 | Qmax: 109.4740 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1167 | Qmax: 107.1416 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1168 | Qmax: 107.1744 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 1169 | Qmax: 109.8837 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1170 | Qmax: 96.4189 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1171 | Qmax: 114.6028 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1172 | Qmax: 119.0871 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1173 | Qmax: 112.1782 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1174 | Qmax: 109.9379 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1175 | Qmax: 104.5409 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1176 | Qmax: 121.0760 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1177 | Qmax: 119.5898 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1178 | Qmax: 110.1195 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1179 | Qmax: 108.7902 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1180 | Qmax: 100.7843 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1181 | Qmax: 108.5261 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1182 | Qmax: 109.6221 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1183 | Qmax: 111.8627 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1184 | Qmax: 117.9448 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1185 | Qmax: 108.8060 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -100 | Episode: 1186 | Qmax: 92.2075 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -90 | Episode: 1187 | Qmax: 107.1771 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1188 | Qmax: 108.6208 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1189 | Qmax: 113.8170 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1190 | Qmax: 108.2387 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1191 | Qmax: 103.0935 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1192 | Qmax: 111.0805 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1193 | Qmax: 107.6985 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1194 | Qmax: 114.2651 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1195 | Qmax: 109.7637 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1196 | Qmax: 114.1690 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1197 | Qmax: 105.9920 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1198 | Qmax: 106.0068 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1199 | Qmax: 98.7535 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -90 | Episode: 1200 | Qmax: 102.6462 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1201 | Qmax: 114.7368 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1202 | Qmax: 101.4171 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1203 | Qmax: 119.6888 | Exploration: 0.019993 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -70 | Episode: 1204 | Qmax: 120.1567 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1205 | Qmax: 114.5995 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1206 | Qmax: 114.5894 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1207 | Qmax: 110.8586 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1208 | Qmax: 119.4236 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1209 | Qmax: 105.8141 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1210 | Qmax: 113.6684 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1211 | Qmax: 108.7639 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1212 | Qmax: 115.9806 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1213 | Qmax: 88.3280 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1214 | Qmax: 114.7789 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1215 | Qmax: 103.5276 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1216 | Qmax: 102.2069 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1217 | Qmax: 116.3370 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1218 | Qmax: 114.1467 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1219 | Qmax: 117.2569 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1220 | Qmax: 109.6413 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1221 | Qmax: 114.2593 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1222 | Qmax: 116.8781 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1223 | Qmax: 108.4930 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1224 | Qmax: 117.1672 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1225 | Qmax: 108.0018 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1226 | Qmax: 117.5661 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1227 | Qmax: 118.7205 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1228 | Qmax: 107.7682 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1229 | Qmax: 110.0241 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1230 | Qmax: 103.5157 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1231 | Qmax: 116.7307 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1232 | Qmax: 121.5606 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1233 | Qmax: 112.0691 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1234 | Qmax: 113.2765 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1235 | Qmax: 107.9412 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1236 | Qmax: 111.4135 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1237 | Qmax: 114.0139 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1238 | Qmax: 96.8699 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1239 | Qmax: 111.4860 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1240 | Qmax: 97.4538 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1241 | Qmax: 115.1090 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1242 | Qmax: 118.0112 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1243 | Qmax: 118.4230 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1244 | Qmax: 106.3128 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1245 | Qmax: 120.2663 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1246 | Qmax: 108.3806 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1247 | Qmax: 95.3304 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1248 | Qmax: 119.5342 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1249 | Qmax: 110.8753 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1250 | Qmax: 107.1377 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1251 | Qmax: 122.4387 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1252 | Qmax: 109.6632 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1253 | Qmax: 112.1439 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -180 | Episode: 1254 | Qmax: 109.3182 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1255 | Qmax: 115.7897 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1256 | Qmax: 113.9500 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1257 | Qmax: 107.7839 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1258 | Qmax: 119.5611 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1259 | Qmax: 108.2504 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1260 | Qmax: 113.7413 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1261 | Qmax: 94.3596 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1262 | Qmax: 114.7979 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -100 | Episode: 1263 | Qmax: 102.4409 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 1264 | Qmax: 114.5282 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1265 | Qmax: 114.4551 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1266 | Qmax: 113.3570 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1267 | Qmax: 103.4597 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1268 | Qmax: 111.4247 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -80 | Episode: 1269 | Qmax: 104.9188 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1270 | Qmax: 99.5080 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1271 | Qmax: 100.7617 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1272 | Qmax: 101.7808 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1273 | Qmax: 111.0159 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1274 | Qmax: 111.1098 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1275 | Qmax: 100.6787 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1276 | Qmax: 122.2079 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1277 | Qmax: 98.6053 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1278 | Qmax: 112.1830 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1279 | Qmax: 114.4571 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1280 | Qmax: 114.8055 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1281 | Qmax: 106.6553 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1282 | Qmax: 115.9396 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1283 | Qmax: 116.1513 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1284 | Qmax: 103.0085 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1285 | Qmax: 111.5970 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1286 | Qmax: 109.5628 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1287 | Qmax: 108.2418 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1288 | Qmax: 116.2132 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1289 | Qmax: 106.6340 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1290 | Qmax: 104.8210 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1291 | Qmax: 97.9481 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1292 | Qmax: 110.6529 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1293 | Qmax: 113.9594 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1294 | Qmax: 104.0236 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1295 | Qmax: 114.2932 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1296 | Qmax: 117.6585 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 1297 | Qmax: 117.8787 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1298 | Qmax: 113.1887 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 1299 | Qmax: 112.7094 | Exploration: 0.019993 | Step: 9 \n",
      "DDQN Saved\n",
      "| Reward: -100 | Episode: 1300 | Qmax: 103.5429 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 1301 | Qmax: 109.9371 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1302 | Qmax: 110.2461 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1303 | Qmax: 106.9593 | Exploration: 0.019993 | Step: 10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -90 | Episode: 1304 | Qmax: 117.7615 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1305 | Qmax: 107.1476 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1306 | Qmax: 109.4002 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1307 | Qmax: 109.5962 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -70 | Episode: 1308 | Qmax: 110.1606 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1309 | Qmax: 113.0361 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -90 | Episode: 1310 | Qmax: 100.6298 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1311 | Qmax: 109.7529 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1312 | Qmax: 115.6089 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1313 | Qmax: 114.6890 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -180 | Episode: 1314 | Qmax: 105.3653 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1315 | Qmax: 116.3139 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1316 | Qmax: 133.6876 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1317 | Qmax: 101.6428 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1318 | Qmax: 123.6765 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1319 | Qmax: 115.3026 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1320 | Qmax: 98.7880 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1321 | Qmax: 117.8423 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1322 | Qmax: 117.6296 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1323 | Qmax: 107.0344 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1324 | Qmax: 107.7563 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1325 | Qmax: 113.9666 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1326 | Qmax: 112.4378 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1327 | Qmax: 111.8587 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1328 | Qmax: 97.7530 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1329 | Qmax: 115.5791 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1330 | Qmax: 107.0482 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1331 | Qmax: 108.8541 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1332 | Qmax: 106.1795 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1333 | Qmax: 103.2071 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1334 | Qmax: 116.4190 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1335 | Qmax: 117.5335 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1336 | Qmax: 104.6288 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1337 | Qmax: 112.2005 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1338 | Qmax: 115.2065 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1339 | Qmax: 110.7933 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -70 | Episode: 1340 | Qmax: 110.3460 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -80 | Episode: 1341 | Qmax: 117.2455 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: 0 | Episode: 1342 | Qmax: 115.9847 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1343 | Qmax: 110.9501 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1344 | Qmax: 115.5089 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1345 | Qmax: 98.1313 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1346 | Qmax: 113.8765 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1347 | Qmax: 103.0648 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1348 | Qmax: 108.6641 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1349 | Qmax: 98.0434 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1350 | Qmax: 99.3772 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1351 | Qmax: 103.0110 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1352 | Qmax: 106.5308 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1353 | Qmax: 107.0462 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1354 | Qmax: 107.5340 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1355 | Qmax: 104.2346 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1356 | Qmax: 110.9190 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1357 | Qmax: 114.7195 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1358 | Qmax: 106.7190 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1359 | Qmax: 101.6167 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1360 | Qmax: 102.2971 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1361 | Qmax: 101.5979 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1362 | Qmax: 113.1059 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1363 | Qmax: 102.1187 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1364 | Qmax: 105.2613 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1365 | Qmax: 113.6201 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1366 | Qmax: 109.3595 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1367 | Qmax: 112.5555 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1368 | Qmax: 107.5570 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1369 | Qmax: 115.1109 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1370 | Qmax: 108.2330 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1371 | Qmax: 114.0553 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1372 | Qmax: 112.6285 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1373 | Qmax: 109.1371 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1374 | Qmax: 111.8588 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1375 | Qmax: 116.5744 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1376 | Qmax: 108.5257 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1377 | Qmax: 108.4523 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1378 | Qmax: 106.8968 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1379 | Qmax: 109.2284 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1380 | Qmax: 115.5187 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1381 | Qmax: 110.9169 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1382 | Qmax: 109.7755 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -90 | Episode: 1383 | Qmax: 109.4632 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1384 | Qmax: 119.8729 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1385 | Qmax: 114.2616 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1386 | Qmax: 107.9045 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1387 | Qmax: 112.7047 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1388 | Qmax: 103.6617 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1389 | Qmax: 112.8627 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1390 | Qmax: 118.7506 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1391 | Qmax: 107.4225 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1392 | Qmax: 112.1031 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1393 | Qmax: 114.7511 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1394 | Qmax: 110.1628 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1395 | Qmax: 109.8910 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1396 | Qmax: 109.6322 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1397 | Qmax: 110.7754 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1398 | Qmax: 105.4873 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1399 | Qmax: 110.6448 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1400 | Qmax: 116.9719 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1401 | Qmax: 114.8128 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1402 | Qmax: 109.3372 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1403 | Qmax: 113.8707 | Exploration: 0.019993 | Step: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: 0 | Episode: 1404 | Qmax: 109.9907 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1405 | Qmax: 110.0704 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1406 | Qmax: 125.0736 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1407 | Qmax: 114.6444 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1408 | Qmax: 108.3395 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1409 | Qmax: 115.8832 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1410 | Qmax: 105.0962 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1411 | Qmax: 110.6167 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1412 | Qmax: 107.2128 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1413 | Qmax: 118.5830 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1414 | Qmax: 115.9725 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1415 | Qmax: 120.9488 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1416 | Qmax: 112.9949 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1417 | Qmax: 101.5238 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -180 | Episode: 1418 | Qmax: 119.5691 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1419 | Qmax: 105.2518 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1420 | Qmax: 110.6761 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1421 | Qmax: 102.3362 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1422 | Qmax: 113.7504 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1423 | Qmax: 104.6871 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1424 | Qmax: 108.6321 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1425 | Qmax: 108.1931 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1426 | Qmax: 121.4704 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1427 | Qmax: 106.0206 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1428 | Qmax: 112.5351 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1429 | Qmax: 105.6704 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1430 | Qmax: 107.0743 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1431 | Qmax: 111.1452 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1432 | Qmax: 109.2949 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1433 | Qmax: 107.5652 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1434 | Qmax: 111.8040 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1435 | Qmax: 112.6119 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1436 | Qmax: 101.7607 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -110 | Episode: 1437 | Qmax: 110.3325 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1438 | Qmax: 105.9956 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1439 | Qmax: 108.4035 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1440 | Qmax: 101.0805 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1441 | Qmax: 115.3569 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1442 | Qmax: 115.2789 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1443 | Qmax: 105.4770 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1444 | Qmax: 110.9455 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1445 | Qmax: 118.9812 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1446 | Qmax: 109.2676 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1447 | Qmax: 115.4302 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1448 | Qmax: 114.5629 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1449 | Qmax: 110.2536 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1450 | Qmax: 113.7877 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1451 | Qmax: 102.0160 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1452 | Qmax: 112.9730 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1453 | Qmax: 109.2207 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1454 | Qmax: 116.7286 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1455 | Qmax: 111.1483 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1456 | Qmax: 117.8100 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1457 | Qmax: 111.7615 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1458 | Qmax: 112.9822 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1459 | Qmax: 112.1168 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1460 | Qmax: 112.2913 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1461 | Qmax: 111.1605 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1462 | Qmax: 117.9711 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1463 | Qmax: 108.0633 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1464 | Qmax: 105.1059 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1465 | Qmax: 107.7838 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1466 | Qmax: 113.3327 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -40 | Episode: 1467 | Qmax: 113.1747 | Exploration: 0.019993 | Step: 14 \n",
      "| Reward: 0 | Episode: 1468 | Qmax: 115.7105 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1469 | Qmax: 126.6699 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1470 | Qmax: 112.9192 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1471 | Qmax: 113.6644 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1472 | Qmax: 111.5804 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1473 | Qmax: 109.3716 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1474 | Qmax: 104.6225 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1475 | Qmax: 114.0754 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1476 | Qmax: 118.6212 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1477 | Qmax: 105.9052 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1478 | Qmax: 113.9896 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1479 | Qmax: 108.9434 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -10 | Episode: 1480 | Qmax: 112.1611 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1481 | Qmax: 109.4426 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1482 | Qmax: 122.1167 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1483 | Qmax: 118.6777 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1484 | Qmax: 114.5042 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1485 | Qmax: 103.5917 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1486 | Qmax: 119.4694 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -90 | Episode: 1487 | Qmax: 109.6213 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1488 | Qmax: 115.3606 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1489 | Qmax: 111.7871 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1490 | Qmax: 115.6230 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1491 | Qmax: 110.0892 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1492 | Qmax: 109.9781 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1493 | Qmax: 112.1886 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1494 | Qmax: 113.0205 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1495 | Qmax: 113.0124 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1496 | Qmax: 116.8862 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1497 | Qmax: 113.5411 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1498 | Qmax: 120.2884 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1499 | Qmax: 113.3215 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -20 | Episode: 1500 | Qmax: 108.2169 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1501 | Qmax: 118.6784 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1502 | Qmax: 103.9187 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1503 | Qmax: 118.2856 | Exploration: 0.019993 | Step: 10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: 0 | Episode: 1504 | Qmax: 112.8118 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1505 | Qmax: 113.5842 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1506 | Qmax: 98.0298 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -10 | Episode: 1507 | Qmax: 114.3578 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1508 | Qmax: 106.3711 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1509 | Qmax: 113.8986 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1510 | Qmax: 106.0812 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1511 | Qmax: 111.7235 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1512 | Qmax: 113.2483 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -170 | Episode: 1513 | Qmax: 113.1366 | Exploration: 0.019993 | Step: 9 \n",
      "| Reward: -70 | Episode: 1514 | Qmax: 116.1887 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1515 | Qmax: 110.4154 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1516 | Qmax: 113.5877 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1517 | Qmax: 110.3817 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -10 | Episode: 1518 | Qmax: 116.5717 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -70 | Episode: 1519 | Qmax: 105.7144 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: -90 | Episode: 1520 | Qmax: 105.4644 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1521 | Qmax: 115.3081 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1522 | Qmax: 104.1438 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1523 | Qmax: 115.7328 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1524 | Qmax: 115.2340 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1525 | Qmax: 110.9287 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: -10 | Episode: 1526 | Qmax: 109.4766 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1527 | Qmax: 111.1261 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1528 | Qmax: 107.4626 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1529 | Qmax: 115.8469 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1530 | Qmax: 112.2694 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1531 | Qmax: 105.9497 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1532 | Qmax: 117.0172 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: -70 | Episode: 1533 | Qmax: 99.6538 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1534 | Qmax: 106.4968 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1535 | Qmax: 125.1185 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1536 | Qmax: 126.4250 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1537 | Qmax: 120.2156 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1538 | Qmax: 119.4077 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1539 | Qmax: 110.6358 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -20 | Episode: 1540 | Qmax: 112.2573 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1541 | Qmax: 111.9345 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1542 | Qmax: 111.9292 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1543 | Qmax: 108.5231 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1544 | Qmax: 112.4687 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1545 | Qmax: 111.8954 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1546 | Qmax: 120.2502 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1547 | Qmax: 116.8904 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1548 | Qmax: 116.1279 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1549 | Qmax: 117.6709 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1550 | Qmax: 115.5897 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1551 | Qmax: 120.7290 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1552 | Qmax: 104.8489 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1553 | Qmax: 111.5529 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1554 | Qmax: 116.7808 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1555 | Qmax: 112.6394 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1556 | Qmax: 115.5549 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1557 | Qmax: 120.4487 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1558 | Qmax: 112.9654 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1559 | Qmax: 114.2194 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: -10 | Episode: 1560 | Qmax: 108.4580 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1561 | Qmax: 110.8409 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1562 | Qmax: 106.7570 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1563 | Qmax: 114.4678 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1564 | Qmax: 117.7369 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1565 | Qmax: 108.8514 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1566 | Qmax: 112.9844 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1567 | Qmax: 107.3349 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1568 | Qmax: 111.3541 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1569 | Qmax: 114.6372 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1570 | Qmax: 103.8021 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1571 | Qmax: 117.0575 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1572 | Qmax: 104.5805 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1573 | Qmax: 119.9050 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1574 | Qmax: 107.8254 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1575 | Qmax: 106.3229 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1576 | Qmax: 112.6811 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1577 | Qmax: 111.1154 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1578 | Qmax: 115.0286 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1579 | Qmax: 114.5753 | Exploration: 0.019993 | Step: 8 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1580 | Qmax: 113.0766 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1581 | Qmax: 111.7631 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1582 | Qmax: 110.8218 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1583 | Qmax: 113.1625 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1584 | Qmax: 114.0009 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1585 | Qmax: 106.4674 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1586 | Qmax: 110.8280 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1587 | Qmax: 112.3239 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1588 | Qmax: 114.2211 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1589 | Qmax: 112.0595 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1590 | Qmax: 111.7053 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -70 | Episode: 1591 | Qmax: 116.2483 | Exploration: 0.019993 | Step: 8 \n",
      "| Reward: 0 | Episode: 1592 | Qmax: 111.7552 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1593 | Qmax: 111.1365 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1594 | Qmax: 115.4508 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1595 | Qmax: 109.7086 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1596 | Qmax: 110.0762 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1597 | Qmax: 112.4193 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1598 | Qmax: 110.6549 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1599 | Qmax: 108.9198 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1600 | Qmax: 116.7640 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1601 | Qmax: 106.4191 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1602 | Qmax: 117.3320 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1603 | Qmax: 114.1365 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1604 | Qmax: 112.5772 | Exploration: 0.019993 | Step: 10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: 0 | Episode: 1605 | Qmax: 112.7617 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1606 | Qmax: 113.7121 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1607 | Qmax: 113.6037 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1608 | Qmax: 101.3825 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1609 | Qmax: 111.2286 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1610 | Qmax: 111.4104 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1611 | Qmax: 111.5500 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1612 | Qmax: 113.8309 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -10 | Episode: 1613 | Qmax: 115.9452 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1614 | Qmax: 116.3157 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1615 | Qmax: 114.8058 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1616 | Qmax: 118.6648 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1617 | Qmax: 110.7865 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1618 | Qmax: 115.5940 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1619 | Qmax: 106.5645 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1620 | Qmax: 110.7963 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1621 | Qmax: 109.2448 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1622 | Qmax: 105.9435 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1623 | Qmax: 113.8716 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1624 | Qmax: 110.5049 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1625 | Qmax: 109.9596 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1626 | Qmax: 116.5269 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1627 | Qmax: 105.2507 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1628 | Qmax: 113.6534 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1629 | Qmax: 110.8433 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1630 | Qmax: 107.7850 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1631 | Qmax: 113.4559 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1632 | Qmax: 111.9672 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1633 | Qmax: 115.5086 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1634 | Qmax: 111.7754 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1635 | Qmax: 117.3530 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1636 | Qmax: 109.5914 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1637 | Qmax: 115.7545 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1638 | Qmax: 111.3391 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1639 | Qmax: 108.1806 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1640 | Qmax: 109.1186 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1641 | Qmax: 110.0139 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1642 | Qmax: 115.1546 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1643 | Qmax: 112.9161 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1644 | Qmax: 111.7088 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1645 | Qmax: 108.4251 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1646 | Qmax: 108.2273 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1647 | Qmax: 106.8230 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1648 | Qmax: 104.8273 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1649 | Qmax: 106.5912 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1650 | Qmax: 111.8647 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1651 | Qmax: 109.0490 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1652 | Qmax: 112.4892 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1653 | Qmax: 114.6002 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1654 | Qmax: 112.2412 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1655 | Qmax: 115.4809 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1656 | Qmax: 109.2323 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -20 | Episode: 1657 | Qmax: 111.8687 | Exploration: 0.019993 | Step: 12 \n",
      "| Reward: 0 | Episode: 1658 | Qmax: 107.0714 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1659 | Qmax: 105.1701 | Exploration: 0.019993 | Step: 10 \n",
      "DDQN Saved\n",
      "| Reward: 0 | Episode: 1660 | Qmax: 107.2660 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1661 | Qmax: 111.1764 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1662 | Qmax: 108.9261 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1663 | Qmax: 106.7171 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1664 | Qmax: 111.4650 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1665 | Qmax: 109.6706 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1666 | Qmax: 114.8854 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1667 | Qmax: 111.4740 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1668 | Qmax: 109.4057 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1669 | Qmax: 115.9817 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: -10 | Episode: 1670 | Qmax: 116.3966 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: -10 | Episode: 1671 | Qmax: 111.7472 | Exploration: 0.019993 | Step: 11 \n",
      "| Reward: 0 | Episode: 1672 | Qmax: 114.3484 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1673 | Qmax: 115.4708 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1674 | Qmax: 100.0473 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1675 | Qmax: 113.1022 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1676 | Qmax: 114.4637 | Exploration: 0.019993 | Step: 10 \n",
      "| Reward: 0 | Episode: 1677 | Qmax: 102.1680 | Exploration: 0.019993 | Step: 10 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba843f01df8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mQnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTAU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMINIBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-07a1be2421e5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sess, env, qnet)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0msummary_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mep_ave_max_q\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0msummary_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEXPLORATION_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0msummary_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 })\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/d/DRA_Guide_Planning/qnetwork.pyc\u001b[0m in \u001b[0;36mget_learning_rate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config=tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "       \n",
    "    state_dim = 3\n",
    "    action_dim = 5\n",
    "    \n",
    "    if RESTORE:\n",
    "        Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR, DEVICE)\n",
    "        Qnet.saver.restore(sess, RESTORE_PATH)\n",
    "        train(sess, env, Qnet)\n",
    "        \n",
    "    else:\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "        env.seed(RANDOM_SEED)\n",
    "    \n",
    "        Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR, DEVICE)\n",
    "\n",
    "        train(sess, env, Qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_path(env, LTL, \"./saved_model/Mar_29_07-25_OR/ddqn.ckpt\", LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Opt_Policy = {}\n",
    "restore_path = \"./saved_model/Mar_17_04-08_10by10_dynamic_normal/ddqn.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "#     np.random.seed(RANDOM_SEED)\n",
    "#     tf.set_random_seed(RANDOM_SEED)\n",
    "#     env.seed(RANDOM_SEED)\n",
    "    \n",
    "    state_dim = 3\n",
    "    action_dim = env.nA\n",
    "    \n",
    "    Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, restore_path)\n",
    "    \n",
    "    for state in range(env.nS):\n",
    "        state_for_nn = np.array(np.unravel_index(state, env.shape)).reshape(1, state_dim)\n",
    "        action = Qnet.predict_a_from_save(state_for_nn, restore_path)\n",
    "        Opt_Policy[state] = action[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = {0: u\"\\u2191\", 1: u\"\\u2192\", 2: u\"\\u2193\", 3: u\"\\u2190\", 4: u\"\\u2613\"}\n",
    "worlds = [np.zeros((env.shape[0], env.shape[1])) for i in range(env.shape[2])]\n",
    "color_dict = {ap: color+1 for color, ap in enumerate(env.ap_dict.keys())}\n",
    "\n",
    "for world in worlds:\n",
    "    world[env.start_state[:-1]] = len(env.ap_dict) + 1\n",
    "    for i in env.coord_dict.keys():\n",
    "        if len(env.coord_dict[i]) >=1:\n",
    "            world[i] = color_dict[env.coord_dict[i][0]]\n",
    "            \n",
    "fig, ax = plt.subplots(2, int(np.ceil(len(worlds)/2)) )\n",
    "\n",
    "for i in range(len(worlds)):\n",
    "    index = np.unravel_index(i, (2, int( np.ceil(len(worlds)/2)) ) )\n",
    "    ax[index[0]][index[1]].imshow(worlds[i])\n",
    "    \n",
    "for k in range(len(worlds)):\n",
    "    index = np.unravel_index(k, (2, int(np.ceil(len(worlds)/2))))\n",
    "    for i in env.ap_dict.keys():\n",
    "        for j in env.ap_dict[i]:\n",
    "            ax[index[0]][index[1]].annotate(i, xy=(j[1] - 0.13, j[0] + 0.13), fontsize=5, color=(0,0,0))\n",
    "\n",
    "for i in range(len(worlds)):\n",
    "    index = np.unravel_index(i, (2, int(np.ceil(len(worlds)/2))))\n",
    "    ax[index[0]][index[1]].set_title(\"Rabin State = \" + str(i))\n",
    "    ax[index[0]][index[1]].annotate(\"R\", xy=(env.start_state[1] - 0.13, env.start_state[0] + 0.13), fontsize=5, color=(1,0,0))\n",
    "    for state, action in Opt_Policy.items():\n",
    "        state = np.unravel_index(state, env.shape)\n",
    "        if state[-1] == i:\n",
    "            ax[index[0]][index[1]].annotate(action_dict[action], xy=(state[1]-0.13, state[0]+0.13), fontsize=10, color=(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how many times LTL are violated in 100 runs -- Static Environment\n",
    "\n",
    "saved_path = \"./saved_model/Mar_16_21-59_10by10_indefinitely_run/ddqn.ckpt\"\n",
    "\n",
    "state_dim = 3\n",
    "action_dim = env.nA\n",
    "\n",
    "counter = 0\n",
    "\n",
    "c_coords = [np.ravel_multi_index(i, env.shape[:-1]) for i in env.ap_dict[\"C\"]]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, saved_path)\n",
    "    \n",
    "    for num_i in range(100):\n",
    "    \n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        for t in count():\n",
    "            state_1d = state\n",
    "            state = np.reshape(list(np.unravel_index(state, env.shape)), (1, state_dim))\n",
    "            state_for_plot = tuple(state[0][:2])\n",
    "            action = Qnet.predict_a_from_save(state, saved_path)\n",
    "            next_state,_,done,_ = env.step(action[0])\n",
    "            next_3d = np.unravel_index(next_state, env.shape)\n",
    "            next_2d = next_3d[:-1]\n",
    "            next_1d = np.ravel_multi_index(next_2d, env.shape[:-1])\n",
    "    #         render(env, state_for_plot, action[0])\n",
    "            if next_1d in c_coords:\n",
    "                counter += 1\n",
    "            state = next_state\n",
    "    #         if t%20 == 0:\n",
    "    #             plt.close(\"all\")\n",
    "            if done:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how many times LTL are violated in 100 runs -- Dynamic Environment\n",
    "\n",
    "saved_path = \"./saved_model/Mar_17_03-15_10by10_dyn_indefinite/ddqn.ckpt\"\n",
    "\n",
    "state_dim = 3\n",
    "action_dim = env.nA\n",
    "\n",
    "counter = 0\n",
    "\n",
    "c_coords = [np.ravel_multi_index(i, env.shape[:-1]) for i in env.ap_dict[\"C\"]]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, saved_path)\n",
    "    \n",
    "    for num_i in range(100):\n",
    "    \n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        for t in count():\n",
    "            state_1d = state\n",
    "            state = np.reshape(list(np.unravel_index(state, env.shape)), (1, state_dim))\n",
    "            state_for_plot = tuple(state[0][:2])\n",
    "            action = Qnet.predict_a_from_save(state, saved_path)\n",
    "            next_state,_,done,info = env.step(action[0])\n",
    "            next_3d = np.unravel_index(next_state, env.shape)\n",
    "            next_2d = next_3d[:-1]\n",
    "            next_1d = np.ravel_multi_index(next_2d, env.shape[:-1])\n",
    "    #         render(env, state_for_plot, action[0])\n",
    "            if next_1d in c_coords and info != \"disappear\":\n",
    "                counter += 1\n",
    "            state = next_state\n",
    "    #         if t%20 == 0:\n",
    "    #             plt.close(\"all\")\n",
    "            if done:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
