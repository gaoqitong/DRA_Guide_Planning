{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from full_prod_DRA import *\n",
    "from buchi import buchi_from_ltl\n",
    "import numpy as np\n",
    "from env_sensing_error import *\n",
    "import scipy\n",
    "# from plot_path_for_prod import *\n",
    "from graphviz import Source\n",
    "from qnetwork import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "# from Plot_Path import *\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from dra_planning import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, env, qnet, prod_planner):\n",
    "    \n",
    "    global EXPLORATION_RATE\n",
    "    global GUIDE_RATE\n",
    "  \n",
    "    summary_ops, summary_vars = build_summaries()\n",
    "    if not RESTORE:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(SUMMARY_DIR, sess.graph)\n",
    "    \n",
    "    qnet.update_target()\n",
    "    \n",
    "    replay_buffer = ReplayBuffer(BUFFER_SIZE, RANDOM_SEED)\n",
    "    \n",
    "    while len(prod_planner.opt_path) == 0:\n",
    "        env.step(np.random.randint(0,qnet.action_dim))\n",
    "        prod_planner.update_wfts_ap()\n",
    "        env.update_dynamic_rabin()\n",
    "        prod_planner.get_global_opt()\n",
    "    print \"Global Solution Found\"\n",
    "    prod_planner.get_opt_rabin()\n",
    "    \n",
    "    saved_dra_planners = {}\n",
    "    \n",
    "    for num_epi in range(MAX_EPISODES):\n",
    "        \n",
    "#         print \"Epi: \", num_epi\n",
    "\n",
    "        s = env.reset()\n",
    "        s = list(np.unravel_index(s, env.shape))\n",
    "#         prod_planner.replace_region_list()\n",
    "        prod_planner.update_wfts_ap()\n",
    "\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "        \n",
    "        reward_list = []\n",
    "        \n",
    "        train_time = 0\n",
    "        batch_time = 0\n",
    "        gym_time = 0\n",
    "        guide_time = 0\n",
    "\n",
    "        for j in range(MAX_EPISODE_LEN):\n",
    "            \n",
    "#             print \"Step: \", j\n",
    "            \n",
    "            gym_start = time.time()\n",
    "\n",
    "            rand_num = np.random.rand(1)\n",
    "    \n",
    "            if rand_num <= EXPLORATION_RATE:\n",
    "                a = np.random.randint(0,qnet.action_dim)\n",
    "                s2, r, terminal, info = env.step(a)\n",
    "                \n",
    "            elif rand_num <= GUIDE_RATE+EXPLORATION_RATE and rand_num > EXPLORATION_RATE:\n",
    "#                 print \"GUIDE\"\n",
    "                guide_start = time.time()\n",
    "                \n",
    "                if rand_num > EXPLORATION_RATE + 0.9*GUIDE_RATE:\n",
    "                # Only update global plan with 0.2 prob for efficiency\n",
    "                    env.update_dynamic_rabin()\n",
    "                    prod_planner.get_global_opt()\n",
    "                    prod_planner.get_opt_rabin()\n",
    "                    \n",
    "                if len(prod_planner.opt_path) > 0:\n",
    "#                     print \"S: \", s\n",
    "#                     print \"last a: \", a\n",
    "                    new_ltl = prod_planner.get_next_ltl(s[-1])\n",
    "                    \n",
    "#                     if new_ltl in saved_dra_planners.keys():\n",
    "                    guide_path = prod_planner.get_local_opt(s[:-1], new_ltl)\n",
    "                    if guide_path != None:\n",
    "#                         print \"GUIDE\"\n",
    "                        a = convert_path_to_action(guide_path)\n",
    "                    else:\n",
    "                        a = np.random.randint(0,qnet.action_dim)\n",
    "#                     else:\n",
    "#                         guide_path = prod_planner.get_local_opt(s[:-1], new_ltl)\n",
    "#                         saved_dra_planners[new_ltl] = prod_planner.dra_full_prod\n",
    "#                         if guide_path != None:\n",
    "#                             a = convert_path_to_action(guide_path)\n",
    "#                         else:\n",
    "#                             a = np.random.randint(0,qnet.action_dim)\n",
    "                        \n",
    "                else:\n",
    "                    a = np.random.randint(0,qnet.action_dim)\n",
    "                \n",
    "                s2, r, terminal, info = env.step(a)\n",
    "                \n",
    "                guide_time += time.time() - guide_start\n",
    "                \n",
    "            else:\n",
    "                a = np.argmax(qnet.predict_q(np.reshape(s, (1, qnet.state_dim))))\n",
    "                s2, r, terminal, info = env.step(a)\n",
    "\n",
    "            prod_planner.update_wfts_ap()\n",
    "                \n",
    "            gym_time += time.time() - gym_start\n",
    "            \n",
    "            batch_start = time.time()\n",
    "            \n",
    "            s2 = list(np.unravel_index(s2, env.shape))\n",
    "\n",
    "            replay_buffer.add(np.reshape(s, (qnet.state_dim,)), np.reshape(a, (1,)), r,\n",
    "                              terminal, np.reshape(s2, (qnet.state_dim,)))\n",
    "            batch_time += time.time() - batch_start\n",
    "\n",
    "            # Keep adding experience to the memory until\n",
    "            # there are at least minibatch size samples\n",
    "            if replay_buffer.size() > MINIBATCH_SIZE:\n",
    "                \n",
    "                batch_start = time.time()\n",
    "                s_batch, a_batch, r_batch, t_batch, s2_batch = replay_buffer.sample_batch(MINIBATCH_SIZE)\n",
    "#                 print \"sbatch: \", s_batch\n",
    "                # Calculate targets\n",
    "                target_q = qnet.predect_target(s2_batch)\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(MINIBATCH_SIZE):\n",
    "                    if t_batch[k]:\n",
    "                        y_i.append(r_batch[k])\n",
    "                    else:\n",
    "                        y_i.append(r_batch[k] + GAMMA * np.amax(target_q[k]))\n",
    "                        \n",
    "                batch_time += time.time() - batch_start\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                train_start = time.time()\n",
    "                predicted_q_value, _ = qnet.train(s_batch, a_batch, np.reshape(y_i, (MINIBATCH_SIZE, 1)), num_epi)\n",
    "\n",
    "                ep_ave_max_q += np.amax(predicted_q_value)\n",
    "                \n",
    "                # Update target networks\n",
    "                qnet.update_target()\n",
    "\n",
    "                train_time += time.time() - train_start\n",
    "\n",
    "            s = s2\n",
    "            ep_reward += r\n",
    "\n",
    "            if terminal or j == MAX_EPISODE_LEN-1:\n",
    "                \n",
    "                if EXPLORATION_RATE > 0.02 and terminal:\n",
    "                    EXPLORATION_RATE = EXPLORATION_RATE*0.999\n",
    "                if GUIDE_RATE > 0.05 and terminal:\n",
    "                    GUIDE_RATE = GUIDE_RATE*0.999\n",
    "                    \n",
    "                reward_list += [ep_reward]\n",
    "                \n",
    "                if np.average(reward_list[-10:]) > LR_DECAY_TRUNCATION:\n",
    "                    qnet.decay_learning_rate(0.98)\n",
    "\n",
    "                print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f} | Exploration: {:.6f} | Step: {:d} | LR: {:.8f}'.format(int(ep_reward), \\\n",
    "                        num_epi, (ep_ave_max_q / float(j)), EXPLORATION_RATE, j, qnet.get_learning_rate()))\n",
    "                \n",
    "                f = open(\"stats/\" + file_appendix + \"_stats.txt\", \"ab\")\n",
    "                f.write(\"| Reward: \" + str(int(ep_reward)) \n",
    "                        +\" | Episode: \" + str(num_epi) \n",
    "                        + \" | Qmax: \" + str(ep_ave_max_q / float(j)) \n",
    "                        + \" | Exploration: \" + str(EXPLORATION_RATE)\n",
    "                        + \" | Step: \" + str(j)\n",
    "                        + \" | LR:\" + str(qnet.get_learning_rate()) + \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                f = open(\"stats/\" + file_appendix + \"_stats_time.txt\", \"ab\")\n",
    "                f.write(\" | Episode: \" + str(num_epi) \n",
    "                        + \" | Train: \" + str(train_time) \n",
    "                        + \" | Gym: \" + str(gym_time)\n",
    "                        + \" | Batch: \" + str(batch_time) \n",
    "                        + \" | Guide: \" + str(guide_time)\n",
    "                        + \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B\"\n",
    "# LTL = \"[] (p1 -> !(X p1) U (p2 || p3) ) && []<>p1\"\n",
    "# LTL = \"T && []<>A && []<>B\"\n",
    "# LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B && []!C && []!D\"\n",
    "LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B && []!C\"\n",
    "# LTL = \"<>(A && <>(B && <> T))\"\n",
    "# LTL = \"<>(A && <>B) && <>[]T && []!C\"\n",
    "# LTL = \"<>(A && <>T) && []!C\"\n",
    "# LTL = \"<>(A && <>(B && <>T)) && []<>(A||T) && []<>B && []!C\"\n",
    "# LTL = \"<>(A && <>(B && <>T)) && []!C\"\n",
    "# LTL = \"<>(A && <>D) && <>(B && <>E) && []<>T && []<>(D || E) && []!C\"\n",
    "\n",
    "LEARNING_RATE = 0.0015\n",
    "GAMMA = 0.99\n",
    "# GAMMA = 0.7\n",
    "TAU = 0.001\n",
    "BUFFER_SIZE = 10**6\n",
    "MINIBATCH_SIZE = 64\n",
    "RANDOM_SEED = 210\n",
    "MAX_EPISODES = 50000\n",
    "MAX_EPISODE_LEN = 1000\n",
    "# file_appendix = \"Guide_Planning_\" + time.ctime()[4:16].replace(\"  \",\"\").replace(\" \",\"_\").replace(\":\",\"-\") + \"_large_\" + LTL\n",
    "file_appendix = \"Guide_Planning_Medium_Mar_6_morning\"\n",
    "SUMMARY_DIR = './results/tf_ddqn_' + file_appendix\n",
    "SAVE_DIR = \"./saved_model/\" + file_appendix + \"/ddqn.ckpt\"\n",
    "EXPLORATION_RATE = 0.2\n",
    "GUIDE_RATE = 0.6\n",
    "LR_DECAY_TRUNCATION = -350\n",
    "RESTORE = 1\n",
    "RESTORE_PATH = \"./saved_model/Guide_Planning_Mar6_16-28_large_A_T_NotC/ddqn.ckpt\"\n",
    "if sys.platform == \"darwin\":\n",
    "    DEVICE = \"/device:CPU:0\"\n",
    "else:\n",
    "    DEVICE = \"/device:GPU:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = CurrentWorld(LTL)\n",
    "prod_planner = Prod_Planning(env, LTL)\n",
    "# with open(\"my.dot\", \"r\") as dotfile:\n",
    "#     text = dotfile.read()\n",
    "# Source(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/Guide_Planning_Mar6_16-28_large_A_T_NotC/ddqn.ckpt\n",
      "Global Solution Found\n",
      "DDQN Saved\n",
      "| Reward: -2294 | Episode: 0 | Qmax: 126.4919 | Exploration: 0.199800 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -2879 | Episode: 1 | Qmax: 263.6668 | Exploration: 0.199600 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -4331 | Episode: 2 | Qmax: 264.5301 | Exploration: 0.199401 | Step: 273 | LR: 0.00150000\n",
      "| Reward: -2392 | Episode: 3 | Qmax: 265.4137 | Exploration: 0.199201 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -2468 | Episode: 4 | Qmax: 266.0963 | Exploration: 0.199002 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -2589 | Episode: 5 | Qmax: 267.6059 | Exploration: 0.198803 | Step: 160 | LR: 0.00150000\n",
      "| Reward: -4488 | Episode: 6 | Qmax: 268.1441 | Exploration: 0.198604 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -2977 | Episode: 7 | Qmax: 268.3345 | Exploration: 0.198406 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -2814 | Episode: 8 | Qmax: 268.4809 | Exploration: 0.198207 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -1866 | Episode: 9 | Qmax: 270.2187 | Exploration: 0.198009 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -2326 | Episode: 10 | Qmax: 268.3755 | Exploration: 0.197811 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -4416 | Episode: 11 | Qmax: 267.9506 | Exploration: 0.197613 | Step: 322 | LR: 0.00150000\n",
      "| Reward: -2924 | Episode: 12 | Qmax: 268.9162 | Exploration: 0.197416 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -2687 | Episode: 13 | Qmax: 270.0371 | Exploration: 0.197218 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -2948 | Episode: 14 | Qmax: 269.0745 | Exploration: 0.197021 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -2105 | Episode: 15 | Qmax: 269.1293 | Exploration: 0.196824 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -2538 | Episode: 16 | Qmax: 267.8875 | Exploration: 0.196627 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -1743 | Episode: 17 | Qmax: 269.5528 | Exploration: 0.196430 | Step: 169 | LR: 0.00150000\n",
      "| Reward: -2622 | Episode: 18 | Qmax: 269.6290 | Exploration: 0.196234 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -3379 | Episode: 19 | Qmax: 269.2704 | Exploration: 0.196038 | Step: 293 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3435 | Episode: 20 | Qmax: 270.3838 | Exploration: 0.195842 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -2459 | Episode: 21 | Qmax: 270.8812 | Exploration: 0.195646 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -2749 | Episode: 22 | Qmax: 272.3388 | Exploration: 0.195450 | Step: 239 | LR: 0.00150000\n",
      "| Reward: -3574 | Episode: 23 | Qmax: 273.7721 | Exploration: 0.195255 | Step: 317 | LR: 0.00150000\n",
      "| Reward: -2966 | Episode: 24 | Qmax: 273.3042 | Exploration: 0.195060 | Step: 321 | LR: 0.00150000\n",
      "| Reward: -2182 | Episode: 25 | Qmax: 273.9753 | Exploration: 0.194864 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -1886 | Episode: 26 | Qmax: 273.6368 | Exploration: 0.194670 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -2239 | Episode: 27 | Qmax: 274.1971 | Exploration: 0.194475 | Step: 143 | LR: 0.00150000\n",
      "| Reward: -4062 | Episode: 28 | Qmax: 273.6674 | Exploration: 0.194280 | Step: 301 | LR: 0.00150000\n",
      "| Reward: -2080 | Episode: 29 | Qmax: 274.8753 | Exploration: 0.194086 | Step: 155 | LR: 0.00150000\n",
      "| Reward: -1679 | Episode: 30 | Qmax: 276.5875 | Exploration: 0.193892 | Step: 123 | LR: 0.00150000\n",
      "| Reward: -2395 | Episode: 31 | Qmax: 274.6937 | Exploration: 0.193698 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -4188 | Episode: 32 | Qmax: 274.3781 | Exploration: 0.193505 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -2780 | Episode: 33 | Qmax: 275.3126 | Exploration: 0.193311 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -3824 | Episode: 35 | Qmax: 274.5783 | Exploration: 0.192925 | Step: 342 | LR: 0.00150000\n",
      "| Reward: -3110 | Episode: 36 | Qmax: 272.2456 | Exploration: 0.192732 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -2252 | Episode: 37 | Qmax: 274.1871 | Exploration: 0.192539 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -2545 | Episode: 38 | Qmax: 272.6951 | Exploration: 0.192346 | Step: 179 | LR: 0.00150000\n",
      "| Reward: -3456 | Episode: 39 | Qmax: 273.7170 | Exploration: 0.192154 | Step: 190 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1594 | Episode: 40 | Qmax: 273.5044 | Exploration: 0.191962 | Step: 173 | LR: 0.00150000\n",
      "| Reward: -3113 | Episode: 41 | Qmax: 273.5455 | Exploration: 0.191770 | Step: 279 | LR: 0.00150000\n",
      "| Reward: -2061 | Episode: 42 | Qmax: 273.7489 | Exploration: 0.191578 | Step: 154 | LR: 0.00150000\n",
      "| Reward: -2681 | Episode: 43 | Qmax: 273.3383 | Exploration: 0.191387 | Step: 180 | LR: 0.00150000\n",
      "| Reward: -2184 | Episode: 44 | Qmax: 273.0883 | Exploration: 0.191195 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1959 | Episode: 45 | Qmax: 273.9806 | Exploration: 0.191004 | Step: 160 | LR: 0.00150000\n",
      "| Reward: -2749 | Episode: 46 | Qmax: 273.9720 | Exploration: 0.190813 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -3283 | Episode: 47 | Qmax: 274.0206 | Exploration: 0.190622 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -2132 | Episode: 48 | Qmax: 273.8393 | Exploration: 0.190432 | Step: 180 | LR: 0.00150000\n",
      "| Reward: -2961 | Episode: 49 | Qmax: 272.2043 | Exploration: 0.190241 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -1940 | Episode: 50 | Qmax: 272.7717 | Exploration: 0.190051 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -3484 | Episode: 51 | Qmax: 273.5670 | Exploration: 0.189861 | Step: 209 | LR: 0.00150000\n",
      "| Reward: -2981 | Episode: 52 | Qmax: 273.9348 | Exploration: 0.189671 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -3245 | Episode: 53 | Qmax: 273.6389 | Exploration: 0.189481 | Step: 303 | LR: 0.00150000\n",
      "| Reward: -3030 | Episode: 54 | Qmax: 274.8877 | Exploration: 0.189292 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -2712 | Episode: 55 | Qmax: 275.0604 | Exploration: 0.189103 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -2741 | Episode: 56 | Qmax: 276.6294 | Exploration: 0.188913 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -3598 | Episode: 57 | Qmax: 275.1711 | Exploration: 0.188725 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -2619 | Episode: 58 | Qmax: 275.7811 | Exploration: 0.188536 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -1575 | Episode: 59 | Qmax: 275.3109 | Exploration: 0.188347 | Step: 181 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3249 | Episode: 60 | Qmax: 274.3851 | Exploration: 0.188159 | Step: 307 | LR: 0.00150000\n",
      "| Reward: -2348 | Episode: 61 | Qmax: 276.3082 | Exploration: 0.187971 | Step: 153 | LR: 0.00150000\n",
      "| Reward: -3189 | Episode: 62 | Qmax: 274.0096 | Exploration: 0.187783 | Step: 274 | LR: 0.00150000\n",
      "| Reward: -2160 | Episode: 63 | Qmax: 275.6206 | Exploration: 0.187595 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -2145 | Episode: 64 | Qmax: 277.0636 | Exploration: 0.187407 | Step: 202 | LR: 0.00150000\n",
      "| Reward: -2339 | Episode: 65 | Qmax: 276.0931 | Exploration: 0.187220 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -3502 | Episode: 66 | Qmax: 276.3202 | Exploration: 0.187033 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -3858 | Episode: 67 | Qmax: 276.1686 | Exploration: 0.186846 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -3160 | Episode: 68 | Qmax: 276.5986 | Exploration: 0.186659 | Step: 281 | LR: 0.00150000\n",
      "| Reward: -1896 | Episode: 69 | Qmax: 275.2838 | Exploration: 0.186472 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -2044 | Episode: 70 | Qmax: 275.3960 | Exploration: 0.186286 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -3622 | Episode: 71 | Qmax: 275.3156 | Exploration: 0.186099 | Step: 239 | LR: 0.00150000\n",
      "| Reward: -1867 | Episode: 72 | Qmax: 276.4262 | Exploration: 0.185913 | Step: 257 | LR: 0.00150000\n",
      "| Reward: -2125 | Episode: 73 | Qmax: 275.7497 | Exploration: 0.185727 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -2925 | Episode: 74 | Qmax: 276.5222 | Exploration: 0.185542 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -4168 | Episode: 75 | Qmax: 276.4863 | Exploration: 0.185356 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -2431 | Episode: 76 | Qmax: 278.3469 | Exploration: 0.185171 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -3042 | Episode: 77 | Qmax: 277.5976 | Exploration: 0.184986 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -3861 | Episode: 78 | Qmax: 278.4681 | Exploration: 0.184801 | Step: 280 | LR: 0.00150000\n",
      "| Reward: -2430 | Episode: 79 | Qmax: 277.0243 | Exploration: 0.184616 | Step: 190 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2351 | Episode: 80 | Qmax: 279.3097 | Exploration: 0.184431 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -2957 | Episode: 81 | Qmax: 278.5168 | Exploration: 0.184247 | Step: 258 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2697 | Episode: 82 | Qmax: 281.0810 | Exploration: 0.184063 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -2180 | Episode: 83 | Qmax: 278.7770 | Exploration: 0.183879 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -2766 | Episode: 84 | Qmax: 279.7465 | Exploration: 0.183695 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -4451 | Episode: 85 | Qmax: 281.1395 | Exploration: 0.183511 | Step: 339 | LR: 0.00150000\n",
      "| Reward: -1772 | Episode: 86 | Qmax: 279.4072 | Exploration: 0.183327 | Step: 162 | LR: 0.00150000\n",
      "| Reward: -2864 | Episode: 87 | Qmax: 279.8727 | Exploration: 0.183144 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -2392 | Episode: 88 | Qmax: 280.2424 | Exploration: 0.182961 | Step: 206 | LR: 0.00150000\n",
      "| Reward: -2314 | Episode: 89 | Qmax: 281.7940 | Exploration: 0.182778 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -2912 | Episode: 90 | Qmax: 280.8767 | Exploration: 0.182595 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -2907 | Episode: 91 | Qmax: 281.9881 | Exploration: 0.182413 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -2192 | Episode: 92 | Qmax: 282.4712 | Exploration: 0.182230 | Step: 240 | LR: 0.00150000\n",
      "| Reward: -2218 | Episode: 93 | Qmax: 281.6690 | Exploration: 0.182048 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -2091 | Episode: 94 | Qmax: 284.0154 | Exploration: 0.181866 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -2638 | Episode: 95 | Qmax: 284.8388 | Exploration: 0.181684 | Step: 173 | LR: 0.00150000\n",
      "| Reward: -2608 | Episode: 96 | Qmax: 285.3617 | Exploration: 0.181502 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -2082 | Episode: 97 | Qmax: 284.7166 | Exploration: 0.181321 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -3031 | Episode: 98 | Qmax: 285.8508 | Exploration: 0.181140 | Step: 161 | LR: 0.00150000\n",
      "| Reward: -2994 | Episode: 99 | Qmax: 284.5329 | Exploration: 0.180958 | Step: 349 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2294 | Episode: 100 | Qmax: 287.7592 | Exploration: 0.180777 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -4295 | Episode: 101 | Qmax: 285.7962 | Exploration: 0.180597 | Step: 363 | LR: 0.00150000\n",
      "| Reward: -2890 | Episode: 102 | Qmax: 289.7922 | Exploration: 0.180416 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -2314 | Episode: 103 | Qmax: 288.5845 | Exploration: 0.180236 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -3262 | Episode: 104 | Qmax: 290.4963 | Exploration: 0.180055 | Step: 293 | LR: 0.00150000\n",
      "| Reward: -2945 | Episode: 105 | Qmax: 290.8846 | Exploration: 0.179875 | Step: 201 | LR: 0.00150000\n",
      "| Reward: -2357 | Episode: 106 | Qmax: 291.7701 | Exploration: 0.179696 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1744 | Episode: 107 | Qmax: 293.6349 | Exploration: 0.179516 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -1986 | Episode: 108 | Qmax: 295.6934 | Exploration: 0.179336 | Step: 151 | LR: 0.00150000\n",
      "| Reward: -2491 | Episode: 109 | Qmax: 296.1035 | Exploration: 0.179157 | Step: 170 | LR: 0.00150000\n",
      "| Reward: -2728 | Episode: 110 | Qmax: 294.1967 | Exploration: 0.178978 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -1954 | Episode: 111 | Qmax: 296.6936 | Exploration: 0.178799 | Step: 128 | LR: 0.00150000\n",
      "| Reward: -2999 | Episode: 112 | Qmax: 294.4277 | Exploration: 0.178620 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -1618 | Episode: 113 | Qmax: 297.7999 | Exploration: 0.178441 | Step: 152 | LR: 0.00150000\n",
      "| Reward: -3286 | Episode: 114 | Qmax: 296.2120 | Exploration: 0.178263 | Step: 326 | LR: 0.00150000\n",
      "| Reward: -1539 | Episode: 115 | Qmax: 298.6978 | Exploration: 0.178085 | Step: 136 | LR: 0.00150000\n",
      "| Reward: -1997 | Episode: 116 | Qmax: 298.8126 | Exploration: 0.177907 | Step: 162 | LR: 0.00150000\n",
      "| Reward: -2250 | Episode: 117 | Qmax: 299.2167 | Exploration: 0.177729 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1378 | Episode: 118 | Qmax: 300.0516 | Exploration: 0.177551 | Step: 128 | LR: 0.00150000\n",
      "| Reward: -2473 | Episode: 119 | Qmax: 302.6107 | Exploration: 0.177373 | Step: 170 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2450 | Episode: 120 | Qmax: 301.9041 | Exploration: 0.177196 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -3946 | Episode: 121 | Qmax: 301.1896 | Exploration: 0.177019 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -3405 | Episode: 122 | Qmax: 302.4453 | Exploration: 0.176842 | Step: 274 | LR: 0.00150000\n",
      "| Reward: -3303 | Episode: 123 | Qmax: 302.3665 | Exploration: 0.176665 | Step: 298 | LR: 0.00150000\n",
      "| Reward: -3698 | Episode: 124 | Qmax: 305.3867 | Exploration: 0.176488 | Step: 234 | LR: 0.00150000\n",
      "| Reward: -2309 | Episode: 125 | Qmax: 303.8635 | Exploration: 0.176312 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -3298 | Episode: 126 | Qmax: 307.0241 | Exploration: 0.176136 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -2679 | Episode: 127 | Qmax: 306.0078 | Exploration: 0.175959 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -2610 | Episode: 128 | Qmax: 307.5273 | Exploration: 0.175783 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -1776 | Episode: 129 | Qmax: 306.8112 | Exploration: 0.175608 | Step: 193 | LR: 0.00150000\n",
      "| Reward: -2700 | Episode: 130 | Qmax: 308.3814 | Exploration: 0.175432 | Step: 325 | LR: 0.00150000\n",
      "| Reward: -3979 | Episode: 131 | Qmax: 309.5851 | Exploration: 0.175257 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -2997 | Episode: 132 | Qmax: 311.8690 | Exploration: 0.175081 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -3550 | Episode: 133 | Qmax: 312.8978 | Exploration: 0.174906 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -3474 | Episode: 134 | Qmax: 311.8931 | Exploration: 0.174731 | Step: 298 | LR: 0.00150000\n",
      "| Reward: -3523 | Episode: 135 | Qmax: 313.5967 | Exploration: 0.174557 | Step: 311 | LR: 0.00150000\n",
      "| Reward: -1741 | Episode: 136 | Qmax: 314.7905 | Exploration: 0.174382 | Step: 167 | LR: 0.00150000\n",
      "| Reward: -3929 | Episode: 137 | Qmax: 314.9360 | Exploration: 0.174208 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -1989 | Episode: 138 | Qmax: 315.8082 | Exploration: 0.174034 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -2862 | Episode: 139 | Qmax: 314.9836 | Exploration: 0.173859 | Step: 199 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3446 | Episode: 140 | Qmax: 316.0251 | Exploration: 0.173686 | Step: 288 | LR: 0.00150000\n",
      "| Reward: -2977 | Episode: 141 | Qmax: 317.2809 | Exploration: 0.173512 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -4192 | Episode: 142 | Qmax: 318.8876 | Exploration: 0.173338 | Step: 521 | LR: 0.00150000\n",
      "| Reward: -2484 | Episode: 143 | Qmax: 318.5421 | Exploration: 0.173165 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -3375 | Episode: 144 | Qmax: 319.2978 | Exploration: 0.172992 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -3034 | Episode: 145 | Qmax: 320.8017 | Exploration: 0.172819 | Step: 281 | LR: 0.00150000\n",
      "| Reward: -4163 | Episode: 146 | Qmax: 322.2961 | Exploration: 0.172646 | Step: 285 | LR: 0.00150000\n",
      "| Reward: -2859 | Episode: 147 | Qmax: 322.0180 | Exploration: 0.172473 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -2872 | Episode: 148 | Qmax: 321.3866 | Exploration: 0.172301 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -3731 | Episode: 149 | Qmax: 323.9693 | Exploration: 0.172129 | Step: 276 | LR: 0.00150000\n",
      "| Reward: -5458 | Episode: 150 | Qmax: 321.8764 | Exploration: 0.171957 | Step: 464 | LR: 0.00150000\n",
      "| Reward: -2577 | Episode: 151 | Qmax: 324.4241 | Exploration: 0.171785 | Step: 202 | LR: 0.00150000\n",
      "| Reward: -2199 | Episode: 152 | Qmax: 326.3724 | Exploration: 0.171613 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -2792 | Episode: 153 | Qmax: 326.7153 | Exploration: 0.171441 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1674 | Episode: 154 | Qmax: 327.0682 | Exploration: 0.171270 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -2681 | Episode: 155 | Qmax: 325.7145 | Exploration: 0.171098 | Step: 243 | LR: 0.00150000\n",
      "| Reward: -1866 | Episode: 156 | Qmax: 329.8078 | Exploration: 0.170927 | Step: 148 | LR: 0.00150000\n",
      "| Reward: -3069 | Episode: 157 | Qmax: 328.6299 | Exploration: 0.170756 | Step: 271 | LR: 0.00150000\n",
      "| Reward: -2194 | Episode: 158 | Qmax: 329.2529 | Exploration: 0.170586 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1730 | Episode: 159 | Qmax: 329.2508 | Exploration: 0.170415 | Step: 264 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3370 | Episode: 160 | Qmax: 330.0101 | Exploration: 0.170245 | Step: 284 | LR: 0.00150000\n",
      "| Reward: -1833 | Episode: 161 | Qmax: 331.4098 | Exploration: 0.170074 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -3536 | Episode: 162 | Qmax: 334.6627 | Exploration: 0.169904 | Step: 288 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -3727 | Episode: 163 | Qmax: 335.8323 | Exploration: 0.169734 | Step: 389 | LR: 0.00150000\n",
      "| Reward: -1819 | Episode: 164 | Qmax: 336.7920 | Exploration: 0.169565 | Step: 209 | LR: 0.00150000\n",
      "| Reward: -3269 | Episode: 165 | Qmax: 339.1721 | Exploration: 0.169395 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -3529 | Episode: 166 | Qmax: 339.9843 | Exploration: 0.169226 | Step: 326 | LR: 0.00150000\n",
      "| Reward: -2164 | Episode: 167 | Qmax: 341.8018 | Exploration: 0.169057 | Step: 158 | LR: 0.00150000\n",
      "| Reward: -3330 | Episode: 168 | Qmax: 340.0956 | Exploration: 0.168887 | Step: 352 | LR: 0.00150000\n",
      "| Reward: -2422 | Episode: 169 | Qmax: 342.9510 | Exploration: 0.168719 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -9721 | Episode: 170 | Qmax: 341.3481 | Exploration: 0.168550 | Step: 893 | LR: 0.00150000\n",
      "| Reward: -1540 | Episode: 171 | Qmax: 345.2976 | Exploration: 0.168381 | Step: 128 | LR: 0.00150000\n",
      "| Reward: -2411 | Episode: 172 | Qmax: 345.8636 | Exploration: 0.168213 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -3257 | Episode: 173 | Qmax: 344.2844 | Exploration: 0.168045 | Step: 450 | LR: 0.00150000\n",
      "| Reward: -2337 | Episode: 174 | Qmax: 346.1122 | Exploration: 0.167877 | Step: 286 | LR: 0.00150000\n",
      "| Reward: -4462 | Episode: 175 | Qmax: 347.4298 | Exploration: 0.167709 | Step: 413 | LR: 0.00150000\n",
      "| Reward: -2026 | Episode: 176 | Qmax: 346.9036 | Exploration: 0.167541 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -1965 | Episode: 177 | Qmax: 347.4551 | Exploration: 0.167374 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -3863 | Episode: 178 | Qmax: 346.8637 | Exploration: 0.167206 | Step: 462 | LR: 0.00150000\n",
      "| Reward: -2417 | Episode: 179 | Qmax: 347.1281 | Exploration: 0.167039 | Step: 240 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -6101 | Episode: 180 | Qmax: 347.1138 | Exploration: 0.166872 | Step: 513 | LR: 0.00150000\n",
      "| Reward: -4314 | Episode: 181 | Qmax: 346.8177 | Exploration: 0.166705 | Step: 463 | LR: 0.00150000\n",
      "| Reward: -2364 | Episode: 182 | Qmax: 346.6517 | Exploration: 0.166538 | Step: 421 | LR: 0.00150000\n",
      "| Reward: -3018 | Episode: 183 | Qmax: 347.2097 | Exploration: 0.166372 | Step: 409 | LR: 0.00150000\n",
      "| Reward: -4291 | Episode: 184 | Qmax: 345.8003 | Exploration: 0.166205 | Step: 350 | LR: 0.00150000\n",
      "| Reward: -3347 | Episode: 185 | Qmax: 346.8348 | Exploration: 0.166039 | Step: 585 | LR: 0.00150000\n",
      "| Reward: -3103 | Episode: 186 | Qmax: 345.8383 | Exploration: 0.165873 | Step: 341 | LR: 0.00150000\n",
      "| Reward: -3032 | Episode: 187 | Qmax: 347.6445 | Exploration: 0.165707 | Step: 243 | LR: 0.00150000\n",
      "| Reward: -2336 | Episode: 188 | Qmax: 346.5297 | Exploration: 0.165542 | Step: 321 | LR: 0.00150000\n",
      "| Reward: -1862 | Episode: 189 | Qmax: 347.7105 | Exploration: 0.165376 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -4896 | Episode: 190 | Qmax: 347.7599 | Exploration: 0.165211 | Step: 388 | LR: 0.00150000\n",
      "| Reward: -3934 | Episode: 191 | Qmax: 349.0009 | Exploration: 0.165046 | Step: 380 | LR: 0.00150000\n",
      "| Reward: -6863 | Episode: 192 | Qmax: 350.0881 | Exploration: 0.164880 | Step: 555 | LR: 0.00150000\n",
      "| Reward: -3492 | Episode: 193 | Qmax: 352.9721 | Exploration: 0.164716 | Step: 424 | LR: 0.00150000\n",
      "| Reward: -3587 | Episode: 194 | Qmax: 355.4368 | Exploration: 0.164551 | Step: 384 | LR: 0.00150000\n",
      "| Reward: -3348 | Episode: 195 | Qmax: 355.9926 | Exploration: 0.164386 | Step: 325 | LR: 0.00150000\n",
      "| Reward: -4672 | Episode: 196 | Qmax: 356.2975 | Exploration: 0.164222 | Step: 380 | LR: 0.00150000\n",
      "| Reward: -3844 | Episode: 197 | Qmax: 357.3021 | Exploration: 0.164058 | Step: 308 | LR: 0.00150000\n",
      "| Reward: -2423 | Episode: 198 | Qmax: 358.0754 | Exploration: 0.163894 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -3399 | Episode: 199 | Qmax: 359.3632 | Exploration: 0.163730 | Step: 322 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2264 | Episode: 200 | Qmax: 360.4120 | Exploration: 0.163566 | Step: 321 | LR: 0.00150000\n",
      "| Reward: -3091 | Episode: 201 | Qmax: 361.1123 | Exploration: 0.163402 | Step: 293 | LR: 0.00150000\n",
      "| Reward: -2498 | Episode: 202 | Qmax: 360.6988 | Exploration: 0.163239 | Step: 294 | LR: 0.00150000\n",
      "| Reward: -3074 | Episode: 203 | Qmax: 361.6717 | Exploration: 0.163076 | Step: 285 | LR: 0.00150000\n",
      "| Reward: -3340 | Episode: 204 | Qmax: 365.6458 | Exploration: 0.162913 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -3362 | Episode: 205 | Qmax: 363.2303 | Exploration: 0.162750 | Step: 339 | LR: 0.00150000\n",
      "| Reward: -2738 | Episode: 206 | Qmax: 364.6888 | Exploration: 0.162587 | Step: 291 | LR: 0.00150000\n",
      "| Reward: -2996 | Episode: 207 | Qmax: 365.8003 | Exploration: 0.162425 | Step: 243 | LR: 0.00150000\n",
      "| Reward: -1807 | Episode: 208 | Qmax: 365.7294 | Exploration: 0.162262 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -2600 | Episode: 209 | Qmax: 367.3910 | Exploration: 0.162100 | Step: 342 | LR: 0.00150000\n",
      "| Reward: -2280 | Episode: 210 | Qmax: 367.7221 | Exploration: 0.161938 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -2479 | Episode: 211 | Qmax: 369.3171 | Exploration: 0.161776 | Step: 320 | LR: 0.00150000\n",
      "| Reward: -2533 | Episode: 212 | Qmax: 369.6753 | Exploration: 0.161614 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -2245 | Episode: 213 | Qmax: 369.7344 | Exploration: 0.161452 | Step: 167 | LR: 0.00150000\n",
      "| Reward: -2705 | Episode: 214 | Qmax: 370.6161 | Exploration: 0.161291 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -2073 | Episode: 215 | Qmax: 371.3291 | Exploration: 0.161130 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -2032 | Episode: 216 | Qmax: 370.0544 | Exploration: 0.160969 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -2988 | Episode: 217 | Qmax: 370.8937 | Exploration: 0.160808 | Step: 433 | LR: 0.00150000\n",
      "| Reward: -2604 | Episode: 218 | Qmax: 369.8274 | Exploration: 0.160647 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -1549 | Episode: 219 | Qmax: 372.0061 | Exploration: 0.160486 | Step: 137 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2209 | Episode: 220 | Qmax: 373.0381 | Exploration: 0.160326 | Step: 446 | LR: 0.00150000\n",
      "| Reward: -3445 | Episode: 221 | Qmax: 371.8538 | Exploration: 0.160165 | Step: 332 | LR: 0.00150000\n",
      "| Reward: -3671 | Episode: 222 | Qmax: 373.6909 | Exploration: 0.160005 | Step: 405 | LR: 0.00150000\n",
      "| Reward: -2140 | Episode: 223 | Qmax: 375.7475 | Exploration: 0.159845 | Step: 341 | LR: 0.00150000\n",
      "| Reward: -3683 | Episode: 224 | Qmax: 375.0961 | Exploration: 0.159685 | Step: 471 | LR: 0.00150000\n",
      "| Reward: -3178 | Episode: 225 | Qmax: 375.5600 | Exploration: 0.159526 | Step: 362 | LR: 0.00150000\n",
      "| Reward: -2188 | Episode: 226 | Qmax: 377.2117 | Exploration: 0.159366 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -2573 | Episode: 227 | Qmax: 375.8096 | Exploration: 0.159207 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -2220 | Episode: 228 | Qmax: 375.5696 | Exploration: 0.159047 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -2929 | Episode: 229 | Qmax: 377.8126 | Exploration: 0.158888 | Step: 284 | LR: 0.00150000\n",
      "| Reward: -1648 | Episode: 230 | Qmax: 376.4601 | Exploration: 0.158730 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -2638 | Episode: 231 | Qmax: 378.2377 | Exploration: 0.158571 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -2193 | Episode: 232 | Qmax: 375.8951 | Exploration: 0.158412 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -3082 | Episode: 233 | Qmax: 377.1491 | Exploration: 0.158254 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -2901 | Episode: 234 | Qmax: 377.3010 | Exploration: 0.158096 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1650 | Episode: 235 | Qmax: 376.0467 | Exploration: 0.157937 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -1423 | Episode: 236 | Qmax: 378.8670 | Exploration: 0.157780 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -2289 | Episode: 237 | Qmax: 376.3832 | Exploration: 0.157622 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -2947 | Episode: 238 | Qmax: 379.1636 | Exploration: 0.157464 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -2815 | Episode: 239 | Qmax: 378.6513 | Exploration: 0.157307 | Step: 395 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -5294 | Episode: 240 | Qmax: 376.8479 | Exploration: 0.157149 | Step: 516 | LR: 0.00150000\n",
      "| Reward: -2187 | Episode: 241 | Qmax: 377.2985 | Exploration: 0.156992 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -1714 | Episode: 242 | Qmax: 379.9389 | Exploration: 0.156835 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -1737 | Episode: 243 | Qmax: 378.6594 | Exploration: 0.156678 | Step: 226 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1996 | Episode: 244 | Qmax: 379.3755 | Exploration: 0.156522 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -2787 | Episode: 245 | Qmax: 378.8760 | Exploration: 0.156365 | Step: 313 | LR: 0.00150000\n",
      "| Reward: -1465 | Episode: 246 | Qmax: 378.6409 | Exploration: 0.156209 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -2460 | Episode: 247 | Qmax: 380.1292 | Exploration: 0.156053 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -1601 | Episode: 248 | Qmax: 379.1879 | Exploration: 0.155897 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -2195 | Episode: 249 | Qmax: 380.5083 | Exploration: 0.155741 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -3544 | Episode: 250 | Qmax: 380.4351 | Exploration: 0.155585 | Step: 323 | LR: 0.00150000\n",
      "| Reward: -1637 | Episode: 251 | Qmax: 380.1938 | Exploration: 0.155429 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -2578 | Episode: 252 | Qmax: 382.0425 | Exploration: 0.155274 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -2123 | Episode: 253 | Qmax: 380.3473 | Exploration: 0.155119 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -2607 | Episode: 254 | Qmax: 380.3417 | Exploration: 0.154964 | Step: 340 | LR: 0.00150000\n",
      "| Reward: -2824 | Episode: 255 | Qmax: 383.0831 | Exploration: 0.154809 | Step: 224 | LR: 0.00150000\n",
      "| Reward: -1739 | Episode: 256 | Qmax: 382.0539 | Exploration: 0.154654 | Step: 156 | LR: 0.00150000\n",
      "| Reward: -1593 | Episode: 257 | Qmax: 383.9375 | Exploration: 0.154499 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -2443 | Episode: 258 | Qmax: 381.4357 | Exploration: 0.154345 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -3589 | Episode: 259 | Qmax: 383.7696 | Exploration: 0.154190 | Step: 206 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2656 | Episode: 260 | Qmax: 384.0038 | Exploration: 0.154036 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -2471 | Episode: 261 | Qmax: 383.4527 | Exploration: 0.153882 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1462 | Episode: 262 | Qmax: 384.4097 | Exploration: 0.153728 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -1502 | Episode: 263 | Qmax: 383.6835 | Exploration: 0.153574 | Step: 279 | LR: 0.00150000\n",
      "| Reward: -2694 | Episode: 264 | Qmax: 384.6568 | Exploration: 0.153421 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -2356 | Episode: 265 | Qmax: 382.9340 | Exploration: 0.153267 | Step: 512 | LR: 0.00150000\n",
      "| Reward: -2566 | Episode: 266 | Qmax: 384.1140 | Exploration: 0.153114 | Step: 362 | LR: 0.00150000\n",
      "| Reward: -1810 | Episode: 267 | Qmax: 383.6842 | Exploration: 0.152961 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -2054 | Episode: 268 | Qmax: 383.6320 | Exploration: 0.152808 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -2234 | Episode: 269 | Qmax: 385.8139 | Exploration: 0.152655 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -2245 | Episode: 270 | Qmax: 383.5657 | Exploration: 0.152503 | Step: 284 | LR: 0.00150000\n",
      "| Reward: -2526 | Episode: 271 | Qmax: 385.7539 | Exploration: 0.152350 | Step: 322 | LR: 0.00150000\n",
      "| Reward: -1801 | Episode: 272 | Qmax: 387.1168 | Exploration: 0.152198 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -2269 | Episode: 273 | Qmax: 386.8561 | Exploration: 0.152046 | Step: 191 | LR: 0.00150000\n",
      "| Reward: -2101 | Episode: 274 | Qmax: 387.2600 | Exploration: 0.151894 | Step: 320 | LR: 0.00150000\n",
      "| Reward: -2189 | Episode: 275 | Qmax: 386.5673 | Exploration: 0.151742 | Step: 318 | LR: 0.00150000\n",
      "| Reward: -2559 | Episode: 276 | Qmax: 387.1325 | Exploration: 0.151590 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -1916 | Episode: 277 | Qmax: 384.9043 | Exploration: 0.151438 | Step: 324 | LR: 0.00150000\n",
      "| Reward: -1787 | Episode: 278 | Qmax: 387.9687 | Exploration: 0.151287 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -2292 | Episode: 279 | Qmax: 387.3266 | Exploration: 0.151136 | Step: 349 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1805 | Episode: 280 | Qmax: 385.3975 | Exploration: 0.150984 | Step: 456 | LR: 0.00150000\n",
      "| Reward: -1485 | Episode: 281 | Qmax: 389.0263 | Exploration: 0.150833 | Step: 172 | LR: 0.00150000\n",
      "| Reward: -2978 | Episode: 282 | Qmax: 387.4021 | Exploration: 0.150683 | Step: 504 | LR: 0.00150000\n",
      "| Reward: -3020 | Episode: 283 | Qmax: 387.2495 | Exploration: 0.150532 | Step: 609 | LR: 0.00150000\n",
      "| Reward: -1291 | Episode: 284 | Qmax: 391.1497 | Exploration: 0.150381 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -1758 | Episode: 285 | Qmax: 388.4083 | Exploration: 0.150231 | Step: 319 | LR: 0.00150000\n",
      "| Reward: -2215 | Episode: 286 | Qmax: 390.3121 | Exploration: 0.150081 | Step: 191 | LR: 0.00150000\n",
      "| Reward: -2308 | Episode: 287 | Qmax: 390.8289 | Exploration: 0.149931 | Step: 221 | LR: 0.00150000\n",
      "| Reward: -2191 | Episode: 288 | Qmax: 391.3981 | Exploration: 0.149781 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -2397 | Episode: 289 | Qmax: 388.5523 | Exploration: 0.149631 | Step: 418 | LR: 0.00150000\n",
      "| Reward: -3244 | Episode: 290 | Qmax: 390.4861 | Exploration: 0.149481 | Step: 365 | LR: 0.00150000\n",
      "| Reward: -1865 | Episode: 291 | Qmax: 391.9382 | Exploration: 0.149332 | Step: 246 | LR: 0.00150000\n",
      "| Reward: -2093 | Episode: 292 | Qmax: 389.0404 | Exploration: 0.149183 | Step: 402 | LR: 0.00150000\n",
      "| Reward: -1700 | Episode: 293 | Qmax: 391.4118 | Exploration: 0.149033 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -2523 | Episode: 294 | Qmax: 388.9857 | Exploration: 0.148884 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -2268 | Episode: 295 | Qmax: 389.9109 | Exploration: 0.148735 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -2622 | Episode: 296 | Qmax: 390.9016 | Exploration: 0.148587 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1761 | Episode: 297 | Qmax: 390.5537 | Exploration: 0.148438 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -1763 | Episode: 298 | Qmax: 391.7093 | Exploration: 0.148290 | Step: 153 | LR: 0.00150000\n",
      "| Reward: -2636 | Episode: 299 | Qmax: 389.4245 | Exploration: 0.148141 | Step: 225 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2080 | Episode: 300 | Qmax: 391.7620 | Exploration: 0.147993 | Step: 317 | LR: 0.00150000\n",
      "| Reward: -2204 | Episode: 301 | Qmax: 391.4571 | Exploration: 0.147845 | Step: 243 | LR: 0.00150000\n",
      "| Reward: -1396 | Episode: 302 | Qmax: 393.7909 | Exploration: 0.147697 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -2201 | Episode: 303 | Qmax: 392.7796 | Exploration: 0.147550 | Step: 348 | LR: 0.00150000\n",
      "| Reward: -2108 | Episode: 304 | Qmax: 392.4026 | Exploration: 0.147402 | Step: 516 | LR: 0.00150000\n",
      "| Reward: -2716 | Episode: 305 | Qmax: 393.9378 | Exploration: 0.147255 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -2708 | Episode: 306 | Qmax: 394.0937 | Exploration: 0.147108 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -2589 | Episode: 307 | Qmax: 393.6203 | Exploration: 0.146960 | Step: 286 | LR: 0.00150000\n",
      "| Reward: -2059 | Episode: 308 | Qmax: 394.2431 | Exploration: 0.146813 | Step: 377 | LR: 0.00150000\n",
      "| Reward: -2840 | Episode: 309 | Qmax: 394.4579 | Exploration: 0.146667 | Step: 384 | LR: 0.00150000\n",
      "| Reward: -1804 | Episode: 310 | Qmax: 394.3315 | Exploration: 0.146520 | Step: 428 | LR: 0.00150000\n",
      "| Reward: -2358 | Episode: 311 | Qmax: 397.6141 | Exploration: 0.146373 | Step: 316 | LR: 0.00150000\n",
      "| Reward: -2315 | Episode: 312 | Qmax: 394.7322 | Exploration: 0.146227 | Step: 246 | LR: 0.00150000\n",
      "| Reward: -1563 | Episode: 313 | Qmax: 395.6731 | Exploration: 0.146081 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -2412 | Episode: 314 | Qmax: 393.4576 | Exploration: 0.145935 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -2626 | Episode: 315 | Qmax: 395.5884 | Exploration: 0.145789 | Step: 404 | LR: 0.00150000\n",
      "| Reward: -2821 | Episode: 316 | Qmax: 395.1257 | Exploration: 0.145643 | Step: 275 | LR: 0.00150000\n",
      "| Reward: -2322 | Episode: 317 | Qmax: 395.3313 | Exploration: 0.145497 | Step: 289 | LR: 0.00150000\n",
      "| Reward: -2143 | Episode: 318 | Qmax: 394.8749 | Exploration: 0.145352 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -2679 | Episode: 319 | Qmax: 395.3623 | Exploration: 0.145207 | Step: 376 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1586 | Episode: 320 | Qmax: 396.8213 | Exploration: 0.145061 | Step: 246 | LR: 0.00150000\n",
      "| Reward: -2096 | Episode: 321 | Qmax: 394.7261 | Exploration: 0.144916 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -1775 | Episode: 322 | Qmax: 396.3710 | Exploration: 0.144771 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -2883 | Episode: 323 | Qmax: 395.3145 | Exploration: 0.144627 | Step: 328 | LR: 0.00150000\n",
      "| Reward: -2014 | Episode: 324 | Qmax: 393.7982 | Exploration: 0.144482 | Step: 269 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2133 | Episode: 325 | Qmax: 394.0696 | Exploration: 0.144337 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -1868 | Episode: 326 | Qmax: 394.5162 | Exploration: 0.144193 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -3068 | Episode: 327 | Qmax: 394.2461 | Exploration: 0.144049 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -2650 | Episode: 328 | Qmax: 393.8715 | Exploration: 0.143905 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -2406 | Episode: 329 | Qmax: 396.3708 | Exploration: 0.143761 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -2202 | Episode: 330 | Qmax: 395.9146 | Exploration: 0.143617 | Step: 430 | LR: 0.00150000\n",
      "| Reward: -2522 | Episode: 331 | Qmax: 396.7374 | Exploration: 0.143474 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -2162 | Episode: 332 | Qmax: 395.3472 | Exploration: 0.143330 | Step: 336 | LR: 0.00150000\n",
      "| Reward: -2460 | Episode: 333 | Qmax: 397.2789 | Exploration: 0.143187 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -1517 | Episode: 334 | Qmax: 398.4904 | Exploration: 0.143044 | Step: 204 | LR: 0.00150000\n",
      "| Reward: -2308 | Episode: 335 | Qmax: 395.2148 | Exploration: 0.142901 | Step: 293 | LR: 0.00150000\n",
      "| Reward: -1222 | Episode: 336 | Qmax: 394.8974 | Exploration: 0.142758 | Step: 179 | LR: 0.00150000\n",
      "| Reward: -2800 | Episode: 337 | Qmax: 396.7485 | Exploration: 0.142615 | Step: 362 | LR: 0.00150000\n",
      "| Reward: -1906 | Episode: 338 | Qmax: 394.3192 | Exploration: 0.142472 | Step: 197 | LR: 0.00150000\n",
      "| Reward: -2789 | Episode: 339 | Qmax: 394.1317 | Exploration: 0.142330 | Step: 306 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2388 | Episode: 340 | Qmax: 394.7653 | Exploration: 0.142188 | Step: 310 | LR: 0.00150000\n",
      "| Reward: -2267 | Episode: 341 | Qmax: 393.5615 | Exploration: 0.142045 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -1479 | Episode: 342 | Qmax: 394.1641 | Exploration: 0.141903 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -2055 | Episode: 343 | Qmax: 394.0171 | Exploration: 0.141761 | Step: 337 | LR: 0.00150000\n",
      "| Reward: -1740 | Episode: 344 | Qmax: 394.1364 | Exploration: 0.141620 | Step: 319 | LR: 0.00150000\n",
      "| Reward: -2071 | Episode: 345 | Qmax: 393.4047 | Exploration: 0.141478 | Step: 344 | LR: 0.00150000\n",
      "| Reward: -3493 | Episode: 346 | Qmax: 394.6048 | Exploration: 0.141337 | Step: 407 | LR: 0.00150000\n",
      "| Reward: -2188 | Episode: 347 | Qmax: 396.3786 | Exploration: 0.141195 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -2226 | Episode: 348 | Qmax: 394.0258 | Exploration: 0.141054 | Step: 256 | LR: 0.00150000\n",
      "| Reward: -3066 | Episode: 349 | Qmax: 394.8692 | Exploration: 0.140913 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -1929 | Episode: 350 | Qmax: 396.1520 | Exploration: 0.140772 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -2469 | Episode: 351 | Qmax: 394.4558 | Exploration: 0.140631 | Step: 328 | LR: 0.00150000\n",
      "| Reward: -2593 | Episode: 352 | Qmax: 394.8271 | Exploration: 0.140491 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -2413 | Episode: 353 | Qmax: 395.4601 | Exploration: 0.140350 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -2140 | Episode: 354 | Qmax: 394.1820 | Exploration: 0.140210 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -2128 | Episode: 355 | Qmax: 396.0004 | Exploration: 0.140070 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -2092 | Episode: 356 | Qmax: 395.0903 | Exploration: 0.139930 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -2048 | Episode: 357 | Qmax: 396.0962 | Exploration: 0.139790 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -2928 | Episode: 358 | Qmax: 396.0790 | Exploration: 0.139650 | Step: 463 | LR: 0.00150000\n",
      "| Reward: -1824 | Episode: 359 | Qmax: 398.1383 | Exploration: 0.139510 | Step: 205 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1944 | Episode: 360 | Qmax: 397.0595 | Exploration: 0.139371 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1385 | Episode: 361 | Qmax: 397.1172 | Exploration: 0.139231 | Step: 234 | LR: 0.00150000\n",
      "| Reward: -1380 | Episode: 362 | Qmax: 394.9227 | Exploration: 0.139092 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -2521 | Episode: 363 | Qmax: 396.3139 | Exploration: 0.138953 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -1570 | Episode: 364 | Qmax: 393.2041 | Exploration: 0.138814 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -2320 | Episode: 365 | Qmax: 394.7823 | Exploration: 0.138675 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -2463 | Episode: 366 | Qmax: 392.3906 | Exploration: 0.138536 | Step: 295 | LR: 0.00150000\n",
      "| Reward: -1928 | Episode: 367 | Qmax: 395.9043 | Exploration: 0.138398 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -1463 | Episode: 368 | Qmax: 394.0868 | Exploration: 0.138260 | Step: 249 | LR: 0.00150000\n",
      "| Reward: -1971 | Episode: 369 | Qmax: 394.7178 | Exploration: 0.138121 | Step: 289 | LR: 0.00150000\n",
      "| Reward: -2556 | Episode: 370 | Qmax: 393.6963 | Exploration: 0.137983 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -2815 | Episode: 371 | Qmax: 395.5057 | Exploration: 0.137845 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -1779 | Episode: 372 | Qmax: 393.1974 | Exploration: 0.137707 | Step: 187 | LR: 0.00150000\n",
      "| Reward: -1471 | Episode: 373 | Qmax: 394.9129 | Exploration: 0.137570 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -2020 | Episode: 374 | Qmax: 396.2735 | Exploration: 0.137432 | Step: 221 | LR: 0.00150000\n",
      "| Reward: -1686 | Episode: 375 | Qmax: 394.4619 | Exploration: 0.137295 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -2154 | Episode: 376 | Qmax: 396.0363 | Exploration: 0.137157 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -1268 | Episode: 377 | Qmax: 397.1657 | Exploration: 0.137020 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -1696 | Episode: 378 | Qmax: 394.2668 | Exploration: 0.136883 | Step: 257 | LR: 0.00150000\n",
      "| Reward: -2413 | Episode: 379 | Qmax: 397.4966 | Exploration: 0.136746 | Step: 254 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2511 | Episode: 380 | Qmax: 395.9129 | Exploration: 0.136610 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -2215 | Episode: 381 | Qmax: 392.8787 | Exploration: 0.136473 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -1693 | Episode: 382 | Qmax: 394.2615 | Exploration: 0.136336 | Step: 227 | LR: 0.00150000\n",
      "| Reward: -2477 | Episode: 383 | Qmax: 395.6757 | Exploration: 0.136200 | Step: 318 | LR: 0.00150000\n",
      "| Reward: -2018 | Episode: 384 | Qmax: 396.5392 | Exploration: 0.136064 | Step: 174 | LR: 0.00150000\n",
      "| Reward: -1210 | Episode: 385 | Qmax: 394.1099 | Exploration: 0.135928 | Step: 158 | LR: 0.00150000\n",
      "| Reward: -1537 | Episode: 386 | Qmax: 399.4566 | Exploration: 0.135792 | Step: 170 | LR: 0.00150000\n",
      "| Reward: -2740 | Episode: 387 | Qmax: 396.5062 | Exploration: 0.135656 | Step: 329 | LR: 0.00150000\n",
      "| Reward: -1560 | Episode: 388 | Qmax: 397.5535 | Exploration: 0.135520 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -2096 | Episode: 389 | Qmax: 398.9899 | Exploration: 0.135385 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -2922 | Episode: 390 | Qmax: 397.4854 | Exploration: 0.135250 | Step: 295 | LR: 0.00150000\n",
      "| Reward: -3225 | Episode: 391 | Qmax: 397.4823 | Exploration: 0.135114 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -2391 | Episode: 392 | Qmax: 396.0379 | Exploration: 0.134979 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -1462 | Episode: 393 | Qmax: 398.0306 | Exploration: 0.134844 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -2665 | Episode: 394 | Qmax: 398.1722 | Exploration: 0.134709 | Step: 308 | LR: 0.00150000\n",
      "| Reward: -2111 | Episode: 395 | Qmax: 398.1228 | Exploration: 0.134575 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -2198 | Episode: 396 | Qmax: 397.2788 | Exploration: 0.134440 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -2013 | Episode: 397 | Qmax: 397.6521 | Exploration: 0.134306 | Step: 331 | LR: 0.00150000\n",
      "| Reward: -2234 | Episode: 398 | Qmax: 398.3801 | Exploration: 0.134171 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -2039 | Episode: 399 | Qmax: 396.8648 | Exploration: 0.134037 | Step: 303 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2689 | Episode: 400 | Qmax: 398.2570 | Exploration: 0.133903 | Step: 206 | LR: 0.00150000\n",
      "| Reward: -1761 | Episode: 401 | Qmax: 398.8516 | Exploration: 0.133769 | Step: 205 | LR: 0.00150000\n",
      "| Reward: -2850 | Episode: 402 | Qmax: 396.1931 | Exploration: 0.133635 | Step: 358 | LR: 0.00150000\n",
      "| Reward: -1656 | Episode: 403 | Qmax: 400.9267 | Exploration: 0.133502 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1818 | Episode: 404 | Qmax: 398.5996 | Exploration: 0.133368 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -3033 | Episode: 405 | Qmax: 398.5374 | Exploration: 0.133235 | Step: 253 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1283 | Episode: 406 | Qmax: 401.9415 | Exploration: 0.133102 | Step: 141 | LR: 0.00150000\n",
      "| Reward: -2154 | Episode: 407 | Qmax: 399.3993 | Exploration: 0.132969 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -1913 | Episode: 408 | Qmax: 399.4828 | Exploration: 0.132836 | Step: 159 | LR: 0.00150000\n",
      "| Reward: -1726 | Episode: 409 | Qmax: 396.9571 | Exploration: 0.132703 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1859 | Episode: 410 | Qmax: 399.2659 | Exploration: 0.132570 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1491 | Episode: 411 | Qmax: 403.6212 | Exploration: 0.132438 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -1672 | Episode: 412 | Qmax: 398.5104 | Exploration: 0.132305 | Step: 143 | LR: 0.00150000\n",
      "| Reward: -1683 | Episode: 413 | Qmax: 401.7655 | Exploration: 0.132173 | Step: 316 | LR: 0.00150000\n",
      "| Reward: -2427 | Episode: 414 | Qmax: 401.4408 | Exploration: 0.132041 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -2166 | Episode: 415 | Qmax: 398.8991 | Exploration: 0.131909 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -2067 | Episode: 416 | Qmax: 400.2649 | Exploration: 0.131777 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1892 | Episode: 417 | Qmax: 399.3769 | Exploration: 0.131645 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -1868 | Episode: 418 | Qmax: 399.9434 | Exploration: 0.131513 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -1752 | Episode: 419 | Qmax: 401.1250 | Exploration: 0.131382 | Step: 259 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1290 | Episode: 420 | Qmax: 403.9180 | Exploration: 0.131250 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -2311 | Episode: 421 | Qmax: 399.9370 | Exploration: 0.131119 | Step: 224 | LR: 0.00150000\n",
      "| Reward: -1778 | Episode: 422 | Qmax: 399.9502 | Exploration: 0.130988 | Step: 240 | LR: 0.00150000\n",
      "| Reward: -2344 | Episode: 423 | Qmax: 401.1501 | Exploration: 0.130857 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -1883 | Episode: 424 | Qmax: 401.2125 | Exploration: 0.130726 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1463 | Episode: 425 | Qmax: 400.2978 | Exploration: 0.130595 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1815 | Episode: 426 | Qmax: 398.7293 | Exploration: 0.130465 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -1586 | Episode: 427 | Qmax: 399.4032 | Exploration: 0.130334 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1602 | Episode: 428 | Qmax: 400.4302 | Exploration: 0.130204 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1781 | Episode: 429 | Qmax: 402.6617 | Exploration: 0.130074 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -2333 | Episode: 430 | Qmax: 401.2263 | Exploration: 0.129944 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -2280 | Episode: 431 | Qmax: 402.7009 | Exploration: 0.129814 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1970 | Episode: 432 | Qmax: 404.4542 | Exploration: 0.129684 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -2082 | Episode: 433 | Qmax: 403.9956 | Exploration: 0.129554 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1799 | Episode: 434 | Qmax: 401.0909 | Exploration: 0.129425 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -2123 | Episode: 435 | Qmax: 401.4571 | Exploration: 0.129295 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -1756 | Episode: 436 | Qmax: 401.5633 | Exploration: 0.129166 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1578 | Episode: 437 | Qmax: 401.0053 | Exploration: 0.129037 | Step: 193 | LR: 0.00150000\n",
      "| Reward: -2083 | Episode: 438 | Qmax: 402.1557 | Exploration: 0.128908 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -2508 | Episode: 439 | Qmax: 400.4903 | Exploration: 0.128779 | Step: 268 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1532 | Episode: 440 | Qmax: 400.2387 | Exploration: 0.128650 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -2495 | Episode: 441 | Qmax: 400.2764 | Exploration: 0.128522 | Step: 273 | LR: 0.00150000\n",
      "| Reward: -1883 | Episode: 442 | Qmax: 401.2284 | Exploration: 0.128393 | Step: 282 | LR: 0.00150000\n",
      "| Reward: -2251 | Episode: 443 | Qmax: 402.9591 | Exploration: 0.128265 | Step: 263 | LR: 0.00150000\n",
      "| Reward: -1558 | Episode: 444 | Qmax: 399.9368 | Exploration: 0.128136 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -1439 | Episode: 445 | Qmax: 401.2509 | Exploration: 0.128008 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1859 | Episode: 446 | Qmax: 399.1166 | Exploration: 0.127880 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -1897 | Episode: 447 | Qmax: 402.6187 | Exploration: 0.127752 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -2193 | Episode: 448 | Qmax: 399.4562 | Exploration: 0.127625 | Step: 286 | LR: 0.00150000\n",
      "| Reward: -1598 | Episode: 449 | Qmax: 398.7707 | Exploration: 0.127497 | Step: 159 | LR: 0.00150000\n",
      "| Reward: -1522 | Episode: 450 | Qmax: 398.7297 | Exploration: 0.127369 | Step: 227 | LR: 0.00150000\n",
      "| Reward: -1818 | Episode: 451 | Qmax: 399.9241 | Exploration: 0.127242 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1894 | Episode: 452 | Qmax: 399.6527 | Exploration: 0.127115 | Step: 275 | LR: 0.00150000\n",
      "| Reward: -1829 | Episode: 453 | Qmax: 398.9265 | Exploration: 0.126988 | Step: 156 | LR: 0.00150000\n",
      "| Reward: -1454 | Episode: 454 | Qmax: 398.6240 | Exploration: 0.126861 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -1618 | Episode: 455 | Qmax: 398.1793 | Exploration: 0.126734 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -2798 | Episode: 456 | Qmax: 398.9773 | Exploration: 0.126607 | Step: 423 | LR: 0.00150000\n",
      "| Reward: -1602 | Episode: 457 | Qmax: 399.4682 | Exploration: 0.126481 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -2313 | Episode: 458 | Qmax: 398.7888 | Exploration: 0.126354 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -1666 | Episode: 459 | Qmax: 398.7581 | Exploration: 0.126228 | Step: 218 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2270 | Episode: 460 | Qmax: 398.6227 | Exploration: 0.126101 | Step: 201 | LR: 0.00150000\n",
      "| Reward: -1458 | Episode: 461 | Qmax: 397.7206 | Exploration: 0.125975 | Step: 343 | LR: 0.00150000\n",
      "| Reward: -1613 | Episode: 462 | Qmax: 397.8658 | Exploration: 0.125849 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1634 | Episode: 463 | Qmax: 397.8870 | Exploration: 0.125724 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1784 | Episode: 464 | Qmax: 399.2750 | Exploration: 0.125598 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -1976 | Episode: 465 | Qmax: 400.4206 | Exploration: 0.125472 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -1328 | Episode: 466 | Qmax: 399.3274 | Exploration: 0.125347 | Step: 249 | LR: 0.00150000\n",
      "| Reward: -1683 | Episode: 467 | Qmax: 396.9585 | Exploration: 0.125221 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -3813 | Episode: 468 | Qmax: 396.1509 | Exploration: 0.125096 | Step: 385 | LR: 0.00150000\n",
      "| Reward: -2069 | Episode: 469 | Qmax: 397.0230 | Exploration: 0.124971 | Step: 315 | LR: 0.00150000\n",
      "| Reward: -2635 | Episode: 470 | Qmax: 398.1700 | Exploration: 0.124846 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -2707 | Episode: 471 | Qmax: 397.7163 | Exploration: 0.124721 | Step: 197 | LR: 0.00150000\n",
      "| Reward: -1833 | Episode: 472 | Qmax: 398.1480 | Exploration: 0.124597 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -2030 | Episode: 473 | Qmax: 397.0698 | Exploration: 0.124472 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1411 | Episode: 474 | Qmax: 395.6039 | Exploration: 0.124347 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -1297 | Episode: 475 | Qmax: 396.5811 | Exploration: 0.124223 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -2003 | Episode: 476 | Qmax: 395.7873 | Exploration: 0.124099 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -1324 | Episode: 477 | Qmax: 395.8672 | Exploration: 0.123975 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -1389 | Episode: 478 | Qmax: 395.8114 | Exploration: 0.123851 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -2118 | Episode: 479 | Qmax: 395.2933 | Exploration: 0.123727 | Step: 301 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1949 | Episode: 480 | Qmax: 396.9798 | Exploration: 0.123603 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -2491 | Episode: 481 | Qmax: 394.4705 | Exploration: 0.123480 | Step: 404 | LR: 0.00150000\n",
      "| Reward: -2166 | Episode: 482 | Qmax: 394.5599 | Exploration: 0.123356 | Step: 358 | LR: 0.00150000\n",
      "| Reward: -1908 | Episode: 483 | Qmax: 394.9635 | Exploration: 0.123233 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -2019 | Episode: 484 | Qmax: 394.9615 | Exploration: 0.123110 | Step: 427 | LR: 0.00150000\n",
      "| Reward: -2444 | Episode: 485 | Qmax: 395.9839 | Exploration: 0.122986 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -2468 | Episode: 486 | Qmax: 396.2504 | Exploration: 0.122863 | Step: 291 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2076 | Episode: 487 | Qmax: 396.3699 | Exploration: 0.122741 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -2512 | Episode: 488 | Qmax: 397.7043 | Exploration: 0.122618 | Step: 335 | LR: 0.00150000\n",
      "| Reward: -2615 | Episode: 489 | Qmax: 395.5500 | Exploration: 0.122495 | Step: 321 | LR: 0.00150000\n",
      "| Reward: -1354 | Episode: 490 | Qmax: 393.4309 | Exploration: 0.122373 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -1916 | Episode: 491 | Qmax: 395.6189 | Exploration: 0.122250 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1564 | Episode: 492 | Qmax: 392.8620 | Exploration: 0.122128 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -1417 | Episode: 493 | Qmax: 394.8405 | Exploration: 0.122006 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -2867 | Episode: 494 | Qmax: 393.2179 | Exploration: 0.121884 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -1526 | Episode: 495 | Qmax: 394.4169 | Exploration: 0.121762 | Step: 159 | LR: 0.00150000\n",
      "| Reward: -1675 | Episode: 496 | Qmax: 393.6523 | Exploration: 0.121640 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1222 | Episode: 497 | Qmax: 392.5994 | Exploration: 0.121519 | Step: 206 | LR: 0.00150000\n",
      "| Reward: -1652 | Episode: 498 | Qmax: 391.7720 | Exploration: 0.121397 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -1852 | Episode: 499 | Qmax: 392.9491 | Exploration: 0.121276 | Step: 179 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1766 | Episode: 500 | Qmax: 392.3740 | Exploration: 0.121155 | Step: 192 | LR: 0.00150000\n",
      "| Reward: -1554 | Episode: 501 | Qmax: 392.0592 | Exploration: 0.121033 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -1690 | Episode: 502 | Qmax: 391.9921 | Exploration: 0.120912 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1911 | Episode: 503 | Qmax: 391.5300 | Exploration: 0.120791 | Step: 310 | LR: 0.00150000\n",
      "| Reward: -1310 | Episode: 504 | Qmax: 391.4992 | Exploration: 0.120671 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -1113 | Episode: 505 | Qmax: 391.7712 | Exploration: 0.120550 | Step: 142 | LR: 0.00150000\n",
      "| Reward: -1844 | Episode: 506 | Qmax: 391.9219 | Exploration: 0.120429 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -2907 | Episode: 507 | Qmax: 391.2358 | Exploration: 0.120309 | Step: 307 | LR: 0.00150000\n",
      "| Reward: -1887 | Episode: 508 | Qmax: 390.0815 | Exploration: 0.120189 | Step: 331 | LR: 0.00150000\n",
      "| Reward: -1451 | Episode: 509 | Qmax: 390.9883 | Exploration: 0.120068 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -1712 | Episode: 510 | Qmax: 389.1530 | Exploration: 0.119948 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -1220 | Episode: 511 | Qmax: 392.2522 | Exploration: 0.119828 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1513 | Episode: 512 | Qmax: 389.1927 | Exploration: 0.119709 | Step: 263 | LR: 0.00150000\n",
      "| Reward: -1456 | Episode: 513 | Qmax: 389.4653 | Exploration: 0.119589 | Step: 305 | LR: 0.00150000\n",
      "| Reward: -1963 | Episode: 514 | Qmax: 388.7288 | Exploration: 0.119469 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -1552 | Episode: 515 | Qmax: 388.1032 | Exploration: 0.119350 | Step: 275 | LR: 0.00150000\n",
      "| Reward: -1715 | Episode: 516 | Qmax: 386.3939 | Exploration: 0.119231 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -2204 | Episode: 517 | Qmax: 387.5130 | Exploration: 0.119111 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1202 | Episode: 518 | Qmax: 387.6907 | Exploration: 0.118992 | Step: 204 | LR: 0.00150000\n",
      "| Reward: -1488 | Episode: 519 | Qmax: 387.5212 | Exploration: 0.118873 | Step: 211 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1295 | Episode: 520 | Qmax: 386.3339 | Exploration: 0.118754 | Step: 180 | LR: 0.00150000\n",
      "| Reward: -2147 | Episode: 521 | Qmax: 383.9504 | Exploration: 0.118636 | Step: 348 | LR: 0.00150000\n",
      "| Reward: -1409 | Episode: 522 | Qmax: 384.7928 | Exploration: 0.118517 | Step: 141 | LR: 0.00150000\n",
      "| Reward: -1815 | Episode: 523 | Qmax: 384.4091 | Exploration: 0.118398 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -1503 | Episode: 524 | Qmax: 384.7174 | Exploration: 0.118280 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1906 | Episode: 525 | Qmax: 382.8712 | Exploration: 0.118162 | Step: 224 | LR: 0.00150000\n",
      "| Reward: -1506 | Episode: 526 | Qmax: 382.7549 | Exploration: 0.118044 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -1811 | Episode: 527 | Qmax: 381.8957 | Exploration: 0.117926 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -1571 | Episode: 528 | Qmax: 380.1395 | Exploration: 0.117808 | Step: 303 | LR: 0.00150000\n",
      "| Reward: -1521 | Episode: 529 | Qmax: 380.8076 | Exploration: 0.117690 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -2259 | Episode: 530 | Qmax: 381.5623 | Exploration: 0.117572 | Step: 181 | LR: 0.00150000\n",
      "| Reward: -1925 | Episode: 531 | Qmax: 381.0514 | Exploration: 0.117455 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -1334 | Episode: 532 | Qmax: 380.9085 | Exploration: 0.117337 | Step: 138 | LR: 0.00150000\n",
      "| Reward: -1208 | Episode: 533 | Qmax: 380.2230 | Exploration: 0.117220 | Step: 174 | LR: 0.00150000\n",
      "| Reward: -1798 | Episode: 534 | Qmax: 378.2605 | Exploration: 0.117103 | Step: 179 | LR: 0.00150000\n",
      "| Reward: -2919 | Episode: 535 | Qmax: 377.8482 | Exploration: 0.116985 | Step: 337 | LR: 0.00150000\n",
      "| Reward: -1523 | Episode: 536 | Qmax: 377.9884 | Exploration: 0.116868 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -1488 | Episode: 537 | Qmax: 377.7906 | Exploration: 0.116752 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -1524 | Episode: 538 | Qmax: 376.6405 | Exploration: 0.116635 | Step: 319 | LR: 0.00150000\n",
      "| Reward: -1373 | Episode: 539 | Qmax: 375.3726 | Exploration: 0.116518 | Step: 294 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2153 | Episode: 540 | Qmax: 375.2310 | Exploration: 0.116402 | Step: 354 | LR: 0.00150000\n",
      "| Reward: -1293 | Episode: 541 | Qmax: 374.5896 | Exploration: 0.116285 | Step: 205 | LR: 0.00150000\n",
      "| Reward: -1291 | Episode: 542 | Qmax: 374.0442 | Exploration: 0.116169 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -2001 | Episode: 543 | Qmax: 372.4839 | Exploration: 0.116053 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -1169 | Episode: 544 | Qmax: 373.6186 | Exploration: 0.115937 | Step: 153 | LR: 0.00150000\n",
      "| Reward: -1355 | Episode: 545 | Qmax: 373.7742 | Exploration: 0.115821 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1811 | Episode: 546 | Qmax: 372.0364 | Exploration: 0.115705 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -1689 | Episode: 547 | Qmax: 371.7973 | Exploration: 0.115589 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -1725 | Episode: 548 | Qmax: 372.6799 | Exploration: 0.115474 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1839 | Episode: 549 | Qmax: 370.8286 | Exploration: 0.115358 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1562 | Episode: 550 | Qmax: 370.7983 | Exploration: 0.115243 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -1513 | Episode: 551 | Qmax: 368.6492 | Exploration: 0.115128 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1342 | Episode: 552 | Qmax: 368.2199 | Exploration: 0.115012 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -2287 | Episode: 553 | Qmax: 367.9111 | Exploration: 0.114897 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1688 | Episode: 554 | Qmax: 366.8748 | Exploration: 0.114783 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -1464 | Episode: 555 | Qmax: 367.0638 | Exploration: 0.114668 | Step: 241 | LR: 0.00150000\n",
      "| Reward: -2465 | Episode: 556 | Qmax: 366.0661 | Exploration: 0.114553 | Step: 378 | LR: 0.00150000\n",
      "| Reward: -1410 | Episode: 557 | Qmax: 366.9778 | Exploration: 0.114439 | Step: 160 | LR: 0.00150000\n",
      "| Reward: -1558 | Episode: 558 | Qmax: 366.8160 | Exploration: 0.114324 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -1592 | Episode: 559 | Qmax: 363.6712 | Exploration: 0.114210 | Step: 342 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1609 | Episode: 560 | Qmax: 363.3939 | Exploration: 0.114096 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -1799 | Episode: 561 | Qmax: 363.8620 | Exploration: 0.113982 | Step: 189 | LR: 0.00150000\n",
      "| Reward: -1940 | Episode: 562 | Qmax: 362.2213 | Exploration: 0.113868 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -2179 | Episode: 563 | Qmax: 361.0877 | Exploration: 0.113754 | Step: 371 | LR: 0.00150000\n",
      "| Reward: -1637 | Episode: 564 | Qmax: 359.9726 | Exploration: 0.113640 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -1300 | Episode: 565 | Qmax: 361.7146 | Exploration: 0.113526 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -1944 | Episode: 566 | Qmax: 360.7520 | Exploration: 0.113413 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -1153 | Episode: 567 | Qmax: 362.2613 | Exploration: 0.113299 | Step: 191 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1713 | Episode: 568 | Qmax: 360.4174 | Exploration: 0.113186 | Step: 202 | LR: 0.00150000\n",
      "| Reward: -1534 | Episode: 569 | Qmax: 358.9285 | Exploration: 0.113073 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -1752 | Episode: 570 | Qmax: 358.3457 | Exploration: 0.112960 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -1387 | Episode: 571 | Qmax: 360.1998 | Exploration: 0.112847 | Step: 128 | LR: 0.00150000\n",
      "| Reward: -1428 | Episode: 572 | Qmax: 358.1784 | Exploration: 0.112734 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -1220 | Episode: 573 | Qmax: 357.3186 | Exploration: 0.112621 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1319 | Episode: 574 | Qmax: 356.8322 | Exploration: 0.112509 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1055 | Episode: 575 | Qmax: 355.3575 | Exploration: 0.112396 | Step: 201 | LR: 0.00150000\n",
      "| Reward: -2285 | Episode: 576 | Qmax: 355.4120 | Exploration: 0.112284 | Step: 234 | LR: 0.00150000\n",
      "| Reward: -1431 | Episode: 577 | Qmax: 355.8495 | Exploration: 0.112171 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -2143 | Episode: 578 | Qmax: 354.9999 | Exploration: 0.112059 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -1298 | Episode: 579 | Qmax: 354.0542 | Exploration: 0.111947 | Step: 237 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2423 | Episode: 580 | Qmax: 352.8973 | Exploration: 0.111835 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -1259 | Episode: 581 | Qmax: 353.8829 | Exploration: 0.111723 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1730 | Episode: 582 | Qmax: 351.4435 | Exploration: 0.111612 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -1248 | Episode: 583 | Qmax: 351.5007 | Exploration: 0.111500 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -1457 | Episode: 584 | Qmax: 350.6892 | Exploration: 0.111389 | Step: 234 | LR: 0.00150000\n",
      "| Reward: -2411 | Episode: 585 | Qmax: 350.1883 | Exploration: 0.111277 | Step: 315 | LR: 0.00150000\n",
      "| Reward: -1345 | Episode: 586 | Qmax: 348.9798 | Exploration: 0.111166 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1431 | Episode: 587 | Qmax: 350.4454 | Exploration: 0.111055 | Step: 181 | LR: 0.00150000\n",
      "| Reward: -1558 | Episode: 588 | Qmax: 349.0919 | Exploration: 0.110944 | Step: 344 | LR: 0.00150000\n",
      "| Reward: -1753 | Episode: 589 | Qmax: 349.2573 | Exploration: 0.110833 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -1341 | Episode: 590 | Qmax: 349.4103 | Exploration: 0.110722 | Step: 172 | LR: 0.00150000\n",
      "| Reward: -1050 | Episode: 591 | Qmax: 348.1078 | Exploration: 0.110611 | Step: 241 | LR: 0.00150000\n",
      "| Reward: -1111 | Episode: 592 | Qmax: 347.4674 | Exploration: 0.110501 | Step: 221 | LR: 0.00150000\n",
      "| Reward: -1989 | Episode: 593 | Qmax: 346.6215 | Exploration: 0.110390 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1395 | Episode: 594 | Qmax: 346.7745 | Exploration: 0.110280 | Step: 136 | LR: 0.00150000\n",
      "| Reward: -1722 | Episode: 595 | Qmax: 346.0145 | Exploration: 0.110169 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -1289 | Episode: 596 | Qmax: 345.7250 | Exploration: 0.110059 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -2166 | Episode: 597 | Qmax: 344.1385 | Exploration: 0.109949 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -1866 | Episode: 598 | Qmax: 343.7837 | Exploration: 0.109839 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -1778 | Episode: 599 | Qmax: 343.2962 | Exploration: 0.109729 | Step: 285 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1310 | Episode: 600 | Qmax: 343.1555 | Exploration: 0.109620 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -1919 | Episode: 601 | Qmax: 342.3527 | Exploration: 0.109510 | Step: 345 | LR: 0.00150000\n",
      "| Reward: -1240 | Episode: 602 | Qmax: 341.7828 | Exploration: 0.109401 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -1224 | Episode: 603 | Qmax: 341.8515 | Exploration: 0.109291 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -1652 | Episode: 604 | Qmax: 340.6462 | Exploration: 0.109182 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -1128 | Episode: 605 | Qmax: 340.1708 | Exploration: 0.109073 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1117 | Episode: 606 | Qmax: 338.7290 | Exploration: 0.108964 | Step: 191 | LR: 0.00150000\n",
      "| Reward: -1192 | Episode: 607 | Qmax: 338.4867 | Exploration: 0.108855 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1961 | Episode: 608 | Qmax: 337.9709 | Exploration: 0.108746 | Step: 315 | LR: 0.00150000\n",
      "| Reward: -1641 | Episode: 609 | Qmax: 337.2682 | Exploration: 0.108637 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -1471 | Episode: 610 | Qmax: 336.8258 | Exploration: 0.108528 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1808 | Episode: 611 | Qmax: 336.3394 | Exploration: 0.108420 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -1643 | Episode: 612 | Qmax: 335.6788 | Exploration: 0.108311 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -1162 | Episode: 613 | Qmax: 336.3813 | Exploration: 0.108203 | Step: 155 | LR: 0.00150000\n",
      "| Reward: -2440 | Episode: 614 | Qmax: 335.1217 | Exploration: 0.108095 | Step: 335 | LR: 0.00150000\n",
      "| Reward: -1620 | Episode: 615 | Qmax: 333.6101 | Exploration: 0.107987 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -1212 | Episode: 616 | Qmax: 333.3913 | Exploration: 0.107879 | Step: 142 | LR: 0.00150000\n",
      "| Reward: -1618 | Episode: 617 | Qmax: 332.5520 | Exploration: 0.107771 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -1321 | Episode: 618 | Qmax: 331.1620 | Exploration: 0.107663 | Step: 314 | LR: 0.00150000\n",
      "| Reward: -2103 | Episode: 619 | Qmax: 331.6978 | Exploration: 0.107556 | Step: 313 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1522 | Episode: 620 | Qmax: 330.8998 | Exploration: 0.107448 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -1816 | Episode: 621 | Qmax: 329.8955 | Exploration: 0.107341 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -1316 | Episode: 622 | Qmax: 329.6015 | Exploration: 0.107233 | Step: 192 | LR: 0.00150000\n",
      "| Reward: -1877 | Episode: 623 | Qmax: 328.6290 | Exploration: 0.107126 | Step: 348 | LR: 0.00150000\n",
      "| Reward: -1119 | Episode: 624 | Qmax: 329.0969 | Exploration: 0.107019 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -2635 | Episode: 625 | Qmax: 328.8215 | Exploration: 0.106912 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -1355 | Episode: 626 | Qmax: 327.7269 | Exploration: 0.106805 | Step: 294 | LR: 0.00150000\n",
      "| Reward: -1878 | Episode: 627 | Qmax: 326.4850 | Exploration: 0.106698 | Step: 358 | LR: 0.00150000\n",
      "| Reward: -1795 | Episode: 628 | Qmax: 325.8847 | Exploration: 0.106591 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -1229 | Episode: 629 | Qmax: 325.6987 | Exploration: 0.106485 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -1283 | Episode: 630 | Qmax: 324.5712 | Exploration: 0.106378 | Step: 204 | LR: 0.00150000\n",
      "| Reward: -2239 | Episode: 631 | Qmax: 324.1200 | Exploration: 0.106272 | Step: 314 | LR: 0.00150000\n",
      "| Reward: -1627 | Episode: 632 | Qmax: 322.7530 | Exploration: 0.106166 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1572 | Episode: 633 | Qmax: 323.5135 | Exploration: 0.106059 | Step: 205 | LR: 0.00150000\n",
      "| Reward: -1995 | Episode: 634 | Qmax: 322.2692 | Exploration: 0.105953 | Step: 304 | LR: 0.00150000\n",
      "| Reward: -1943 | Episode: 635 | Qmax: 322.0481 | Exploration: 0.105847 | Step: 279 | LR: 0.00150000\n",
      "| Reward: -2073 | Episode: 636 | Qmax: 321.0574 | Exploration: 0.105742 | Step: 193 | LR: 0.00150000\n",
      "| Reward: -1427 | Episode: 637 | Qmax: 321.2958 | Exploration: 0.105636 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1974 | Episode: 638 | Qmax: 320.8046 | Exploration: 0.105530 | Step: 247 | LR: 0.00150000\n",
      "| Reward: -1430 | Episode: 639 | Qmax: 318.4538 | Exploration: 0.105425 | Step: 234 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1429 | Episode: 640 | Qmax: 318.0110 | Exploration: 0.105319 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -2254 | Episode: 641 | Qmax: 318.3169 | Exploration: 0.105214 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1073 | Episode: 642 | Qmax: 317.3354 | Exploration: 0.105109 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -1764 | Episode: 643 | Qmax: 317.8962 | Exploration: 0.105004 | Step: 280 | LR: 0.00150000\n",
      "| Reward: -1392 | Episode: 644 | Qmax: 316.1737 | Exploration: 0.104899 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1491 | Episode: 645 | Qmax: 315.8180 | Exploration: 0.104794 | Step: 241 | LR: 0.00150000\n",
      "| Reward: -1993 | Episode: 646 | Qmax: 314.2287 | Exploration: 0.104689 | Step: 428 | LR: 0.00150000\n",
      "| Reward: -1437 | Episode: 647 | Qmax: 314.8370 | Exploration: 0.104584 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -2350 | Episode: 648 | Qmax: 314.0676 | Exploration: 0.104480 | Step: 218 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2153 | Episode: 649 | Qmax: 312.8498 | Exploration: 0.104375 | Step: 381 | LR: 0.00150000\n",
      "| Reward: -2122 | Episode: 650 | Qmax: 311.4533 | Exploration: 0.104271 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -1579 | Episode: 651 | Qmax: 311.5913 | Exploration: 0.104167 | Step: 419 | LR: 0.00150000\n",
      "| Reward: -1263 | Episode: 652 | Qmax: 311.8647 | Exploration: 0.104062 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -1360 | Episode: 653 | Qmax: 311.0455 | Exploration: 0.103958 | Step: 290 | LR: 0.00150000\n",
      "| Reward: -1126 | Episode: 654 | Qmax: 313.0032 | Exploration: 0.103854 | Step: 137 | LR: 0.00150000\n",
      "| Reward: -1519 | Episode: 655 | Qmax: 309.7170 | Exploration: 0.103751 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1867 | Episode: 656 | Qmax: 309.2363 | Exploration: 0.103647 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -947 | Episode: 657 | Qmax: 310.1439 | Exploration: 0.103543 | Step: 165 | LR: 0.00150000\n",
      "| Reward: -1863 | Episode: 658 | Qmax: 309.0232 | Exploration: 0.103440 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1895 | Episode: 659 | Qmax: 307.8179 | Exploration: 0.103336 | Step: 276 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2117 | Episode: 660 | Qmax: 308.4309 | Exploration: 0.103233 | Step: 255 | LR: 0.00150000\n",
      "| Reward: -1170 | Episode: 661 | Qmax: 306.9044 | Exploration: 0.103130 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1772 | Episode: 662 | Qmax: 306.5704 | Exploration: 0.103026 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -1628 | Episode: 663 | Qmax: 306.8786 | Exploration: 0.102923 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -2040 | Episode: 664 | Qmax: 305.7816 | Exploration: 0.102820 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -2027 | Episode: 665 | Qmax: 304.8838 | Exploration: 0.102718 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -1675 | Episode: 666 | Qmax: 302.9523 | Exploration: 0.102615 | Step: 416 | LR: 0.00150000\n",
      "| Reward: -1285 | Episode: 667 | Qmax: 302.4545 | Exploration: 0.102512 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -1959 | Episode: 669 | Qmax: 301.5143 | Exploration: 0.102307 | Step: 367 | LR: 0.00150000\n",
      "| Reward: -916 | Episode: 670 | Qmax: 301.1004 | Exploration: 0.102205 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -1453 | Episode: 671 | Qmax: 300.0589 | Exploration: 0.102103 | Step: 320 | LR: 0.00150000\n",
      "| Reward: -1193 | Episode: 672 | Qmax: 299.5986 | Exploration: 0.102001 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1708 | Episode: 673 | Qmax: 299.2266 | Exploration: 0.101899 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -1489 | Episode: 674 | Qmax: 298.2338 | Exploration: 0.101797 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -1941 | Episode: 675 | Qmax: 297.0156 | Exploration: 0.101695 | Step: 421 | LR: 0.00150000\n",
      "| Reward: -1915 | Episode: 676 | Qmax: 296.0907 | Exploration: 0.101593 | Step: 332 | LR: 0.00150000\n",
      "| Reward: -1417 | Episode: 677 | Qmax: 296.9219 | Exploration: 0.101492 | Step: 239 | LR: 0.00150000\n",
      "| Reward: -1613 | Episode: 678 | Qmax: 295.6585 | Exploration: 0.101390 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -2214 | Episode: 679 | Qmax: 293.9264 | Exploration: 0.101289 | Step: 361 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1771 | Episode: 680 | Qmax: 293.1219 | Exploration: 0.101188 | Step: 296 | LR: 0.00150000\n",
      "| Reward: -1735 | Episode: 681 | Qmax: 292.8675 | Exploration: 0.101086 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1157 | Episode: 682 | Qmax: 292.6728 | Exploration: 0.100985 | Step: 276 | LR: 0.00150000\n",
      "| Reward: -1839 | Episode: 683 | Qmax: 291.3010 | Exploration: 0.100884 | Step: 337 | LR: 0.00150000\n",
      "| Reward: -1295 | Episode: 684 | Qmax: 291.3337 | Exploration: 0.100783 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -2019 | Episode: 685 | Qmax: 289.8259 | Exploration: 0.100683 | Step: 373 | LR: 0.00150000\n",
      "| Reward: -1757 | Episode: 686 | Qmax: 289.3245 | Exploration: 0.100582 | Step: 255 | LR: 0.00150000\n",
      "| Reward: -1751 | Episode: 687 | Qmax: 288.9359 | Exploration: 0.100481 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1282 | Episode: 688 | Qmax: 287.7183 | Exploration: 0.100381 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -1359 | Episode: 689 | Qmax: 287.1742 | Exploration: 0.100281 | Step: 307 | LR: 0.00150000\n",
      "| Reward: -1653 | Episode: 690 | Qmax: 287.0884 | Exploration: 0.100180 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -2075 | Episode: 691 | Qmax: 286.1335 | Exploration: 0.100080 | Step: 339 | LR: 0.00150000\n",
      "| Reward: -1170 | Episode: 692 | Qmax: 286.9785 | Exploration: 0.099980 | Step: 172 | LR: 0.00150000\n",
      "| Reward: -1635 | Episode: 693 | Qmax: 284.6408 | Exploration: 0.099880 | Step: 376 | LR: 0.00150000\n",
      "| Reward: -2222 | Episode: 694 | Qmax: 283.6256 | Exploration: 0.099780 | Step: 495 | LR: 0.00150000\n",
      "| Reward: -2334 | Episode: 695 | Qmax: 283.1275 | Exploration: 0.099680 | Step: 373 | LR: 0.00150000\n",
      "| Reward: -1260 | Episode: 696 | Qmax: 282.6365 | Exploration: 0.099581 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1681 | Episode: 697 | Qmax: 281.8473 | Exploration: 0.099481 | Step: 332 | LR: 0.00150000\n",
      "| Reward: -1345 | Episode: 698 | Qmax: 280.9498 | Exploration: 0.099382 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -1602 | Episode: 699 | Qmax: 280.8732 | Exploration: 0.099282 | Step: 235 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1421 | Episode: 700 | Qmax: 279.8656 | Exploration: 0.099183 | Step: 288 | LR: 0.00150000\n",
      "| Reward: -1987 | Episode: 701 | Qmax: 278.9415 | Exploration: 0.099084 | Step: 377 | LR: 0.00150000\n",
      "| Reward: -1504 | Episode: 702 | Qmax: 278.7700 | Exploration: 0.098985 | Step: 353 | LR: 0.00150000\n",
      "| Reward: -2013 | Episode: 703 | Qmax: 278.4072 | Exploration: 0.098886 | Step: 349 | LR: 0.00150000\n",
      "| Reward: -1449 | Episode: 704 | Qmax: 278.3396 | Exploration: 0.098787 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1458 | Episode: 705 | Qmax: 276.7521 | Exploration: 0.098688 | Step: 334 | LR: 0.00150000\n",
      "| Reward: -2321 | Episode: 706 | Qmax: 276.8475 | Exploration: 0.098589 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1627 | Episode: 707 | Qmax: 276.5401 | Exploration: 0.098491 | Step: 350 | LR: 0.00150000\n",
      "| Reward: -2149 | Episode: 708 | Qmax: 275.8635 | Exploration: 0.098392 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -1533 | Episode: 709 | Qmax: 276.4356 | Exploration: 0.098294 | Step: 274 | LR: 0.00150000\n",
      "| Reward: -2071 | Episode: 710 | Qmax: 275.1729 | Exploration: 0.098196 | Step: 353 | LR: 0.00150000\n",
      "| Reward: -1383 | Episode: 711 | Qmax: 274.0284 | Exploration: 0.098097 | Step: 457 | LR: 0.00150000\n",
      "| Reward: -1242 | Episode: 712 | Qmax: 272.6765 | Exploration: 0.097999 | Step: 478 | LR: 0.00150000\n",
      "| Reward: -1765 | Episode: 713 | Qmax: 272.2577 | Exploration: 0.097901 | Step: 398 | LR: 0.00150000\n",
      "| Reward: -1572 | Episode: 714 | Qmax: 270.9473 | Exploration: 0.097803 | Step: 502 | LR: 0.00150000\n",
      "| Reward: -1472 | Episode: 715 | Qmax: 271.4333 | Exploration: 0.097706 | Step: 294 | LR: 0.00150000\n",
      "| Reward: -1460 | Episode: 716 | Qmax: 270.2032 | Exploration: 0.097608 | Step: 327 | LR: 0.00150000\n",
      "| Reward: -1760 | Episode: 717 | Qmax: 269.0040 | Exploration: 0.097510 | Step: 375 | LR: 0.00150000\n",
      "| Reward: -2280 | Episode: 718 | Qmax: 268.0903 | Exploration: 0.097413 | Step: 427 | LR: 0.00150000\n",
      "| Reward: -1667 | Episode: 719 | Qmax: 268.5295 | Exploration: 0.097315 | Step: 183 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1523 | Episode: 720 | Qmax: 267.3084 | Exploration: 0.097218 | Step: 255 | LR: 0.00150000\n",
      "| Reward: -1771 | Episode: 721 | Qmax: 266.4321 | Exploration: 0.097121 | Step: 287 | LR: 0.00150000\n",
      "| Reward: -1589 | Episode: 722 | Qmax: 265.2318 | Exploration: 0.097024 | Step: 465 | LR: 0.00150000\n",
      "| Reward: -1887 | Episode: 723 | Qmax: 264.8995 | Exploration: 0.096927 | Step: 376 | LR: 0.00150000\n",
      "| Reward: -1997 | Episode: 724 | Qmax: 263.8653 | Exploration: 0.096830 | Step: 423 | LR: 0.00150000\n",
      "| Reward: -1564 | Episode: 725 | Qmax: 262.9393 | Exploration: 0.096733 | Step: 368 | LR: 0.00150000\n",
      "| Reward: -1295 | Episode: 726 | Qmax: 262.2126 | Exploration: 0.096636 | Step: 297 | LR: 0.00150000\n",
      "| Reward: -2325 | Episode: 727 | Qmax: 261.6190 | Exploration: 0.096540 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -1212 | Episode: 728 | Qmax: 261.5844 | Exploration: 0.096443 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -2370 | Episode: 729 | Qmax: 260.3553 | Exploration: 0.096347 | Step: 427 | LR: 0.00150000\n",
      "| Reward: -1472 | Episode: 730 | Qmax: 259.2627 | Exploration: 0.096250 | Step: 429 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1495 | Episode: 731 | Qmax: 259.1963 | Exploration: 0.096154 | Step: 227 | LR: 0.00150000\n",
      "| Reward: -1552 | Episode: 732 | Qmax: 259.1102 | Exploration: 0.096058 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -1774 | Episode: 733 | Qmax: 257.4386 | Exploration: 0.095962 | Step: 335 | LR: 0.00150000\n",
      "| Reward: -1788 | Episode: 734 | Qmax: 256.8932 | Exploration: 0.095866 | Step: 241 | LR: 0.00150000\n",
      "| Reward: -2274 | Episode: 735 | Qmax: 256.5508 | Exploration: 0.095770 | Step: 448 | LR: 0.00150000\n",
      "| Reward: -2303 | Episode: 736 | Qmax: 255.5041 | Exploration: 0.095674 | Step: 405 | LR: 0.00150000\n",
      "| Reward: -1964 | Episode: 737 | Qmax: 254.6213 | Exploration: 0.095579 | Step: 354 | LR: 0.00150000\n",
      "| Reward: -1301 | Episode: 738 | Qmax: 254.6712 | Exploration: 0.095483 | Step: 402 | LR: 0.00150000\n",
      "| Reward: -1812 | Episode: 739 | Qmax: 253.8170 | Exploration: 0.095387 | Step: 391 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1352 | Episode: 740 | Qmax: 252.8281 | Exploration: 0.095292 | Step: 282 | LR: 0.00150000\n",
      "| Reward: -1768 | Episode: 741 | Qmax: 252.1705 | Exploration: 0.095197 | Step: 365 | LR: 0.00150000\n",
      "| Reward: -1126 | Episode: 742 | Qmax: 251.7548 | Exploration: 0.095102 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -1694 | Episode: 743 | Qmax: 251.3098 | Exploration: 0.095006 | Step: 390 | LR: 0.00150000\n",
      "| Reward: -1695 | Episode: 744 | Qmax: 251.0137 | Exploration: 0.094911 | Step: 400 | LR: 0.00150000\n",
      "| Reward: -1464 | Episode: 745 | Qmax: 250.0186 | Exploration: 0.094817 | Step: 286 | LR: 0.00150000\n",
      "| Reward: -1380 | Episode: 746 | Qmax: 249.3110 | Exploration: 0.094722 | Step: 337 | LR: 0.00150000\n",
      "| Reward: -2392 | Episode: 747 | Qmax: 249.1479 | Exploration: 0.094627 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -1644 | Episode: 748 | Qmax: 247.8125 | Exploration: 0.094532 | Step: 385 | LR: 0.00150000\n",
      "| Reward: -1454 | Episode: 749 | Qmax: 247.4546 | Exploration: 0.094438 | Step: 312 | LR: 0.00150000\n",
      "| Reward: -2015 | Episode: 750 | Qmax: 246.3704 | Exploration: 0.094343 | Step: 540 | LR: 0.00150000\n",
      "| Reward: -2146 | Episode: 751 | Qmax: 245.7964 | Exploration: 0.094249 | Step: 419 | LR: 0.00150000\n",
      "| Reward: -2326 | Episode: 752 | Qmax: 244.0778 | Exploration: 0.094155 | Step: 383 | LR: 0.00150000\n",
      "| Reward: -1379 | Episode: 753 | Qmax: 243.9667 | Exploration: 0.094061 | Step: 327 | LR: 0.00150000\n",
      "| Reward: -2037 | Episode: 754 | Qmax: 243.7711 | Exploration: 0.093967 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -3030 | Episode: 755 | Qmax: 242.1377 | Exploration: 0.093873 | Step: 664 | LR: 0.00150000\n",
      "| Reward: -4636 | Episode: 756 | Qmax: 240.4996 | Exploration: 0.093873 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1526 | Episode: 757 | Qmax: 239.8730 | Exploration: 0.093779 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1724 | Episode: 758 | Qmax: 239.3653 | Exploration: 0.093685 | Step: 447 | LR: 0.00150000\n",
      "| Reward: -1679 | Episode: 759 | Qmax: 238.1110 | Exploration: 0.093591 | Step: 438 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -901 | Episode: 760 | Qmax: 237.5761 | Exploration: 0.093498 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1377 | Episode: 761 | Qmax: 237.4995 | Exploration: 0.093404 | Step: 298 | LR: 0.00150000\n",
      "| Reward: -1431 | Episode: 762 | Qmax: 237.6464 | Exploration: 0.093311 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -2769 | Episode: 763 | Qmax: 236.1370 | Exploration: 0.093218 | Step: 565 | LR: 0.00150000\n",
      "| Reward: -1993 | Episode: 764 | Qmax: 235.7345 | Exploration: 0.093124 | Step: 347 | LR: 0.00150000\n",
      "| Reward: -4673 | Episode: 765 | Qmax: 234.0215 | Exploration: 0.093031 | Step: 723 | LR: 0.00150000\n",
      "| Reward: -2484 | Episode: 766 | Qmax: 232.6502 | Exploration: 0.092938 | Step: 658 | LR: 0.00150000\n",
      "| Reward: -2728 | Episode: 767 | Qmax: 232.0710 | Exploration: 0.092845 | Step: 488 | LR: 0.00150000\n",
      "| Reward: -2192 | Episode: 768 | Qmax: 231.7004 | Exploration: 0.092752 | Step: 303 | LR: 0.00150000\n",
      "| Reward: -1275 | Episode: 769 | Qmax: 231.0214 | Exploration: 0.092660 | Step: 385 | LR: 0.00150000\n",
      "| Reward: -1876 | Episode: 770 | Qmax: 229.7815 | Exploration: 0.092567 | Step: 491 | LR: 0.00150000\n",
      "| Reward: -1734 | Episode: 771 | Qmax: 229.7096 | Exploration: 0.092474 | Step: 349 | LR: 0.00150000\n",
      "| Reward: -2929 | Episode: 772 | Qmax: 228.5989 | Exploration: 0.092382 | Step: 383 | LR: 0.00150000\n",
      "| Reward: -1862 | Episode: 773 | Qmax: 228.5472 | Exploration: 0.092290 | Step: 306 | LR: 0.00150000\n",
      "| Reward: -5095 | Episode: 774 | Qmax: 226.8575 | Exploration: 0.092290 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2043 | Episode: 775 | Qmax: 226.2012 | Exploration: 0.092197 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -2935 | Episode: 776 | Qmax: 224.8016 | Exploration: 0.092105 | Step: 641 | LR: 0.00150000\n",
      "| Reward: -2435 | Episode: 777 | Qmax: 223.4937 | Exploration: 0.092013 | Step: 546 | LR: 0.00150000\n",
      "| Reward: -3993 | Episode: 778 | Qmax: 222.4302 | Exploration: 0.091921 | Step: 952 | LR: 0.00150000\n",
      "| Reward: -2996 | Episode: 779 | Qmax: 220.9853 | Exploration: 0.091829 | Step: 702 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1823 | Episode: 780 | Qmax: 221.0420 | Exploration: 0.091737 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -3777 | Episode: 781 | Qmax: 219.1474 | Exploration: 0.091645 | Step: 997 | LR: 0.00150000\n",
      "| Reward: -1747 | Episode: 782 | Qmax: 218.5109 | Exploration: 0.091554 | Step: 362 | LR: 0.00150000\n",
      "| Reward: -1622 | Episode: 783 | Qmax: 218.2691 | Exploration: 0.091462 | Step: 327 | LR: 0.00150000\n",
      "| Reward: -4501 | Episode: 784 | Qmax: 216.7134 | Exploration: 0.091462 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2109 | Episode: 785 | Qmax: 216.1029 | Exploration: 0.091371 | Step: 409 | LR: 0.00150000\n",
      "| Reward: -4420 | Episode: 786 | Qmax: 214.4895 | Exploration: 0.091371 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2842 | Episode: 787 | Qmax: 213.3496 | Exploration: 0.091279 | Step: 566 | LR: 0.00150000\n",
      "| Reward: -3243 | Episode: 788 | Qmax: 212.5666 | Exploration: 0.091188 | Step: 670 | LR: 0.00150000\n",
      "| Reward: -1450 | Episode: 789 | Qmax: 211.9890 | Exploration: 0.091097 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -2937 | Episode: 790 | Qmax: 210.7453 | Exploration: 0.091006 | Step: 616 | LR: 0.00150000\n",
      "| Reward: -1504 | Episode: 791 | Qmax: 210.4916 | Exploration: 0.090915 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -2714 | Episode: 792 | Qmax: 209.9822 | Exploration: 0.090824 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -4414 | Episode: 793 | Qmax: 208.5724 | Exploration: 0.090733 | Step: 941 | LR: 0.00150000\n",
      "| Reward: -2869 | Episode: 794 | Qmax: 207.3455 | Exploration: 0.090642 | Step: 539 | LR: 0.00150000\n",
      "| Reward: -3622 | Episode: 795 | Qmax: 206.5082 | Exploration: 0.090552 | Step: 590 | LR: 0.00150000\n",
      "| Reward: -1871 | Episode: 796 | Qmax: 206.6216 | Exploration: 0.090461 | Step: 288 | LR: 0.00150000\n",
      "| Reward: -1829 | Episode: 797 | Qmax: 205.9376 | Exploration: 0.090371 | Step: 282 | LR: 0.00150000\n",
      "| Reward: -1669 | Episode: 798 | Qmax: 205.5320 | Exploration: 0.090280 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -1583 | Episode: 799 | Qmax: 205.1239 | Exploration: 0.090190 | Step: 198 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2920 | Episode: 800 | Qmax: 203.8022 | Exploration: 0.090100 | Step: 860 | LR: 0.00150000\n",
      "| Reward: -2717 | Episode: 801 | Qmax: 203.0438 | Exploration: 0.090010 | Step: 621 | LR: 0.00150000\n",
      "| Reward: -3060 | Episode: 802 | Qmax: 202.5105 | Exploration: 0.089920 | Step: 568 | LR: 0.00150000\n",
      "| Reward: -1212 | Episode: 803 | Qmax: 201.7650 | Exploration: 0.089830 | Step: 295 | LR: 0.00150000\n",
      "| Reward: -3580 | Episode: 804 | Qmax: 201.1239 | Exploration: 0.089740 | Step: 881 | LR: 0.00150000\n",
      "| Reward: -2190 | Episode: 805 | Qmax: 199.8001 | Exploration: 0.089650 | Step: 490 | LR: 0.00150000\n",
      "| Reward: -2041 | Episode: 806 | Qmax: 199.8828 | Exploration: 0.089561 | Step: 287 | LR: 0.00150000\n",
      "| Reward: -2146 | Episode: 807 | Qmax: 199.3884 | Exploration: 0.089471 | Step: 329 | LR: 0.00150000\n",
      "| Reward: -1468 | Episode: 808 | Qmax: 198.8714 | Exploration: 0.089382 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -1726 | Episode: 809 | Qmax: 198.7344 | Exploration: 0.089292 | Step: 296 | LR: 0.00150000\n",
      "| Reward: -3596 | Episode: 810 | Qmax: 196.7589 | Exploration: 0.089203 | Step: 852 | LR: 0.00150000\n",
      "| Reward: -1927 | Episode: 811 | Qmax: 195.8723 | Exploration: 0.089114 | Step: 497 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1341 | Episode: 812 | Qmax: 195.3415 | Exploration: 0.089025 | Step: 370 | LR: 0.00150000\n",
      "| Reward: -1950 | Episode: 813 | Qmax: 194.5038 | Exploration: 0.088936 | Step: 331 | LR: 0.00150000\n",
      "| Reward: -2494 | Episode: 814 | Qmax: 193.8507 | Exploration: 0.088847 | Step: 488 | LR: 0.00150000\n",
      "| Reward: -1162 | Episode: 815 | Qmax: 194.0977 | Exploration: 0.088758 | Step: 209 | LR: 0.00150000\n",
      "| Reward: -1914 | Episode: 816 | Qmax: 192.5241 | Exploration: 0.088669 | Step: 493 | LR: 0.00150000\n",
      "| Reward: -4096 | Episode: 817 | Qmax: 190.8537 | Exploration: 0.088669 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1841 | Episode: 818 | Qmax: 190.3171 | Exploration: 0.088580 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -1359 | Episode: 819 | Qmax: 189.8210 | Exploration: 0.088492 | Step: 487 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1705 | Episode: 820 | Qmax: 188.7089 | Exploration: 0.088403 | Step: 392 | LR: 0.00150000\n",
      "| Reward: -1281 | Episode: 821 | Qmax: 188.2374 | Exploration: 0.088315 | Step: 409 | LR: 0.00150000\n",
      "| Reward: -1238 | Episode: 822 | Qmax: 187.2543 | Exploration: 0.088227 | Step: 285 | LR: 0.00150000\n",
      "| Reward: -1773 | Episode: 823 | Qmax: 186.2215 | Exploration: 0.088138 | Step: 451 | LR: 0.00150000\n",
      "| Reward: -2557 | Episode: 824 | Qmax: 185.4467 | Exploration: 0.088050 | Step: 389 | LR: 0.00150000\n",
      "| Reward: -3340 | Episode: 825 | Qmax: 183.7323 | Exploration: 0.088050 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3295 | Episode: 826 | Qmax: 181.5090 | Exploration: 0.088050 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1862 | Episode: 827 | Qmax: 180.5455 | Exploration: 0.087962 | Step: 513 | LR: 0.00150000\n",
      "| Reward: -2147 | Episode: 828 | Qmax: 179.2609 | Exploration: 0.087874 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -1855 | Episode: 829 | Qmax: 178.2166 | Exploration: 0.087786 | Step: 515 | LR: 0.00150000\n",
      "| Reward: -1625 | Episode: 830 | Qmax: 177.8431 | Exploration: 0.087699 | Step: 393 | LR: 0.00150000\n",
      "| Reward: -1419 | Episode: 831 | Qmax: 177.0347 | Exploration: 0.087611 | Step: 277 | LR: 0.00150000\n",
      "| Reward: -2034 | Episode: 832 | Qmax: 176.5130 | Exploration: 0.087523 | Step: 298 | LR: 0.00150000\n",
      "| Reward: -2767 | Episode: 833 | Qmax: 174.9613 | Exploration: 0.087436 | Step: 779 | LR: 0.00150000\n",
      "| Reward: -2194 | Episode: 834 | Qmax: 173.2936 | Exploration: 0.087348 | Step: 890 | LR: 0.00150000\n",
      "| Reward: -1546 | Episode: 835 | Qmax: 172.2207 | Exploration: 0.087261 | Step: 449 | LR: 0.00150000\n",
      "| Reward: -2996 | Episode: 836 | Qmax: 170.6509 | Exploration: 0.087174 | Step: 783 | LR: 0.00150000\n",
      "| Reward: -2386 | Episode: 837 | Qmax: 169.2281 | Exploration: 0.087086 | Step: 677 | LR: 0.00150000\n",
      "| Reward: -2998 | Episode: 838 | Qmax: 167.4499 | Exploration: 0.087086 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1149 | Episode: 839 | Qmax: 166.9467 | Exploration: 0.086999 | Step: 241 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1649 | Episode: 840 | Qmax: 165.4913 | Exploration: 0.086912 | Step: 408 | LR: 0.00150000\n",
      "| Reward: -1788 | Episode: 841 | Qmax: 164.7203 | Exploration: 0.086825 | Step: 457 | LR: 0.00150000\n",
      "| Reward: -2268 | Episode: 842 | Qmax: 163.5788 | Exploration: 0.086739 | Step: 451 | LR: 0.00150000\n",
      "| Reward: -2340 | Episode: 843 | Qmax: 162.4513 | Exploration: 0.086652 | Step: 640 | LR: 0.00150000\n",
      "| Reward: -1636 | Episode: 844 | Qmax: 161.8652 | Exploration: 0.086565 | Step: 368 | LR: 0.00150000\n",
      "| Reward: -1958 | Episode: 845 | Qmax: 160.7200 | Exploration: 0.086479 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -2982 | Episode: 846 | Qmax: 159.4840 | Exploration: 0.086392 | Step: 859 | LR: 0.00150000\n",
      "| Reward: -2026 | Episode: 847 | Qmax: 158.4346 | Exploration: 0.086306 | Step: 434 | LR: 0.00150000\n",
      "| Reward: -2152 | Episode: 848 | Qmax: 157.6353 | Exploration: 0.086220 | Step: 443 | LR: 0.00150000\n",
      "| Reward: -4231 | Episode: 849 | Qmax: 156.2297 | Exploration: 0.086220 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2632 | Episode: 850 | Qmax: 154.8986 | Exploration: 0.086133 | Step: 545 | LR: 0.00150000\n",
      "| Reward: -1438 | Episode: 851 | Qmax: 154.0760 | Exploration: 0.086047 | Step: 386 | LR: 0.00150000\n",
      "| Reward: -2624 | Episode: 852 | Qmax: 152.9055 | Exploration: 0.085961 | Step: 726 | LR: 0.00150000\n",
      "| Reward: -2032 | Episode: 853 | Qmax: 151.4869 | Exploration: 0.085875 | Step: 494 | LR: 0.00150000\n",
      "| Reward: -2130 | Episode: 854 | Qmax: 150.8248 | Exploration: 0.085789 | Step: 448 | LR: 0.00150000\n",
      "| Reward: -3691 | Episode: 855 | Qmax: 149.5817 | Exploration: 0.085789 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2907 | Episode: 856 | Qmax: 147.9035 | Exploration: 0.085703 | Step: 793 | LR: 0.00150000\n",
      "| Reward: -2067 | Episode: 857 | Qmax: 146.6130 | Exploration: 0.085618 | Step: 556 | LR: 0.00150000\n",
      "| Reward: -2329 | Episode: 858 | Qmax: 145.4700 | Exploration: 0.085532 | Step: 593 | LR: 0.00150000\n",
      "| Reward: -2825 | Episode: 859 | Qmax: 144.2749 | Exploration: 0.085447 | Step: 549 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1629 | Episode: 860 | Qmax: 143.1847 | Exploration: 0.085361 | Step: 622 | LR: 0.00150000\n",
      "| Reward: -1537 | Episode: 861 | Qmax: 142.1944 | Exploration: 0.085276 | Step: 404 | LR: 0.00150000\n"
     ]
    }
   ],
   "source": [
    "config=tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "       \n",
    "    state_dim = 3\n",
    "    action_dim = 5\n",
    "    \n",
    "    if RESTORE:\n",
    "        Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR, DEVICE)\n",
    "        Qnet.saver.restore(sess, RESTORE_PATH)\n",
    "        train(sess, env, Qnet, prod_planner)\n",
    "        \n",
    "    else:\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "        env.seed(RANDOM_SEED)\n",
    "    \n",
    "        Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR, DEVICE)\n",
    "\n",
    "        train(sess, env, Qnet, prod_planner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(prod_planner.opt_rabin) == 1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(env.s,(10,10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(env.s,(10,10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns,r,_,_ = env.step(1)\n",
    "print np.unravel_index(ns,(10,10,5)),r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_planner.get_global_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.last_ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.last_dynamic_coord_dict[(2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.coord_dict[(2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.dynamic_coord_dict[(2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.possible_states(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[env.rabin.graph[str(1)][str(0)][k][\"label\"] for k in range(len(env.rabin.graph[str(1)][str(0)]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.check_ap(\"C\", u' !A&!T&C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.graph[\"0\"][\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env._calculate_transition_prob((4, 3, 1), [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(221,(10,10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = (4,3,1)\n",
    "delta=[0,1]\n",
    "delta_list = [[-1, 0], [1, 0], [0, -1], [0, 1], [0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_position_candidates = [np.array(current[:2]) + np.array(delta)]\n",
    "new_position_candidates += [np.array(current[:2]) + np.array(i) for i in delta_list if i != delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_positions = [env._limit_coordinates(i).astype(int) for i in new_position_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_rabin_state = [env.rabin.next_state(current, tuple(i)) for i in new_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.next_state((4,3,1),(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.coord_dict[(2,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.next_state((4,3,1),[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.deadlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(prod_planner.opt_rabin) == 8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CurrentWorld(LTL.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_planner = Prod_Planning(env, LTL.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_planner.update_wfts_ap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.dynamic_coord_dict[(5,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.last_dynamic_coord_dict[(5,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_planner.region_list[np.ravel_multi_index((5,5),(10,10))].ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.last_ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
