{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from full_prod_DRA import *\n",
    "from buchi import buchi_from_ltl\n",
    "import numpy as np\n",
    "from env_sensing_error import *\n",
    "import scipy\n",
    "# from plot_path_for_prod import *\n",
    "from graphviz import Source\n",
    "from qnetwork import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "# from Plot_Path import *\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from dra_planning import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, env, qnet, prod_planner):\n",
    "    \n",
    "    global EXPLORATION_RATE\n",
    "    global GUIDE_RATE\n",
    "  \n",
    "    summary_ops, summary_vars = build_summaries()\n",
    "    if not RESTORE:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(SUMMARY_DIR, sess.graph)\n",
    "    \n",
    "    qnet.update_target()\n",
    "    \n",
    "    replay_buffer = ReplayBuffer(BUFFER_SIZE, RANDOM_SEED)\n",
    "    \n",
    "    while len(prod_planner.opt_path) == 0:\n",
    "        env.step(np.random.randint(0,qnet.action_dim))\n",
    "        prod_planner.update_wfts_ap()\n",
    "        env.update_dynamic_rabin()\n",
    "        prod_planner.get_global_opt()\n",
    "    print \"Global Solution Found\"\n",
    "    prod_planner.get_opt_rabin()\n",
    "    \n",
    "    saved_dra_planners = {}\n",
    "    \n",
    "    for num_epi in range(MAX_EPISODES):\n",
    "        \n",
    "#         print \"Epi: \", num_epi\n",
    "\n",
    "        s = env.reset()\n",
    "        s = list(np.unravel_index(s, env.shape))\n",
    "#         prod_planner.replace_region_list()\n",
    "        prod_planner.update_wfts_ap()\n",
    "\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "        \n",
    "        reward_list = []\n",
    "        \n",
    "        train_time = 0\n",
    "        batch_time = 0\n",
    "        gym_time = 0\n",
    "        guide_time = 0\n",
    "\n",
    "        for j in range(MAX_EPISODE_LEN):\n",
    "            \n",
    "#             print \"Step: \", j\n",
    "            \n",
    "            gym_start = time.time()\n",
    "\n",
    "            rand_num = np.random.rand(1)\n",
    "    \n",
    "            if rand_num <= EXPLORATION_RATE:\n",
    "                a = np.random.randint(0,qnet.action_dim)\n",
    "                s2, r, terminal, info = env.step(a)\n",
    "                \n",
    "            elif rand_num <= GUIDE_RATE+EXPLORATION_RATE and rand_num > EXPLORATION_RATE:\n",
    "#                 print \"GUIDE\"\n",
    "                guide_start = time.time()\n",
    "                \n",
    "                if rand_num > EXPLORATION_RATE + 0.9*GUIDE_RATE:\n",
    "                # Only update global plan with 0.2 prob for efficiency\n",
    "                    env.update_dynamic_rabin()\n",
    "                    prod_planner.get_global_opt()\n",
    "                    prod_planner.get_opt_rabin()\n",
    "                    \n",
    "                if len(prod_planner.opt_path) > 0:\n",
    "#                     print \"S: \", s\n",
    "#                     print \"last a: \", a\n",
    "                    new_ltl = prod_planner.get_next_ltl(s[-1])\n",
    "                    \n",
    "#                     if new_ltl in saved_dra_planners.keys():\n",
    "                    guide_path = prod_planner.get_local_opt(s[:-1], new_ltl)\n",
    "                    if guide_path != None:\n",
    "#                         print \"GUIDE\"\n",
    "                        a = convert_path_to_action(guide_path)\n",
    "                    else:\n",
    "                        a = np.random.randint(0,qnet.action_dim)\n",
    "#                     else:\n",
    "#                         guide_path = prod_planner.get_local_opt(s[:-1], new_ltl)\n",
    "#                         saved_dra_planners[new_ltl] = prod_planner.dra_full_prod\n",
    "#                         if guide_path != None:\n",
    "#                             a = convert_path_to_action(guide_path)\n",
    "#                         else:\n",
    "#                             a = np.random.randint(0,qnet.action_dim)\n",
    "                        \n",
    "                else:\n",
    "                    a = np.random.randint(0,qnet.action_dim)\n",
    "                \n",
    "                s2, r, terminal, info = env.step(a)\n",
    "                \n",
    "                guide_time += time.time() - guide_start\n",
    "                \n",
    "            else:\n",
    "                a = np.argmax(qnet.predict_q(np.reshape(s, (1, qnet.state_dim))))\n",
    "                s2, r, terminal, info = env.step(a)\n",
    "\n",
    "            prod_planner.update_wfts_ap()\n",
    "                \n",
    "            gym_time += time.time() - gym_start\n",
    "            \n",
    "            batch_start = time.time()\n",
    "            \n",
    "            s2 = list(np.unravel_index(s2, env.shape))\n",
    "\n",
    "            replay_buffer.add(np.reshape(s, (qnet.state_dim,)), np.reshape(a, (1,)), r,\n",
    "                              terminal, np.reshape(s2, (qnet.state_dim,)))\n",
    "            batch_time += time.time() - batch_start\n",
    "\n",
    "            # Keep adding experience to the memory until\n",
    "            # there are at least minibatch size samples\n",
    "            if replay_buffer.size() > MINIBATCH_SIZE:\n",
    "                \n",
    "                batch_start = time.time()\n",
    "                s_batch, a_batch, r_batch, t_batch, s2_batch = replay_buffer.sample_batch(MINIBATCH_SIZE)\n",
    "#                 print \"sbatch: \", s_batch\n",
    "                # Calculate targets\n",
    "                target_q = qnet.predect_target(s2_batch)\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(MINIBATCH_SIZE):\n",
    "                    if t_batch[k]:\n",
    "                        y_i.append(r_batch[k])\n",
    "                    else:\n",
    "                        y_i.append(r_batch[k] + GAMMA * np.amax(target_q[k]))\n",
    "                        \n",
    "                batch_time += time.time() - batch_start\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                train_start = time.time()\n",
    "                predicted_q_value, _ = qnet.train(s_batch, a_batch, np.reshape(y_i, (MINIBATCH_SIZE, 1)), num_epi)\n",
    "\n",
    "                ep_ave_max_q += np.amax(predicted_q_value)\n",
    "                \n",
    "                # Update target networks\n",
    "                qnet.update_target()\n",
    "\n",
    "                train_time += time.time() - train_start\n",
    "\n",
    "            s = s2\n",
    "            ep_reward += r\n",
    "\n",
    "            if terminal or j == MAX_EPISODE_LEN-1:\n",
    "                \n",
    "                if EXPLORATION_RATE > 0.02 and terminal:\n",
    "                    EXPLORATION_RATE = EXPLORATION_RATE*0.999\n",
    "                if GUIDE_RATE > 0.05 and terminal:\n",
    "                    GUIDE_RATE = GUIDE_RATE*0.999\n",
    "                    \n",
    "                reward_list += [ep_reward]\n",
    "                \n",
    "                if np.average(reward_list[-10:]) > LR_DECAY_TRUNCATION:\n",
    "                    qnet.decay_learning_rate(0.98)\n",
    "\n",
    "                print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f} | Exploration: {:.6f} | Step: {:d} | LR: {:.8f}'.format(int(ep_reward), \\\n",
    "                        num_epi, (ep_ave_max_q / float(j)), EXPLORATION_RATE, j, qnet.get_learning_rate()))\n",
    "                \n",
    "                f = open(\"stats/\" + file_appendix + \"_stats.txt\", \"ab\")\n",
    "                f.write(\"| Reward: \" + str(int(ep_reward)) \n",
    "                        +\" | Episode: \" + str(num_epi) \n",
    "                        + \" | Qmax: \" + str(ep_ave_max_q / float(j)) \n",
    "                        + \" | Exploration: \" + str(EXPLORATION_RATE)\n",
    "                        + \" | Step: \" + str(j)\n",
    "                        + \" | LR:\" + str(qnet.get_learning_rate()) + \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                f = open(\"stats/\" + file_appendix + \"_stats_time.txt\", \"ab\")\n",
    "                f.write(\" | Episode: \" + str(num_epi) \n",
    "                        + \" | Train: \" + str(train_time) \n",
    "                        + \" | Gym: \" + str(gym_time)\n",
    "                        + \" | Batch: \" + str(batch_time) \n",
    "                        + \" | Guide: \" + str(guide_time)\n",
    "                        + \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B\"\n",
    "# LTL = \"[] (p1 -> !(X p1) U (p2 || p3) ) && []<>p1\"\n",
    "# LTL = \"T && []<>A && []<>B\"\n",
    "# LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B && []!C && []!D\"\n",
    "LTL = \"<>(A && <>(B && <> T)) && []<>A && []<>B && []!C\"\n",
    "# LTL = \"<>(A && <>(B && <> T))\"\n",
    "# LTL = \"<>(A && <>B) && <>[]T && []!C\"\n",
    "# LTL = \"<>(A && <>T) && []!C\"\n",
    "# LTL = \"<>(A && <>(B && <>T)) && []<>(A||T) && []<>B && []!C\"\n",
    "# LTL = \"<>(A && <>(B && <>T)) && []!C\"\n",
    "# LTL = \"<>(A && <>D) && <>(B && <>E) && []<>T && []<>(D || E) && []!C\"\n",
    "\n",
    "LEARNING_RATE = 0.0015\n",
    "GAMMA = 0.99\n",
    "# GAMMA = 0.7\n",
    "TAU = 0.001\n",
    "BUFFER_SIZE = 10**6\n",
    "MINIBATCH_SIZE = 64\n",
    "RANDOM_SEED = 210\n",
    "MAX_EPISODES = 50000\n",
    "MAX_EPISODE_LEN = 1000\n",
    "# file_appendix = \"Guide_Planning_\" + time.ctime()[4:16].replace(\"  \",\"\").replace(\" \",\"_\").replace(\":\",\"-\") + \"_large_\" + LTL\n",
    "file_appendix = \"Guide_Planning_Medium_Mar_6_morning\"\n",
    "SUMMARY_DIR = './results/tf_ddqn_' + file_appendix\n",
    "SAVE_DIR = \"./saved_model/\" + file_appendix + \"/ddqn.ckpt\"\n",
    "EXPLORATION_RATE = 0.2\n",
    "GUIDE_RATE = 0.6\n",
    "LR_DECAY_TRUNCATION = -350\n",
    "RESTORE = 1\n",
    "RESTORE_PATH = \"./saved_model/Guide_Planning_Mar6_16-28_large_A_T_NotC/ddqn.ckpt\"\n",
    "if sys.platform == \"darwin\":\n",
    "    DEVICE = \"/device:CPU:0\"\n",
    "else:\n",
    "    DEVICE = \"/device:GPU:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = CurrentWorld(LTL)\n",
    "prod_planner = Prod_Planning(env, LTL)\n",
    "# with open(\"my.dot\", \"r\") as dotfile:\n",
    "#     text = dotfile.read()\n",
    "# Source(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/Guide_Planning_Mar6_16-28_large_A_T_NotC/ddqn.ckpt\n",
      "Global Solution Found\n",
      "DDQN Saved\n",
      "| Reward: -2294 | Episode: 0 | Qmax: 126.4919 | Exploration: 0.199800 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -2879 | Episode: 1 | Qmax: 263.6668 | Exploration: 0.199600 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -4331 | Episode: 2 | Qmax: 264.5301 | Exploration: 0.199401 | Step: 273 | LR: 0.00150000\n",
      "| Reward: -2392 | Episode: 3 | Qmax: 265.4137 | Exploration: 0.199201 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -2468 | Episode: 4 | Qmax: 266.0963 | Exploration: 0.199002 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -2589 | Episode: 5 | Qmax: 267.6059 | Exploration: 0.198803 | Step: 160 | LR: 0.00150000\n",
      "| Reward: -4488 | Episode: 6 | Qmax: 268.1441 | Exploration: 0.198604 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -2977 | Episode: 7 | Qmax: 268.3345 | Exploration: 0.198406 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -2814 | Episode: 8 | Qmax: 268.4809 | Exploration: 0.198207 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -1866 | Episode: 9 | Qmax: 270.2187 | Exploration: 0.198009 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -2326 | Episode: 10 | Qmax: 268.3755 | Exploration: 0.197811 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -4416 | Episode: 11 | Qmax: 267.9506 | Exploration: 0.197613 | Step: 322 | LR: 0.00150000\n",
      "| Reward: -2924 | Episode: 12 | Qmax: 268.9162 | Exploration: 0.197416 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -2687 | Episode: 13 | Qmax: 270.0371 | Exploration: 0.197218 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -2948 | Episode: 14 | Qmax: 269.0745 | Exploration: 0.197021 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -2105 | Episode: 15 | Qmax: 269.1293 | Exploration: 0.196824 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -2538 | Episode: 16 | Qmax: 267.8875 | Exploration: 0.196627 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -1743 | Episode: 17 | Qmax: 269.5528 | Exploration: 0.196430 | Step: 169 | LR: 0.00150000\n",
      "| Reward: -2622 | Episode: 18 | Qmax: 269.6290 | Exploration: 0.196234 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -3379 | Episode: 19 | Qmax: 269.2704 | Exploration: 0.196038 | Step: 293 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3435 | Episode: 20 | Qmax: 270.3838 | Exploration: 0.195842 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -2459 | Episode: 21 | Qmax: 270.8812 | Exploration: 0.195646 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -2749 | Episode: 22 | Qmax: 272.3388 | Exploration: 0.195450 | Step: 239 | LR: 0.00150000\n",
      "| Reward: -3574 | Episode: 23 | Qmax: 273.7721 | Exploration: 0.195255 | Step: 317 | LR: 0.00150000\n",
      "| Reward: -2966 | Episode: 24 | Qmax: 273.3042 | Exploration: 0.195060 | Step: 321 | LR: 0.00150000\n",
      "| Reward: -2182 | Episode: 25 | Qmax: 273.9753 | Exploration: 0.194864 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -1886 | Episode: 26 | Qmax: 273.6368 | Exploration: 0.194670 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -2239 | Episode: 27 | Qmax: 274.1971 | Exploration: 0.194475 | Step: 143 | LR: 0.00150000\n",
      "| Reward: -4062 | Episode: 28 | Qmax: 273.6674 | Exploration: 0.194280 | Step: 301 | LR: 0.00150000\n",
      "| Reward: -2080 | Episode: 29 | Qmax: 274.8753 | Exploration: 0.194086 | Step: 155 | LR: 0.00150000\n",
      "| Reward: -1679 | Episode: 30 | Qmax: 276.5875 | Exploration: 0.193892 | Step: 123 | LR: 0.00150000\n",
      "| Reward: -2395 | Episode: 31 | Qmax: 274.6937 | Exploration: 0.193698 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -4188 | Episode: 32 | Qmax: 274.3781 | Exploration: 0.193505 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -2780 | Episode: 33 | Qmax: 275.3126 | Exploration: 0.193311 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -3824 | Episode: 35 | Qmax: 274.5783 | Exploration: 0.192925 | Step: 342 | LR: 0.00150000\n",
      "| Reward: -3110 | Episode: 36 | Qmax: 272.2456 | Exploration: 0.192732 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -2252 | Episode: 37 | Qmax: 274.1871 | Exploration: 0.192539 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -2545 | Episode: 38 | Qmax: 272.6951 | Exploration: 0.192346 | Step: 179 | LR: 0.00150000\n",
      "| Reward: -3456 | Episode: 39 | Qmax: 273.7170 | Exploration: 0.192154 | Step: 190 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1594 | Episode: 40 | Qmax: 273.5044 | Exploration: 0.191962 | Step: 173 | LR: 0.00150000\n",
      "| Reward: -3113 | Episode: 41 | Qmax: 273.5455 | Exploration: 0.191770 | Step: 279 | LR: 0.00150000\n",
      "| Reward: -2061 | Episode: 42 | Qmax: 273.7489 | Exploration: 0.191578 | Step: 154 | LR: 0.00150000\n",
      "| Reward: -2681 | Episode: 43 | Qmax: 273.3383 | Exploration: 0.191387 | Step: 180 | LR: 0.00150000\n",
      "| Reward: -2184 | Episode: 44 | Qmax: 273.0883 | Exploration: 0.191195 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1959 | Episode: 45 | Qmax: 273.9806 | Exploration: 0.191004 | Step: 160 | LR: 0.00150000\n",
      "| Reward: -2749 | Episode: 46 | Qmax: 273.9720 | Exploration: 0.190813 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -3283 | Episode: 47 | Qmax: 274.0206 | Exploration: 0.190622 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -2132 | Episode: 48 | Qmax: 273.8393 | Exploration: 0.190432 | Step: 180 | LR: 0.00150000\n",
      "| Reward: -2961 | Episode: 49 | Qmax: 272.2043 | Exploration: 0.190241 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -1940 | Episode: 50 | Qmax: 272.7717 | Exploration: 0.190051 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -3484 | Episode: 51 | Qmax: 273.5670 | Exploration: 0.189861 | Step: 209 | LR: 0.00150000\n",
      "| Reward: -2981 | Episode: 52 | Qmax: 273.9348 | Exploration: 0.189671 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -3245 | Episode: 53 | Qmax: 273.6389 | Exploration: 0.189481 | Step: 303 | LR: 0.00150000\n",
      "| Reward: -3030 | Episode: 54 | Qmax: 274.8877 | Exploration: 0.189292 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -2712 | Episode: 55 | Qmax: 275.0604 | Exploration: 0.189103 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -2741 | Episode: 56 | Qmax: 276.6294 | Exploration: 0.188913 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -3598 | Episode: 57 | Qmax: 275.1711 | Exploration: 0.188725 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -2619 | Episode: 58 | Qmax: 275.7811 | Exploration: 0.188536 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -1575 | Episode: 59 | Qmax: 275.3109 | Exploration: 0.188347 | Step: 181 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3249 | Episode: 60 | Qmax: 274.3851 | Exploration: 0.188159 | Step: 307 | LR: 0.00150000\n",
      "| Reward: -2348 | Episode: 61 | Qmax: 276.3082 | Exploration: 0.187971 | Step: 153 | LR: 0.00150000\n",
      "| Reward: -3189 | Episode: 62 | Qmax: 274.0096 | Exploration: 0.187783 | Step: 274 | LR: 0.00150000\n",
      "| Reward: -2160 | Episode: 63 | Qmax: 275.6206 | Exploration: 0.187595 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -2145 | Episode: 64 | Qmax: 277.0636 | Exploration: 0.187407 | Step: 202 | LR: 0.00150000\n",
      "| Reward: -2339 | Episode: 65 | Qmax: 276.0931 | Exploration: 0.187220 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -3502 | Episode: 66 | Qmax: 276.3202 | Exploration: 0.187033 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -3858 | Episode: 67 | Qmax: 276.1686 | Exploration: 0.186846 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -3160 | Episode: 68 | Qmax: 276.5986 | Exploration: 0.186659 | Step: 281 | LR: 0.00150000\n",
      "| Reward: -1896 | Episode: 69 | Qmax: 275.2838 | Exploration: 0.186472 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -2044 | Episode: 70 | Qmax: 275.3960 | Exploration: 0.186286 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -3622 | Episode: 71 | Qmax: 275.3156 | Exploration: 0.186099 | Step: 239 | LR: 0.00150000\n",
      "| Reward: -1867 | Episode: 72 | Qmax: 276.4262 | Exploration: 0.185913 | Step: 257 | LR: 0.00150000\n",
      "| Reward: -2125 | Episode: 73 | Qmax: 275.7497 | Exploration: 0.185727 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -2925 | Episode: 74 | Qmax: 276.5222 | Exploration: 0.185542 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -4168 | Episode: 75 | Qmax: 276.4863 | Exploration: 0.185356 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -2431 | Episode: 76 | Qmax: 278.3469 | Exploration: 0.185171 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -3042 | Episode: 77 | Qmax: 277.5976 | Exploration: 0.184986 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -3861 | Episode: 78 | Qmax: 278.4681 | Exploration: 0.184801 | Step: 280 | LR: 0.00150000\n",
      "| Reward: -2430 | Episode: 79 | Qmax: 277.0243 | Exploration: 0.184616 | Step: 190 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2351 | Episode: 80 | Qmax: 279.3097 | Exploration: 0.184431 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -2957 | Episode: 81 | Qmax: 278.5168 | Exploration: 0.184247 | Step: 258 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2697 | Episode: 82 | Qmax: 281.0810 | Exploration: 0.184063 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -2180 | Episode: 83 | Qmax: 278.7770 | Exploration: 0.183879 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -2766 | Episode: 84 | Qmax: 279.7465 | Exploration: 0.183695 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -4451 | Episode: 85 | Qmax: 281.1395 | Exploration: 0.183511 | Step: 339 | LR: 0.00150000\n",
      "| Reward: -1772 | Episode: 86 | Qmax: 279.4072 | Exploration: 0.183327 | Step: 162 | LR: 0.00150000\n",
      "| Reward: -2864 | Episode: 87 | Qmax: 279.8727 | Exploration: 0.183144 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -2392 | Episode: 88 | Qmax: 280.2424 | Exploration: 0.182961 | Step: 206 | LR: 0.00150000\n",
      "| Reward: -2314 | Episode: 89 | Qmax: 281.7940 | Exploration: 0.182778 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -2912 | Episode: 90 | Qmax: 280.8767 | Exploration: 0.182595 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -2907 | Episode: 91 | Qmax: 281.9881 | Exploration: 0.182413 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -2192 | Episode: 92 | Qmax: 282.4712 | Exploration: 0.182230 | Step: 240 | LR: 0.00150000\n",
      "| Reward: -2218 | Episode: 93 | Qmax: 281.6690 | Exploration: 0.182048 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -2091 | Episode: 94 | Qmax: 284.0154 | Exploration: 0.181866 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -2638 | Episode: 95 | Qmax: 284.8388 | Exploration: 0.181684 | Step: 173 | LR: 0.00150000\n",
      "| Reward: -2608 | Episode: 96 | Qmax: 285.3617 | Exploration: 0.181502 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -2082 | Episode: 97 | Qmax: 284.7166 | Exploration: 0.181321 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -3031 | Episode: 98 | Qmax: 285.8508 | Exploration: 0.181140 | Step: 161 | LR: 0.00150000\n",
      "| Reward: -2994 | Episode: 99 | Qmax: 284.5329 | Exploration: 0.180958 | Step: 349 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2294 | Episode: 100 | Qmax: 287.7592 | Exploration: 0.180777 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -4295 | Episode: 101 | Qmax: 285.7962 | Exploration: 0.180597 | Step: 363 | LR: 0.00150000\n",
      "| Reward: -2890 | Episode: 102 | Qmax: 289.7922 | Exploration: 0.180416 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -2314 | Episode: 103 | Qmax: 288.5845 | Exploration: 0.180236 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -3262 | Episode: 104 | Qmax: 290.4963 | Exploration: 0.180055 | Step: 293 | LR: 0.00150000\n",
      "| Reward: -2945 | Episode: 105 | Qmax: 290.8846 | Exploration: 0.179875 | Step: 201 | LR: 0.00150000\n",
      "| Reward: -2357 | Episode: 106 | Qmax: 291.7701 | Exploration: 0.179696 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1744 | Episode: 107 | Qmax: 293.6349 | Exploration: 0.179516 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -1986 | Episode: 108 | Qmax: 295.6934 | Exploration: 0.179336 | Step: 151 | LR: 0.00150000\n",
      "| Reward: -2491 | Episode: 109 | Qmax: 296.1035 | Exploration: 0.179157 | Step: 170 | LR: 0.00150000\n",
      "| Reward: -2728 | Episode: 110 | Qmax: 294.1967 | Exploration: 0.178978 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -1954 | Episode: 111 | Qmax: 296.6936 | Exploration: 0.178799 | Step: 128 | LR: 0.00150000\n",
      "| Reward: -2999 | Episode: 112 | Qmax: 294.4277 | Exploration: 0.178620 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -1618 | Episode: 113 | Qmax: 297.7999 | Exploration: 0.178441 | Step: 152 | LR: 0.00150000\n",
      "| Reward: -3286 | Episode: 114 | Qmax: 296.2120 | Exploration: 0.178263 | Step: 326 | LR: 0.00150000\n",
      "| Reward: -1539 | Episode: 115 | Qmax: 298.6978 | Exploration: 0.178085 | Step: 136 | LR: 0.00150000\n",
      "| Reward: -1997 | Episode: 116 | Qmax: 298.8126 | Exploration: 0.177907 | Step: 162 | LR: 0.00150000\n",
      "| Reward: -2250 | Episode: 117 | Qmax: 299.2167 | Exploration: 0.177729 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1378 | Episode: 118 | Qmax: 300.0516 | Exploration: 0.177551 | Step: 128 | LR: 0.00150000\n",
      "| Reward: -2473 | Episode: 119 | Qmax: 302.6107 | Exploration: 0.177373 | Step: 170 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2450 | Episode: 120 | Qmax: 301.9041 | Exploration: 0.177196 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -3946 | Episode: 121 | Qmax: 301.1896 | Exploration: 0.177019 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -3405 | Episode: 122 | Qmax: 302.4453 | Exploration: 0.176842 | Step: 274 | LR: 0.00150000\n",
      "| Reward: -3303 | Episode: 123 | Qmax: 302.3665 | Exploration: 0.176665 | Step: 298 | LR: 0.00150000\n",
      "| Reward: -3698 | Episode: 124 | Qmax: 305.3867 | Exploration: 0.176488 | Step: 234 | LR: 0.00150000\n",
      "| Reward: -2309 | Episode: 125 | Qmax: 303.8635 | Exploration: 0.176312 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -3298 | Episode: 126 | Qmax: 307.0241 | Exploration: 0.176136 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -2679 | Episode: 127 | Qmax: 306.0078 | Exploration: 0.175959 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -2610 | Episode: 128 | Qmax: 307.5273 | Exploration: 0.175783 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -1776 | Episode: 129 | Qmax: 306.8112 | Exploration: 0.175608 | Step: 193 | LR: 0.00150000\n",
      "| Reward: -2700 | Episode: 130 | Qmax: 308.3814 | Exploration: 0.175432 | Step: 325 | LR: 0.00150000\n",
      "| Reward: -3979 | Episode: 131 | Qmax: 309.5851 | Exploration: 0.175257 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -2997 | Episode: 132 | Qmax: 311.8690 | Exploration: 0.175081 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -3550 | Episode: 133 | Qmax: 312.8978 | Exploration: 0.174906 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -3474 | Episode: 134 | Qmax: 311.8931 | Exploration: 0.174731 | Step: 298 | LR: 0.00150000\n",
      "| Reward: -3523 | Episode: 135 | Qmax: 313.5967 | Exploration: 0.174557 | Step: 311 | LR: 0.00150000\n",
      "| Reward: -1741 | Episode: 136 | Qmax: 314.7905 | Exploration: 0.174382 | Step: 167 | LR: 0.00150000\n",
      "| Reward: -3929 | Episode: 137 | Qmax: 314.9360 | Exploration: 0.174208 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -1989 | Episode: 138 | Qmax: 315.8082 | Exploration: 0.174034 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -2862 | Episode: 139 | Qmax: 314.9836 | Exploration: 0.173859 | Step: 199 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3446 | Episode: 140 | Qmax: 316.0251 | Exploration: 0.173686 | Step: 288 | LR: 0.00150000\n",
      "| Reward: -2977 | Episode: 141 | Qmax: 317.2809 | Exploration: 0.173512 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -4192 | Episode: 142 | Qmax: 318.8876 | Exploration: 0.173338 | Step: 521 | LR: 0.00150000\n",
      "| Reward: -2484 | Episode: 143 | Qmax: 318.5421 | Exploration: 0.173165 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -3375 | Episode: 144 | Qmax: 319.2978 | Exploration: 0.172992 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -3034 | Episode: 145 | Qmax: 320.8017 | Exploration: 0.172819 | Step: 281 | LR: 0.00150000\n",
      "| Reward: -4163 | Episode: 146 | Qmax: 322.2961 | Exploration: 0.172646 | Step: 285 | LR: 0.00150000\n",
      "| Reward: -2859 | Episode: 147 | Qmax: 322.0180 | Exploration: 0.172473 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -2872 | Episode: 148 | Qmax: 321.3866 | Exploration: 0.172301 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -3731 | Episode: 149 | Qmax: 323.9693 | Exploration: 0.172129 | Step: 276 | LR: 0.00150000\n",
      "| Reward: -5458 | Episode: 150 | Qmax: 321.8764 | Exploration: 0.171957 | Step: 464 | LR: 0.00150000\n",
      "| Reward: -2577 | Episode: 151 | Qmax: 324.4241 | Exploration: 0.171785 | Step: 202 | LR: 0.00150000\n",
      "| Reward: -2199 | Episode: 152 | Qmax: 326.3724 | Exploration: 0.171613 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -2792 | Episode: 153 | Qmax: 326.7153 | Exploration: 0.171441 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1674 | Episode: 154 | Qmax: 327.0682 | Exploration: 0.171270 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -2681 | Episode: 155 | Qmax: 325.7145 | Exploration: 0.171098 | Step: 243 | LR: 0.00150000\n",
      "| Reward: -1866 | Episode: 156 | Qmax: 329.8078 | Exploration: 0.170927 | Step: 148 | LR: 0.00150000\n",
      "| Reward: -3069 | Episode: 157 | Qmax: 328.6299 | Exploration: 0.170756 | Step: 271 | LR: 0.00150000\n",
      "| Reward: -2194 | Episode: 158 | Qmax: 329.2529 | Exploration: 0.170586 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1730 | Episode: 159 | Qmax: 329.2508 | Exploration: 0.170415 | Step: 264 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3370 | Episode: 160 | Qmax: 330.0101 | Exploration: 0.170245 | Step: 284 | LR: 0.00150000\n",
      "| Reward: -1833 | Episode: 161 | Qmax: 331.4098 | Exploration: 0.170074 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -3536 | Episode: 162 | Qmax: 334.6627 | Exploration: 0.169904 | Step: 288 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -3727 | Episode: 163 | Qmax: 335.8323 | Exploration: 0.169734 | Step: 389 | LR: 0.00150000\n",
      "| Reward: -1819 | Episode: 164 | Qmax: 336.7920 | Exploration: 0.169565 | Step: 209 | LR: 0.00150000\n",
      "| Reward: -3269 | Episode: 165 | Qmax: 339.1721 | Exploration: 0.169395 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -3529 | Episode: 166 | Qmax: 339.9843 | Exploration: 0.169226 | Step: 326 | LR: 0.00150000\n",
      "| Reward: -2164 | Episode: 167 | Qmax: 341.8018 | Exploration: 0.169057 | Step: 158 | LR: 0.00150000\n",
      "| Reward: -3330 | Episode: 168 | Qmax: 340.0956 | Exploration: 0.168887 | Step: 352 | LR: 0.00150000\n",
      "| Reward: -2422 | Episode: 169 | Qmax: 342.9510 | Exploration: 0.168719 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -9721 | Episode: 170 | Qmax: 341.3481 | Exploration: 0.168550 | Step: 893 | LR: 0.00150000\n",
      "| Reward: -1540 | Episode: 171 | Qmax: 345.2976 | Exploration: 0.168381 | Step: 128 | LR: 0.00150000\n",
      "| Reward: -2411 | Episode: 172 | Qmax: 345.8636 | Exploration: 0.168213 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -3257 | Episode: 173 | Qmax: 344.2844 | Exploration: 0.168045 | Step: 450 | LR: 0.00150000\n",
      "| Reward: -2337 | Episode: 174 | Qmax: 346.1122 | Exploration: 0.167877 | Step: 286 | LR: 0.00150000\n",
      "| Reward: -4462 | Episode: 175 | Qmax: 347.4298 | Exploration: 0.167709 | Step: 413 | LR: 0.00150000\n",
      "| Reward: -2026 | Episode: 176 | Qmax: 346.9036 | Exploration: 0.167541 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -1965 | Episode: 177 | Qmax: 347.4551 | Exploration: 0.167374 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -3863 | Episode: 178 | Qmax: 346.8637 | Exploration: 0.167206 | Step: 462 | LR: 0.00150000\n",
      "| Reward: -2417 | Episode: 179 | Qmax: 347.1281 | Exploration: 0.167039 | Step: 240 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -6101 | Episode: 180 | Qmax: 347.1138 | Exploration: 0.166872 | Step: 513 | LR: 0.00150000\n",
      "| Reward: -4314 | Episode: 181 | Qmax: 346.8177 | Exploration: 0.166705 | Step: 463 | LR: 0.00150000\n",
      "| Reward: -2364 | Episode: 182 | Qmax: 346.6517 | Exploration: 0.166538 | Step: 421 | LR: 0.00150000\n",
      "| Reward: -3018 | Episode: 183 | Qmax: 347.2097 | Exploration: 0.166372 | Step: 409 | LR: 0.00150000\n",
      "| Reward: -4291 | Episode: 184 | Qmax: 345.8003 | Exploration: 0.166205 | Step: 350 | LR: 0.00150000\n",
      "| Reward: -3347 | Episode: 185 | Qmax: 346.8348 | Exploration: 0.166039 | Step: 585 | LR: 0.00150000\n",
      "| Reward: -3103 | Episode: 186 | Qmax: 345.8383 | Exploration: 0.165873 | Step: 341 | LR: 0.00150000\n",
      "| Reward: -3032 | Episode: 187 | Qmax: 347.6445 | Exploration: 0.165707 | Step: 243 | LR: 0.00150000\n",
      "| Reward: -2336 | Episode: 188 | Qmax: 346.5297 | Exploration: 0.165542 | Step: 321 | LR: 0.00150000\n",
      "| Reward: -1862 | Episode: 189 | Qmax: 347.7105 | Exploration: 0.165376 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -4896 | Episode: 190 | Qmax: 347.7599 | Exploration: 0.165211 | Step: 388 | LR: 0.00150000\n",
      "| Reward: -3934 | Episode: 191 | Qmax: 349.0009 | Exploration: 0.165046 | Step: 380 | LR: 0.00150000\n",
      "| Reward: -6863 | Episode: 192 | Qmax: 350.0881 | Exploration: 0.164880 | Step: 555 | LR: 0.00150000\n",
      "| Reward: -3492 | Episode: 193 | Qmax: 352.9721 | Exploration: 0.164716 | Step: 424 | LR: 0.00150000\n",
      "| Reward: -3587 | Episode: 194 | Qmax: 355.4368 | Exploration: 0.164551 | Step: 384 | LR: 0.00150000\n",
      "| Reward: -3348 | Episode: 195 | Qmax: 355.9926 | Exploration: 0.164386 | Step: 325 | LR: 0.00150000\n",
      "| Reward: -4672 | Episode: 196 | Qmax: 356.2975 | Exploration: 0.164222 | Step: 380 | LR: 0.00150000\n",
      "| Reward: -3844 | Episode: 197 | Qmax: 357.3021 | Exploration: 0.164058 | Step: 308 | LR: 0.00150000\n",
      "| Reward: -2423 | Episode: 198 | Qmax: 358.0754 | Exploration: 0.163894 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -3399 | Episode: 199 | Qmax: 359.3632 | Exploration: 0.163730 | Step: 322 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2264 | Episode: 200 | Qmax: 360.4120 | Exploration: 0.163566 | Step: 321 | LR: 0.00150000\n",
      "| Reward: -3091 | Episode: 201 | Qmax: 361.1123 | Exploration: 0.163402 | Step: 293 | LR: 0.00150000\n",
      "| Reward: -2498 | Episode: 202 | Qmax: 360.6988 | Exploration: 0.163239 | Step: 294 | LR: 0.00150000\n",
      "| Reward: -3074 | Episode: 203 | Qmax: 361.6717 | Exploration: 0.163076 | Step: 285 | LR: 0.00150000\n",
      "| Reward: -3340 | Episode: 204 | Qmax: 365.6458 | Exploration: 0.162913 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -3362 | Episode: 205 | Qmax: 363.2303 | Exploration: 0.162750 | Step: 339 | LR: 0.00150000\n",
      "| Reward: -2738 | Episode: 206 | Qmax: 364.6888 | Exploration: 0.162587 | Step: 291 | LR: 0.00150000\n",
      "| Reward: -2996 | Episode: 207 | Qmax: 365.8003 | Exploration: 0.162425 | Step: 243 | LR: 0.00150000\n",
      "| Reward: -1807 | Episode: 208 | Qmax: 365.7294 | Exploration: 0.162262 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -2600 | Episode: 209 | Qmax: 367.3910 | Exploration: 0.162100 | Step: 342 | LR: 0.00150000\n",
      "| Reward: -2280 | Episode: 210 | Qmax: 367.7221 | Exploration: 0.161938 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -2479 | Episode: 211 | Qmax: 369.3171 | Exploration: 0.161776 | Step: 320 | LR: 0.00150000\n",
      "| Reward: -2533 | Episode: 212 | Qmax: 369.6753 | Exploration: 0.161614 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -2245 | Episode: 213 | Qmax: 369.7344 | Exploration: 0.161452 | Step: 167 | LR: 0.00150000\n",
      "| Reward: -2705 | Episode: 214 | Qmax: 370.6161 | Exploration: 0.161291 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -2073 | Episode: 215 | Qmax: 371.3291 | Exploration: 0.161130 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -2032 | Episode: 216 | Qmax: 370.0544 | Exploration: 0.160969 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -2988 | Episode: 217 | Qmax: 370.8937 | Exploration: 0.160808 | Step: 433 | LR: 0.00150000\n",
      "| Reward: -2604 | Episode: 218 | Qmax: 369.8274 | Exploration: 0.160647 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -1549 | Episode: 219 | Qmax: 372.0061 | Exploration: 0.160486 | Step: 137 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2209 | Episode: 220 | Qmax: 373.0381 | Exploration: 0.160326 | Step: 446 | LR: 0.00150000\n",
      "| Reward: -3445 | Episode: 221 | Qmax: 371.8538 | Exploration: 0.160165 | Step: 332 | LR: 0.00150000\n",
      "| Reward: -3671 | Episode: 222 | Qmax: 373.6909 | Exploration: 0.160005 | Step: 405 | LR: 0.00150000\n",
      "| Reward: -2140 | Episode: 223 | Qmax: 375.7475 | Exploration: 0.159845 | Step: 341 | LR: 0.00150000\n",
      "| Reward: -3683 | Episode: 224 | Qmax: 375.0961 | Exploration: 0.159685 | Step: 471 | LR: 0.00150000\n",
      "| Reward: -3178 | Episode: 225 | Qmax: 375.5600 | Exploration: 0.159526 | Step: 362 | LR: 0.00150000\n",
      "| Reward: -2188 | Episode: 226 | Qmax: 377.2117 | Exploration: 0.159366 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -2573 | Episode: 227 | Qmax: 375.8096 | Exploration: 0.159207 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -2220 | Episode: 228 | Qmax: 375.5696 | Exploration: 0.159047 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -2929 | Episode: 229 | Qmax: 377.8126 | Exploration: 0.158888 | Step: 284 | LR: 0.00150000\n",
      "| Reward: -1648 | Episode: 230 | Qmax: 376.4601 | Exploration: 0.158730 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -2638 | Episode: 231 | Qmax: 378.2377 | Exploration: 0.158571 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -2193 | Episode: 232 | Qmax: 375.8951 | Exploration: 0.158412 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -3082 | Episode: 233 | Qmax: 377.1491 | Exploration: 0.158254 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -2901 | Episode: 234 | Qmax: 377.3010 | Exploration: 0.158096 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1650 | Episode: 235 | Qmax: 376.0467 | Exploration: 0.157937 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -1423 | Episode: 236 | Qmax: 378.8670 | Exploration: 0.157780 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -2289 | Episode: 237 | Qmax: 376.3832 | Exploration: 0.157622 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -2947 | Episode: 238 | Qmax: 379.1636 | Exploration: 0.157464 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -2815 | Episode: 239 | Qmax: 378.6513 | Exploration: 0.157307 | Step: 395 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -5294 | Episode: 240 | Qmax: 376.8479 | Exploration: 0.157149 | Step: 516 | LR: 0.00150000\n",
      "| Reward: -2187 | Episode: 241 | Qmax: 377.2985 | Exploration: 0.156992 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -1714 | Episode: 242 | Qmax: 379.9389 | Exploration: 0.156835 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -1737 | Episode: 243 | Qmax: 378.6594 | Exploration: 0.156678 | Step: 226 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1996 | Episode: 244 | Qmax: 379.3755 | Exploration: 0.156522 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -2787 | Episode: 245 | Qmax: 378.8760 | Exploration: 0.156365 | Step: 313 | LR: 0.00150000\n",
      "| Reward: -1465 | Episode: 246 | Qmax: 378.6409 | Exploration: 0.156209 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -2460 | Episode: 247 | Qmax: 380.1292 | Exploration: 0.156053 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -1601 | Episode: 248 | Qmax: 379.1879 | Exploration: 0.155897 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -2195 | Episode: 249 | Qmax: 380.5083 | Exploration: 0.155741 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -3544 | Episode: 250 | Qmax: 380.4351 | Exploration: 0.155585 | Step: 323 | LR: 0.00150000\n",
      "| Reward: -1637 | Episode: 251 | Qmax: 380.1938 | Exploration: 0.155429 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -2578 | Episode: 252 | Qmax: 382.0425 | Exploration: 0.155274 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -2123 | Episode: 253 | Qmax: 380.3473 | Exploration: 0.155119 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -2607 | Episode: 254 | Qmax: 380.3417 | Exploration: 0.154964 | Step: 340 | LR: 0.00150000\n",
      "| Reward: -2824 | Episode: 255 | Qmax: 383.0831 | Exploration: 0.154809 | Step: 224 | LR: 0.00150000\n",
      "| Reward: -1739 | Episode: 256 | Qmax: 382.0539 | Exploration: 0.154654 | Step: 156 | LR: 0.00150000\n",
      "| Reward: -1593 | Episode: 257 | Qmax: 383.9375 | Exploration: 0.154499 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -2443 | Episode: 258 | Qmax: 381.4357 | Exploration: 0.154345 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -3589 | Episode: 259 | Qmax: 383.7696 | Exploration: 0.154190 | Step: 206 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2656 | Episode: 260 | Qmax: 384.0038 | Exploration: 0.154036 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -2471 | Episode: 261 | Qmax: 383.4527 | Exploration: 0.153882 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1462 | Episode: 262 | Qmax: 384.4097 | Exploration: 0.153728 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -1502 | Episode: 263 | Qmax: 383.6835 | Exploration: 0.153574 | Step: 279 | LR: 0.00150000\n",
      "| Reward: -2694 | Episode: 264 | Qmax: 384.6568 | Exploration: 0.153421 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -2356 | Episode: 265 | Qmax: 382.9340 | Exploration: 0.153267 | Step: 512 | LR: 0.00150000\n",
      "| Reward: -2566 | Episode: 266 | Qmax: 384.1140 | Exploration: 0.153114 | Step: 362 | LR: 0.00150000\n",
      "| Reward: -1810 | Episode: 267 | Qmax: 383.6842 | Exploration: 0.152961 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -2054 | Episode: 268 | Qmax: 383.6320 | Exploration: 0.152808 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -2234 | Episode: 269 | Qmax: 385.8139 | Exploration: 0.152655 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -2245 | Episode: 270 | Qmax: 383.5657 | Exploration: 0.152503 | Step: 284 | LR: 0.00150000\n",
      "| Reward: -2526 | Episode: 271 | Qmax: 385.7539 | Exploration: 0.152350 | Step: 322 | LR: 0.00150000\n",
      "| Reward: -1801 | Episode: 272 | Qmax: 387.1168 | Exploration: 0.152198 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -2269 | Episode: 273 | Qmax: 386.8561 | Exploration: 0.152046 | Step: 191 | LR: 0.00150000\n",
      "| Reward: -2101 | Episode: 274 | Qmax: 387.2600 | Exploration: 0.151894 | Step: 320 | LR: 0.00150000\n",
      "| Reward: -2189 | Episode: 275 | Qmax: 386.5673 | Exploration: 0.151742 | Step: 318 | LR: 0.00150000\n",
      "| Reward: -2559 | Episode: 276 | Qmax: 387.1325 | Exploration: 0.151590 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -1916 | Episode: 277 | Qmax: 384.9043 | Exploration: 0.151438 | Step: 324 | LR: 0.00150000\n",
      "| Reward: -1787 | Episode: 278 | Qmax: 387.9687 | Exploration: 0.151287 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -2292 | Episode: 279 | Qmax: 387.3266 | Exploration: 0.151136 | Step: 349 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1805 | Episode: 280 | Qmax: 385.3975 | Exploration: 0.150984 | Step: 456 | LR: 0.00150000\n",
      "| Reward: -1485 | Episode: 281 | Qmax: 389.0263 | Exploration: 0.150833 | Step: 172 | LR: 0.00150000\n",
      "| Reward: -2978 | Episode: 282 | Qmax: 387.4021 | Exploration: 0.150683 | Step: 504 | LR: 0.00150000\n",
      "| Reward: -3020 | Episode: 283 | Qmax: 387.2495 | Exploration: 0.150532 | Step: 609 | LR: 0.00150000\n",
      "| Reward: -1291 | Episode: 284 | Qmax: 391.1497 | Exploration: 0.150381 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -1758 | Episode: 285 | Qmax: 388.4083 | Exploration: 0.150231 | Step: 319 | LR: 0.00150000\n",
      "| Reward: -2215 | Episode: 286 | Qmax: 390.3121 | Exploration: 0.150081 | Step: 191 | LR: 0.00150000\n",
      "| Reward: -2308 | Episode: 287 | Qmax: 390.8289 | Exploration: 0.149931 | Step: 221 | LR: 0.00150000\n",
      "| Reward: -2191 | Episode: 288 | Qmax: 391.3981 | Exploration: 0.149781 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -2397 | Episode: 289 | Qmax: 388.5523 | Exploration: 0.149631 | Step: 418 | LR: 0.00150000\n",
      "| Reward: -3244 | Episode: 290 | Qmax: 390.4861 | Exploration: 0.149481 | Step: 365 | LR: 0.00150000\n",
      "| Reward: -1865 | Episode: 291 | Qmax: 391.9382 | Exploration: 0.149332 | Step: 246 | LR: 0.00150000\n",
      "| Reward: -2093 | Episode: 292 | Qmax: 389.0404 | Exploration: 0.149183 | Step: 402 | LR: 0.00150000\n",
      "| Reward: -1700 | Episode: 293 | Qmax: 391.4118 | Exploration: 0.149033 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -2523 | Episode: 294 | Qmax: 388.9857 | Exploration: 0.148884 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -2268 | Episode: 295 | Qmax: 389.9109 | Exploration: 0.148735 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -2622 | Episode: 296 | Qmax: 390.9016 | Exploration: 0.148587 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1761 | Episode: 297 | Qmax: 390.5537 | Exploration: 0.148438 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -1763 | Episode: 298 | Qmax: 391.7093 | Exploration: 0.148290 | Step: 153 | LR: 0.00150000\n",
      "| Reward: -2636 | Episode: 299 | Qmax: 389.4245 | Exploration: 0.148141 | Step: 225 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2080 | Episode: 300 | Qmax: 391.7620 | Exploration: 0.147993 | Step: 317 | LR: 0.00150000\n",
      "| Reward: -2204 | Episode: 301 | Qmax: 391.4571 | Exploration: 0.147845 | Step: 243 | LR: 0.00150000\n",
      "| Reward: -1396 | Episode: 302 | Qmax: 393.7909 | Exploration: 0.147697 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -2201 | Episode: 303 | Qmax: 392.7796 | Exploration: 0.147550 | Step: 348 | LR: 0.00150000\n",
      "| Reward: -2108 | Episode: 304 | Qmax: 392.4026 | Exploration: 0.147402 | Step: 516 | LR: 0.00150000\n",
      "| Reward: -2716 | Episode: 305 | Qmax: 393.9378 | Exploration: 0.147255 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -2708 | Episode: 306 | Qmax: 394.0937 | Exploration: 0.147108 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -2589 | Episode: 307 | Qmax: 393.6203 | Exploration: 0.146960 | Step: 286 | LR: 0.00150000\n",
      "| Reward: -2059 | Episode: 308 | Qmax: 394.2431 | Exploration: 0.146813 | Step: 377 | LR: 0.00150000\n",
      "| Reward: -2840 | Episode: 309 | Qmax: 394.4579 | Exploration: 0.146667 | Step: 384 | LR: 0.00150000\n",
      "| Reward: -1804 | Episode: 310 | Qmax: 394.3315 | Exploration: 0.146520 | Step: 428 | LR: 0.00150000\n",
      "| Reward: -2358 | Episode: 311 | Qmax: 397.6141 | Exploration: 0.146373 | Step: 316 | LR: 0.00150000\n",
      "| Reward: -2315 | Episode: 312 | Qmax: 394.7322 | Exploration: 0.146227 | Step: 246 | LR: 0.00150000\n",
      "| Reward: -1563 | Episode: 313 | Qmax: 395.6731 | Exploration: 0.146081 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -2412 | Episode: 314 | Qmax: 393.4576 | Exploration: 0.145935 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -2626 | Episode: 315 | Qmax: 395.5884 | Exploration: 0.145789 | Step: 404 | LR: 0.00150000\n",
      "| Reward: -2821 | Episode: 316 | Qmax: 395.1257 | Exploration: 0.145643 | Step: 275 | LR: 0.00150000\n",
      "| Reward: -2322 | Episode: 317 | Qmax: 395.3313 | Exploration: 0.145497 | Step: 289 | LR: 0.00150000\n",
      "| Reward: -2143 | Episode: 318 | Qmax: 394.8749 | Exploration: 0.145352 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -2679 | Episode: 319 | Qmax: 395.3623 | Exploration: 0.145207 | Step: 376 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1586 | Episode: 320 | Qmax: 396.8213 | Exploration: 0.145061 | Step: 246 | LR: 0.00150000\n",
      "| Reward: -2096 | Episode: 321 | Qmax: 394.7261 | Exploration: 0.144916 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -1775 | Episode: 322 | Qmax: 396.3710 | Exploration: 0.144771 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -2883 | Episode: 323 | Qmax: 395.3145 | Exploration: 0.144627 | Step: 328 | LR: 0.00150000\n",
      "| Reward: -2014 | Episode: 324 | Qmax: 393.7982 | Exploration: 0.144482 | Step: 269 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2133 | Episode: 325 | Qmax: 394.0696 | Exploration: 0.144337 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -1868 | Episode: 326 | Qmax: 394.5162 | Exploration: 0.144193 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -3068 | Episode: 327 | Qmax: 394.2461 | Exploration: 0.144049 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -2650 | Episode: 328 | Qmax: 393.8715 | Exploration: 0.143905 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -2406 | Episode: 329 | Qmax: 396.3708 | Exploration: 0.143761 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -2202 | Episode: 330 | Qmax: 395.9146 | Exploration: 0.143617 | Step: 430 | LR: 0.00150000\n",
      "| Reward: -2522 | Episode: 331 | Qmax: 396.7374 | Exploration: 0.143474 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -2162 | Episode: 332 | Qmax: 395.3472 | Exploration: 0.143330 | Step: 336 | LR: 0.00150000\n",
      "| Reward: -2460 | Episode: 333 | Qmax: 397.2789 | Exploration: 0.143187 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -1517 | Episode: 334 | Qmax: 398.4904 | Exploration: 0.143044 | Step: 204 | LR: 0.00150000\n",
      "| Reward: -2308 | Episode: 335 | Qmax: 395.2148 | Exploration: 0.142901 | Step: 293 | LR: 0.00150000\n",
      "| Reward: -1222 | Episode: 336 | Qmax: 394.8974 | Exploration: 0.142758 | Step: 179 | LR: 0.00150000\n",
      "| Reward: -2800 | Episode: 337 | Qmax: 396.7485 | Exploration: 0.142615 | Step: 362 | LR: 0.00150000\n",
      "| Reward: -1906 | Episode: 338 | Qmax: 394.3192 | Exploration: 0.142472 | Step: 197 | LR: 0.00150000\n",
      "| Reward: -2789 | Episode: 339 | Qmax: 394.1317 | Exploration: 0.142330 | Step: 306 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2388 | Episode: 340 | Qmax: 394.7653 | Exploration: 0.142188 | Step: 310 | LR: 0.00150000\n",
      "| Reward: -2267 | Episode: 341 | Qmax: 393.5615 | Exploration: 0.142045 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -1479 | Episode: 342 | Qmax: 394.1641 | Exploration: 0.141903 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -2055 | Episode: 343 | Qmax: 394.0171 | Exploration: 0.141761 | Step: 337 | LR: 0.00150000\n",
      "| Reward: -1740 | Episode: 344 | Qmax: 394.1364 | Exploration: 0.141620 | Step: 319 | LR: 0.00150000\n",
      "| Reward: -2071 | Episode: 345 | Qmax: 393.4047 | Exploration: 0.141478 | Step: 344 | LR: 0.00150000\n",
      "| Reward: -3493 | Episode: 346 | Qmax: 394.6048 | Exploration: 0.141337 | Step: 407 | LR: 0.00150000\n",
      "| Reward: -2188 | Episode: 347 | Qmax: 396.3786 | Exploration: 0.141195 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -2226 | Episode: 348 | Qmax: 394.0258 | Exploration: 0.141054 | Step: 256 | LR: 0.00150000\n",
      "| Reward: -3066 | Episode: 349 | Qmax: 394.8692 | Exploration: 0.140913 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -1929 | Episode: 350 | Qmax: 396.1520 | Exploration: 0.140772 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -2469 | Episode: 351 | Qmax: 394.4558 | Exploration: 0.140631 | Step: 328 | LR: 0.00150000\n",
      "| Reward: -2593 | Episode: 352 | Qmax: 394.8271 | Exploration: 0.140491 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -2413 | Episode: 353 | Qmax: 395.4601 | Exploration: 0.140350 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -2140 | Episode: 354 | Qmax: 394.1820 | Exploration: 0.140210 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -2128 | Episode: 355 | Qmax: 396.0004 | Exploration: 0.140070 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -2092 | Episode: 356 | Qmax: 395.0903 | Exploration: 0.139930 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -2048 | Episode: 357 | Qmax: 396.0962 | Exploration: 0.139790 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -2928 | Episode: 358 | Qmax: 396.0790 | Exploration: 0.139650 | Step: 463 | LR: 0.00150000\n",
      "| Reward: -1824 | Episode: 359 | Qmax: 398.1383 | Exploration: 0.139510 | Step: 205 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1944 | Episode: 360 | Qmax: 397.0595 | Exploration: 0.139371 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1385 | Episode: 361 | Qmax: 397.1172 | Exploration: 0.139231 | Step: 234 | LR: 0.00150000\n",
      "| Reward: -1380 | Episode: 362 | Qmax: 394.9227 | Exploration: 0.139092 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -2521 | Episode: 363 | Qmax: 396.3139 | Exploration: 0.138953 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -1570 | Episode: 364 | Qmax: 393.2041 | Exploration: 0.138814 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -2320 | Episode: 365 | Qmax: 394.7823 | Exploration: 0.138675 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -2463 | Episode: 366 | Qmax: 392.3906 | Exploration: 0.138536 | Step: 295 | LR: 0.00150000\n",
      "| Reward: -1928 | Episode: 367 | Qmax: 395.9043 | Exploration: 0.138398 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -1463 | Episode: 368 | Qmax: 394.0868 | Exploration: 0.138260 | Step: 249 | LR: 0.00150000\n",
      "| Reward: -1971 | Episode: 369 | Qmax: 394.7178 | Exploration: 0.138121 | Step: 289 | LR: 0.00150000\n",
      "| Reward: -2556 | Episode: 370 | Qmax: 393.6963 | Exploration: 0.137983 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -2815 | Episode: 371 | Qmax: 395.5057 | Exploration: 0.137845 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -1779 | Episode: 372 | Qmax: 393.1974 | Exploration: 0.137707 | Step: 187 | LR: 0.00150000\n",
      "| Reward: -1471 | Episode: 373 | Qmax: 394.9129 | Exploration: 0.137570 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -2020 | Episode: 374 | Qmax: 396.2735 | Exploration: 0.137432 | Step: 221 | LR: 0.00150000\n",
      "| Reward: -1686 | Episode: 375 | Qmax: 394.4619 | Exploration: 0.137295 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -2154 | Episode: 376 | Qmax: 396.0363 | Exploration: 0.137157 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -1268 | Episode: 377 | Qmax: 397.1657 | Exploration: 0.137020 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -1696 | Episode: 378 | Qmax: 394.2668 | Exploration: 0.136883 | Step: 257 | LR: 0.00150000\n",
      "| Reward: -2413 | Episode: 379 | Qmax: 397.4966 | Exploration: 0.136746 | Step: 254 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2511 | Episode: 380 | Qmax: 395.9129 | Exploration: 0.136610 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -2215 | Episode: 381 | Qmax: 392.8787 | Exploration: 0.136473 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -1693 | Episode: 382 | Qmax: 394.2615 | Exploration: 0.136336 | Step: 227 | LR: 0.00150000\n",
      "| Reward: -2477 | Episode: 383 | Qmax: 395.6757 | Exploration: 0.136200 | Step: 318 | LR: 0.00150000\n",
      "| Reward: -2018 | Episode: 384 | Qmax: 396.5392 | Exploration: 0.136064 | Step: 174 | LR: 0.00150000\n",
      "| Reward: -1210 | Episode: 385 | Qmax: 394.1099 | Exploration: 0.135928 | Step: 158 | LR: 0.00150000\n",
      "| Reward: -1537 | Episode: 386 | Qmax: 399.4566 | Exploration: 0.135792 | Step: 170 | LR: 0.00150000\n",
      "| Reward: -2740 | Episode: 387 | Qmax: 396.5062 | Exploration: 0.135656 | Step: 329 | LR: 0.00150000\n",
      "| Reward: -1560 | Episode: 388 | Qmax: 397.5535 | Exploration: 0.135520 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -2096 | Episode: 389 | Qmax: 398.9899 | Exploration: 0.135385 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -2922 | Episode: 390 | Qmax: 397.4854 | Exploration: 0.135250 | Step: 295 | LR: 0.00150000\n",
      "| Reward: -3225 | Episode: 391 | Qmax: 397.4823 | Exploration: 0.135114 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -2391 | Episode: 392 | Qmax: 396.0379 | Exploration: 0.134979 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -1462 | Episode: 393 | Qmax: 398.0306 | Exploration: 0.134844 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -2665 | Episode: 394 | Qmax: 398.1722 | Exploration: 0.134709 | Step: 308 | LR: 0.00150000\n",
      "| Reward: -2111 | Episode: 395 | Qmax: 398.1228 | Exploration: 0.134575 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -2198 | Episode: 396 | Qmax: 397.2788 | Exploration: 0.134440 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -2013 | Episode: 397 | Qmax: 397.6521 | Exploration: 0.134306 | Step: 331 | LR: 0.00150000\n",
      "| Reward: -2234 | Episode: 398 | Qmax: 398.3801 | Exploration: 0.134171 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -2039 | Episode: 399 | Qmax: 396.8648 | Exploration: 0.134037 | Step: 303 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2689 | Episode: 400 | Qmax: 398.2570 | Exploration: 0.133903 | Step: 206 | LR: 0.00150000\n",
      "| Reward: -1761 | Episode: 401 | Qmax: 398.8516 | Exploration: 0.133769 | Step: 205 | LR: 0.00150000\n",
      "| Reward: -2850 | Episode: 402 | Qmax: 396.1931 | Exploration: 0.133635 | Step: 358 | LR: 0.00150000\n",
      "| Reward: -1656 | Episode: 403 | Qmax: 400.9267 | Exploration: 0.133502 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1818 | Episode: 404 | Qmax: 398.5996 | Exploration: 0.133368 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -3033 | Episode: 405 | Qmax: 398.5374 | Exploration: 0.133235 | Step: 253 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1283 | Episode: 406 | Qmax: 401.9415 | Exploration: 0.133102 | Step: 141 | LR: 0.00150000\n",
      "| Reward: -2154 | Episode: 407 | Qmax: 399.3993 | Exploration: 0.132969 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -1913 | Episode: 408 | Qmax: 399.4828 | Exploration: 0.132836 | Step: 159 | LR: 0.00150000\n",
      "| Reward: -1726 | Episode: 409 | Qmax: 396.9571 | Exploration: 0.132703 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1859 | Episode: 410 | Qmax: 399.2659 | Exploration: 0.132570 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1491 | Episode: 411 | Qmax: 403.6212 | Exploration: 0.132438 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -1672 | Episode: 412 | Qmax: 398.5104 | Exploration: 0.132305 | Step: 143 | LR: 0.00150000\n",
      "| Reward: -1683 | Episode: 413 | Qmax: 401.7655 | Exploration: 0.132173 | Step: 316 | LR: 0.00150000\n",
      "| Reward: -2427 | Episode: 414 | Qmax: 401.4408 | Exploration: 0.132041 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -2166 | Episode: 415 | Qmax: 398.8991 | Exploration: 0.131909 | Step: 250 | LR: 0.00150000\n",
      "| Reward: -2067 | Episode: 416 | Qmax: 400.2649 | Exploration: 0.131777 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1892 | Episode: 417 | Qmax: 399.3769 | Exploration: 0.131645 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -1868 | Episode: 418 | Qmax: 399.9434 | Exploration: 0.131513 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -1752 | Episode: 419 | Qmax: 401.1250 | Exploration: 0.131382 | Step: 259 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1290 | Episode: 420 | Qmax: 403.9180 | Exploration: 0.131250 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -2311 | Episode: 421 | Qmax: 399.9370 | Exploration: 0.131119 | Step: 224 | LR: 0.00150000\n",
      "| Reward: -1778 | Episode: 422 | Qmax: 399.9502 | Exploration: 0.130988 | Step: 240 | LR: 0.00150000\n",
      "| Reward: -2344 | Episode: 423 | Qmax: 401.1501 | Exploration: 0.130857 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -1883 | Episode: 424 | Qmax: 401.2125 | Exploration: 0.130726 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1463 | Episode: 425 | Qmax: 400.2978 | Exploration: 0.130595 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1815 | Episode: 426 | Qmax: 398.7293 | Exploration: 0.130465 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -1586 | Episode: 427 | Qmax: 399.4032 | Exploration: 0.130334 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1602 | Episode: 428 | Qmax: 400.4302 | Exploration: 0.130204 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1781 | Episode: 429 | Qmax: 402.6617 | Exploration: 0.130074 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -2333 | Episode: 430 | Qmax: 401.2263 | Exploration: 0.129944 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -2280 | Episode: 431 | Qmax: 402.7009 | Exploration: 0.129814 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1970 | Episode: 432 | Qmax: 404.4542 | Exploration: 0.129684 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -2082 | Episode: 433 | Qmax: 403.9956 | Exploration: 0.129554 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1799 | Episode: 434 | Qmax: 401.0909 | Exploration: 0.129425 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -2123 | Episode: 435 | Qmax: 401.4571 | Exploration: 0.129295 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -1756 | Episode: 436 | Qmax: 401.5633 | Exploration: 0.129166 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1578 | Episode: 437 | Qmax: 401.0053 | Exploration: 0.129037 | Step: 193 | LR: 0.00150000\n",
      "| Reward: -2083 | Episode: 438 | Qmax: 402.1557 | Exploration: 0.128908 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -2508 | Episode: 439 | Qmax: 400.4903 | Exploration: 0.128779 | Step: 268 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1532 | Episode: 440 | Qmax: 400.2387 | Exploration: 0.128650 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -2495 | Episode: 441 | Qmax: 400.2764 | Exploration: 0.128522 | Step: 273 | LR: 0.00150000\n",
      "| Reward: -1883 | Episode: 442 | Qmax: 401.2284 | Exploration: 0.128393 | Step: 282 | LR: 0.00150000\n",
      "| Reward: -2251 | Episode: 443 | Qmax: 402.9591 | Exploration: 0.128265 | Step: 263 | LR: 0.00150000\n",
      "| Reward: -1558 | Episode: 444 | Qmax: 399.9368 | Exploration: 0.128136 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -1439 | Episode: 445 | Qmax: 401.2509 | Exploration: 0.128008 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1859 | Episode: 446 | Qmax: 399.1166 | Exploration: 0.127880 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -1897 | Episode: 447 | Qmax: 402.6187 | Exploration: 0.127752 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -2193 | Episode: 448 | Qmax: 399.4562 | Exploration: 0.127625 | Step: 286 | LR: 0.00150000\n",
      "| Reward: -1598 | Episode: 449 | Qmax: 398.7707 | Exploration: 0.127497 | Step: 159 | LR: 0.00150000\n",
      "| Reward: -1522 | Episode: 450 | Qmax: 398.7297 | Exploration: 0.127369 | Step: 227 | LR: 0.00150000\n",
      "| Reward: -1818 | Episode: 451 | Qmax: 399.9241 | Exploration: 0.127242 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1894 | Episode: 452 | Qmax: 399.6527 | Exploration: 0.127115 | Step: 275 | LR: 0.00150000\n",
      "| Reward: -1829 | Episode: 453 | Qmax: 398.9265 | Exploration: 0.126988 | Step: 156 | LR: 0.00150000\n",
      "| Reward: -1454 | Episode: 454 | Qmax: 398.6240 | Exploration: 0.126861 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -1618 | Episode: 455 | Qmax: 398.1793 | Exploration: 0.126734 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -2798 | Episode: 456 | Qmax: 398.9773 | Exploration: 0.126607 | Step: 423 | LR: 0.00150000\n",
      "| Reward: -1602 | Episode: 457 | Qmax: 399.4682 | Exploration: 0.126481 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -2313 | Episode: 458 | Qmax: 398.7888 | Exploration: 0.126354 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -1666 | Episode: 459 | Qmax: 398.7581 | Exploration: 0.126228 | Step: 218 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2270 | Episode: 460 | Qmax: 398.6227 | Exploration: 0.126101 | Step: 201 | LR: 0.00150000\n",
      "| Reward: -1458 | Episode: 461 | Qmax: 397.7206 | Exploration: 0.125975 | Step: 343 | LR: 0.00150000\n",
      "| Reward: -1613 | Episode: 462 | Qmax: 397.8658 | Exploration: 0.125849 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1634 | Episode: 463 | Qmax: 397.8870 | Exploration: 0.125724 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1784 | Episode: 464 | Qmax: 399.2750 | Exploration: 0.125598 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -1976 | Episode: 465 | Qmax: 400.4206 | Exploration: 0.125472 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -1328 | Episode: 466 | Qmax: 399.3274 | Exploration: 0.125347 | Step: 249 | LR: 0.00150000\n",
      "| Reward: -1683 | Episode: 467 | Qmax: 396.9585 | Exploration: 0.125221 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -3813 | Episode: 468 | Qmax: 396.1509 | Exploration: 0.125096 | Step: 385 | LR: 0.00150000\n",
      "| Reward: -2069 | Episode: 469 | Qmax: 397.0230 | Exploration: 0.124971 | Step: 315 | LR: 0.00150000\n",
      "| Reward: -2635 | Episode: 470 | Qmax: 398.1700 | Exploration: 0.124846 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -2707 | Episode: 471 | Qmax: 397.7163 | Exploration: 0.124721 | Step: 197 | LR: 0.00150000\n",
      "| Reward: -1833 | Episode: 472 | Qmax: 398.1480 | Exploration: 0.124597 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -2030 | Episode: 473 | Qmax: 397.0698 | Exploration: 0.124472 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1411 | Episode: 474 | Qmax: 395.6039 | Exploration: 0.124347 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -1297 | Episode: 475 | Qmax: 396.5811 | Exploration: 0.124223 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -2003 | Episode: 476 | Qmax: 395.7873 | Exploration: 0.124099 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -1324 | Episode: 477 | Qmax: 395.8672 | Exploration: 0.123975 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -1389 | Episode: 478 | Qmax: 395.8114 | Exploration: 0.123851 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -2118 | Episode: 479 | Qmax: 395.2933 | Exploration: 0.123727 | Step: 301 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1949 | Episode: 480 | Qmax: 396.9798 | Exploration: 0.123603 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -2491 | Episode: 481 | Qmax: 394.4705 | Exploration: 0.123480 | Step: 404 | LR: 0.00150000\n",
      "| Reward: -2166 | Episode: 482 | Qmax: 394.5599 | Exploration: 0.123356 | Step: 358 | LR: 0.00150000\n",
      "| Reward: -1908 | Episode: 483 | Qmax: 394.9635 | Exploration: 0.123233 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -2019 | Episode: 484 | Qmax: 394.9615 | Exploration: 0.123110 | Step: 427 | LR: 0.00150000\n",
      "| Reward: -2444 | Episode: 485 | Qmax: 395.9839 | Exploration: 0.122986 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -2468 | Episode: 486 | Qmax: 396.2504 | Exploration: 0.122863 | Step: 291 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2076 | Episode: 487 | Qmax: 396.3699 | Exploration: 0.122741 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -2512 | Episode: 488 | Qmax: 397.7043 | Exploration: 0.122618 | Step: 335 | LR: 0.00150000\n",
      "| Reward: -2615 | Episode: 489 | Qmax: 395.5500 | Exploration: 0.122495 | Step: 321 | LR: 0.00150000\n",
      "| Reward: -1354 | Episode: 490 | Qmax: 393.4309 | Exploration: 0.122373 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -1916 | Episode: 491 | Qmax: 395.6189 | Exploration: 0.122250 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1564 | Episode: 492 | Qmax: 392.8620 | Exploration: 0.122128 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -1417 | Episode: 493 | Qmax: 394.8405 | Exploration: 0.122006 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -2867 | Episode: 494 | Qmax: 393.2179 | Exploration: 0.121884 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -1526 | Episode: 495 | Qmax: 394.4169 | Exploration: 0.121762 | Step: 159 | LR: 0.00150000\n",
      "| Reward: -1675 | Episode: 496 | Qmax: 393.6523 | Exploration: 0.121640 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1222 | Episode: 497 | Qmax: 392.5994 | Exploration: 0.121519 | Step: 206 | LR: 0.00150000\n",
      "| Reward: -1652 | Episode: 498 | Qmax: 391.7720 | Exploration: 0.121397 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -1852 | Episode: 499 | Qmax: 392.9491 | Exploration: 0.121276 | Step: 179 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1766 | Episode: 500 | Qmax: 392.3740 | Exploration: 0.121155 | Step: 192 | LR: 0.00150000\n",
      "| Reward: -1554 | Episode: 501 | Qmax: 392.0592 | Exploration: 0.121033 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -1690 | Episode: 502 | Qmax: 391.9921 | Exploration: 0.120912 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1911 | Episode: 503 | Qmax: 391.5300 | Exploration: 0.120791 | Step: 310 | LR: 0.00150000\n",
      "| Reward: -1310 | Episode: 504 | Qmax: 391.4992 | Exploration: 0.120671 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -1113 | Episode: 505 | Qmax: 391.7712 | Exploration: 0.120550 | Step: 142 | LR: 0.00150000\n",
      "| Reward: -1844 | Episode: 506 | Qmax: 391.9219 | Exploration: 0.120429 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -2907 | Episode: 507 | Qmax: 391.2358 | Exploration: 0.120309 | Step: 307 | LR: 0.00150000\n",
      "| Reward: -1887 | Episode: 508 | Qmax: 390.0815 | Exploration: 0.120189 | Step: 331 | LR: 0.00150000\n",
      "| Reward: -1451 | Episode: 509 | Qmax: 390.9883 | Exploration: 0.120068 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -1712 | Episode: 510 | Qmax: 389.1530 | Exploration: 0.119948 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -1220 | Episode: 511 | Qmax: 392.2522 | Exploration: 0.119828 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1513 | Episode: 512 | Qmax: 389.1927 | Exploration: 0.119709 | Step: 263 | LR: 0.00150000\n",
      "| Reward: -1456 | Episode: 513 | Qmax: 389.4653 | Exploration: 0.119589 | Step: 305 | LR: 0.00150000\n",
      "| Reward: -1963 | Episode: 514 | Qmax: 388.7288 | Exploration: 0.119469 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -1552 | Episode: 515 | Qmax: 388.1032 | Exploration: 0.119350 | Step: 275 | LR: 0.00150000\n",
      "| Reward: -1715 | Episode: 516 | Qmax: 386.3939 | Exploration: 0.119231 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -2204 | Episode: 517 | Qmax: 387.5130 | Exploration: 0.119111 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1202 | Episode: 518 | Qmax: 387.6907 | Exploration: 0.118992 | Step: 204 | LR: 0.00150000\n",
      "| Reward: -1488 | Episode: 519 | Qmax: 387.5212 | Exploration: 0.118873 | Step: 211 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1295 | Episode: 520 | Qmax: 386.3339 | Exploration: 0.118754 | Step: 180 | LR: 0.00150000\n",
      "| Reward: -2147 | Episode: 521 | Qmax: 383.9504 | Exploration: 0.118636 | Step: 348 | LR: 0.00150000\n",
      "| Reward: -1409 | Episode: 522 | Qmax: 384.7928 | Exploration: 0.118517 | Step: 141 | LR: 0.00150000\n",
      "| Reward: -1815 | Episode: 523 | Qmax: 384.4091 | Exploration: 0.118398 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -1503 | Episode: 524 | Qmax: 384.7174 | Exploration: 0.118280 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1906 | Episode: 525 | Qmax: 382.8712 | Exploration: 0.118162 | Step: 224 | LR: 0.00150000\n",
      "| Reward: -1506 | Episode: 526 | Qmax: 382.7549 | Exploration: 0.118044 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -1811 | Episode: 527 | Qmax: 381.8957 | Exploration: 0.117926 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -1571 | Episode: 528 | Qmax: 380.1395 | Exploration: 0.117808 | Step: 303 | LR: 0.00150000\n",
      "| Reward: -1521 | Episode: 529 | Qmax: 380.8076 | Exploration: 0.117690 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -2259 | Episode: 530 | Qmax: 381.5623 | Exploration: 0.117572 | Step: 181 | LR: 0.00150000\n",
      "| Reward: -1925 | Episode: 531 | Qmax: 381.0514 | Exploration: 0.117455 | Step: 261 | LR: 0.00150000\n",
      "| Reward: -1334 | Episode: 532 | Qmax: 380.9085 | Exploration: 0.117337 | Step: 138 | LR: 0.00150000\n",
      "| Reward: -1208 | Episode: 533 | Qmax: 380.2230 | Exploration: 0.117220 | Step: 174 | LR: 0.00150000\n",
      "| Reward: -1798 | Episode: 534 | Qmax: 378.2605 | Exploration: 0.117103 | Step: 179 | LR: 0.00150000\n",
      "| Reward: -2919 | Episode: 535 | Qmax: 377.8482 | Exploration: 0.116985 | Step: 337 | LR: 0.00150000\n",
      "| Reward: -1523 | Episode: 536 | Qmax: 377.9884 | Exploration: 0.116868 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -1488 | Episode: 537 | Qmax: 377.7906 | Exploration: 0.116752 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -1524 | Episode: 538 | Qmax: 376.6405 | Exploration: 0.116635 | Step: 319 | LR: 0.00150000\n",
      "| Reward: -1373 | Episode: 539 | Qmax: 375.3726 | Exploration: 0.116518 | Step: 294 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2153 | Episode: 540 | Qmax: 375.2310 | Exploration: 0.116402 | Step: 354 | LR: 0.00150000\n",
      "| Reward: -1293 | Episode: 541 | Qmax: 374.5896 | Exploration: 0.116285 | Step: 205 | LR: 0.00150000\n",
      "| Reward: -1291 | Episode: 542 | Qmax: 374.0442 | Exploration: 0.116169 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -2001 | Episode: 543 | Qmax: 372.4839 | Exploration: 0.116053 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -1169 | Episode: 544 | Qmax: 373.6186 | Exploration: 0.115937 | Step: 153 | LR: 0.00150000\n",
      "| Reward: -1355 | Episode: 545 | Qmax: 373.7742 | Exploration: 0.115821 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1811 | Episode: 546 | Qmax: 372.0364 | Exploration: 0.115705 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -1689 | Episode: 547 | Qmax: 371.7973 | Exploration: 0.115589 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -1725 | Episode: 548 | Qmax: 372.6799 | Exploration: 0.115474 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1839 | Episode: 549 | Qmax: 370.8286 | Exploration: 0.115358 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1562 | Episode: 550 | Qmax: 370.7983 | Exploration: 0.115243 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -1513 | Episode: 551 | Qmax: 368.6492 | Exploration: 0.115128 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1342 | Episode: 552 | Qmax: 368.2199 | Exploration: 0.115012 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -2287 | Episode: 553 | Qmax: 367.9111 | Exploration: 0.114897 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1688 | Episode: 554 | Qmax: 366.8748 | Exploration: 0.114783 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -1464 | Episode: 555 | Qmax: 367.0638 | Exploration: 0.114668 | Step: 241 | LR: 0.00150000\n",
      "| Reward: -2465 | Episode: 556 | Qmax: 366.0661 | Exploration: 0.114553 | Step: 378 | LR: 0.00150000\n",
      "| Reward: -1410 | Episode: 557 | Qmax: 366.9778 | Exploration: 0.114439 | Step: 160 | LR: 0.00150000\n",
      "| Reward: -1558 | Episode: 558 | Qmax: 366.8160 | Exploration: 0.114324 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -1592 | Episode: 559 | Qmax: 363.6712 | Exploration: 0.114210 | Step: 342 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1609 | Episode: 560 | Qmax: 363.3939 | Exploration: 0.114096 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -1799 | Episode: 561 | Qmax: 363.8620 | Exploration: 0.113982 | Step: 189 | LR: 0.00150000\n",
      "| Reward: -1940 | Episode: 562 | Qmax: 362.2213 | Exploration: 0.113868 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -2179 | Episode: 563 | Qmax: 361.0877 | Exploration: 0.113754 | Step: 371 | LR: 0.00150000\n",
      "| Reward: -1637 | Episode: 564 | Qmax: 359.9726 | Exploration: 0.113640 | Step: 198 | LR: 0.00150000\n",
      "| Reward: -1300 | Episode: 565 | Qmax: 361.7146 | Exploration: 0.113526 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -1944 | Episode: 566 | Qmax: 360.7520 | Exploration: 0.113413 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -1153 | Episode: 567 | Qmax: 362.2613 | Exploration: 0.113299 | Step: 191 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1713 | Episode: 568 | Qmax: 360.4174 | Exploration: 0.113186 | Step: 202 | LR: 0.00150000\n",
      "| Reward: -1534 | Episode: 569 | Qmax: 358.9285 | Exploration: 0.113073 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -1752 | Episode: 570 | Qmax: 358.3457 | Exploration: 0.112960 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -1387 | Episode: 571 | Qmax: 360.1998 | Exploration: 0.112847 | Step: 128 | LR: 0.00150000\n",
      "| Reward: -1428 | Episode: 572 | Qmax: 358.1784 | Exploration: 0.112734 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -1220 | Episode: 573 | Qmax: 357.3186 | Exploration: 0.112621 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1319 | Episode: 574 | Qmax: 356.8322 | Exploration: 0.112509 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1055 | Episode: 575 | Qmax: 355.3575 | Exploration: 0.112396 | Step: 201 | LR: 0.00150000\n",
      "| Reward: -2285 | Episode: 576 | Qmax: 355.4120 | Exploration: 0.112284 | Step: 234 | LR: 0.00150000\n",
      "| Reward: -1431 | Episode: 577 | Qmax: 355.8495 | Exploration: 0.112171 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -2143 | Episode: 578 | Qmax: 354.9999 | Exploration: 0.112059 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -1298 | Episode: 579 | Qmax: 354.0542 | Exploration: 0.111947 | Step: 237 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2423 | Episode: 580 | Qmax: 352.8973 | Exploration: 0.111835 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -1259 | Episode: 581 | Qmax: 353.8829 | Exploration: 0.111723 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1730 | Episode: 582 | Qmax: 351.4435 | Exploration: 0.111612 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -1248 | Episode: 583 | Qmax: 351.5007 | Exploration: 0.111500 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -1457 | Episode: 584 | Qmax: 350.6892 | Exploration: 0.111389 | Step: 234 | LR: 0.00150000\n",
      "| Reward: -2411 | Episode: 585 | Qmax: 350.1883 | Exploration: 0.111277 | Step: 315 | LR: 0.00150000\n",
      "| Reward: -1345 | Episode: 586 | Qmax: 348.9798 | Exploration: 0.111166 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1431 | Episode: 587 | Qmax: 350.4454 | Exploration: 0.111055 | Step: 181 | LR: 0.00150000\n",
      "| Reward: -1558 | Episode: 588 | Qmax: 349.0919 | Exploration: 0.110944 | Step: 344 | LR: 0.00150000\n",
      "| Reward: -1753 | Episode: 589 | Qmax: 349.2573 | Exploration: 0.110833 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -1341 | Episode: 590 | Qmax: 349.4103 | Exploration: 0.110722 | Step: 172 | LR: 0.00150000\n",
      "| Reward: -1050 | Episode: 591 | Qmax: 348.1078 | Exploration: 0.110611 | Step: 241 | LR: 0.00150000\n",
      "| Reward: -1111 | Episode: 592 | Qmax: 347.4674 | Exploration: 0.110501 | Step: 221 | LR: 0.00150000\n",
      "| Reward: -1989 | Episode: 593 | Qmax: 346.6215 | Exploration: 0.110390 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1395 | Episode: 594 | Qmax: 346.7745 | Exploration: 0.110280 | Step: 136 | LR: 0.00150000\n",
      "| Reward: -1722 | Episode: 595 | Qmax: 346.0145 | Exploration: 0.110169 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -1289 | Episode: 596 | Qmax: 345.7250 | Exploration: 0.110059 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -2166 | Episode: 597 | Qmax: 344.1385 | Exploration: 0.109949 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -1866 | Episode: 598 | Qmax: 343.7837 | Exploration: 0.109839 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -1778 | Episode: 599 | Qmax: 343.2962 | Exploration: 0.109729 | Step: 285 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1310 | Episode: 600 | Qmax: 343.1555 | Exploration: 0.109620 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -1919 | Episode: 601 | Qmax: 342.3527 | Exploration: 0.109510 | Step: 345 | LR: 0.00150000\n",
      "| Reward: -1240 | Episode: 602 | Qmax: 341.7828 | Exploration: 0.109401 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -1224 | Episode: 603 | Qmax: 341.8515 | Exploration: 0.109291 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -1652 | Episode: 604 | Qmax: 340.6462 | Exploration: 0.109182 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -1128 | Episode: 605 | Qmax: 340.1708 | Exploration: 0.109073 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1117 | Episode: 606 | Qmax: 338.7290 | Exploration: 0.108964 | Step: 191 | LR: 0.00150000\n",
      "| Reward: -1192 | Episode: 607 | Qmax: 338.4867 | Exploration: 0.108855 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1961 | Episode: 608 | Qmax: 337.9709 | Exploration: 0.108746 | Step: 315 | LR: 0.00150000\n",
      "| Reward: -1641 | Episode: 609 | Qmax: 337.2682 | Exploration: 0.108637 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -1471 | Episode: 610 | Qmax: 336.8258 | Exploration: 0.108528 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1808 | Episode: 611 | Qmax: 336.3394 | Exploration: 0.108420 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -1643 | Episode: 612 | Qmax: 335.6788 | Exploration: 0.108311 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -1162 | Episode: 613 | Qmax: 336.3813 | Exploration: 0.108203 | Step: 155 | LR: 0.00150000\n",
      "| Reward: -2440 | Episode: 614 | Qmax: 335.1217 | Exploration: 0.108095 | Step: 335 | LR: 0.00150000\n",
      "| Reward: -1620 | Episode: 615 | Qmax: 333.6101 | Exploration: 0.107987 | Step: 244 | LR: 0.00150000\n",
      "| Reward: -1212 | Episode: 616 | Qmax: 333.3913 | Exploration: 0.107879 | Step: 142 | LR: 0.00150000\n",
      "| Reward: -1618 | Episode: 617 | Qmax: 332.5520 | Exploration: 0.107771 | Step: 233 | LR: 0.00150000\n",
      "| Reward: -1321 | Episode: 618 | Qmax: 331.1620 | Exploration: 0.107663 | Step: 314 | LR: 0.00150000\n",
      "| Reward: -2103 | Episode: 619 | Qmax: 331.6978 | Exploration: 0.107556 | Step: 313 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1522 | Episode: 620 | Qmax: 330.8998 | Exploration: 0.107448 | Step: 254 | LR: 0.00150000\n",
      "| Reward: -1816 | Episode: 621 | Qmax: 329.8955 | Exploration: 0.107341 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -1316 | Episode: 622 | Qmax: 329.6015 | Exploration: 0.107233 | Step: 192 | LR: 0.00150000\n",
      "| Reward: -1877 | Episode: 623 | Qmax: 328.6290 | Exploration: 0.107126 | Step: 348 | LR: 0.00150000\n",
      "| Reward: -1119 | Episode: 624 | Qmax: 329.0969 | Exploration: 0.107019 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -2635 | Episode: 625 | Qmax: 328.8215 | Exploration: 0.106912 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -1355 | Episode: 626 | Qmax: 327.7269 | Exploration: 0.106805 | Step: 294 | LR: 0.00150000\n",
      "| Reward: -1878 | Episode: 627 | Qmax: 326.4850 | Exploration: 0.106698 | Step: 358 | LR: 0.00150000\n",
      "| Reward: -1795 | Episode: 628 | Qmax: 325.8847 | Exploration: 0.106591 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -1229 | Episode: 629 | Qmax: 325.6987 | Exploration: 0.106485 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -1283 | Episode: 630 | Qmax: 324.5712 | Exploration: 0.106378 | Step: 204 | LR: 0.00150000\n",
      "| Reward: -2239 | Episode: 631 | Qmax: 324.1200 | Exploration: 0.106272 | Step: 314 | LR: 0.00150000\n",
      "| Reward: -1627 | Episode: 632 | Qmax: 322.7530 | Exploration: 0.106166 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1572 | Episode: 633 | Qmax: 323.5135 | Exploration: 0.106059 | Step: 205 | LR: 0.00150000\n",
      "| Reward: -1995 | Episode: 634 | Qmax: 322.2692 | Exploration: 0.105953 | Step: 304 | LR: 0.00150000\n",
      "| Reward: -1943 | Episode: 635 | Qmax: 322.0481 | Exploration: 0.105847 | Step: 279 | LR: 0.00150000\n",
      "| Reward: -2073 | Episode: 636 | Qmax: 321.0574 | Exploration: 0.105742 | Step: 193 | LR: 0.00150000\n",
      "| Reward: -1427 | Episode: 637 | Qmax: 321.2958 | Exploration: 0.105636 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1974 | Episode: 638 | Qmax: 320.8046 | Exploration: 0.105530 | Step: 247 | LR: 0.00150000\n",
      "| Reward: -1430 | Episode: 639 | Qmax: 318.4538 | Exploration: 0.105425 | Step: 234 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1429 | Episode: 640 | Qmax: 318.0110 | Exploration: 0.105319 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -2254 | Episode: 641 | Qmax: 318.3169 | Exploration: 0.105214 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1073 | Episode: 642 | Qmax: 317.3354 | Exploration: 0.105109 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -1764 | Episode: 643 | Qmax: 317.8962 | Exploration: 0.105004 | Step: 280 | LR: 0.00150000\n",
      "| Reward: -1392 | Episode: 644 | Qmax: 316.1737 | Exploration: 0.104899 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1491 | Episode: 645 | Qmax: 315.8180 | Exploration: 0.104794 | Step: 241 | LR: 0.00150000\n",
      "| Reward: -1993 | Episode: 646 | Qmax: 314.2287 | Exploration: 0.104689 | Step: 428 | LR: 0.00150000\n",
      "| Reward: -1437 | Episode: 647 | Qmax: 314.8370 | Exploration: 0.104584 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -2350 | Episode: 648 | Qmax: 314.0676 | Exploration: 0.104480 | Step: 218 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2153 | Episode: 649 | Qmax: 312.8498 | Exploration: 0.104375 | Step: 381 | LR: 0.00150000\n",
      "| Reward: -2122 | Episode: 650 | Qmax: 311.4533 | Exploration: 0.104271 | Step: 251 | LR: 0.00150000\n",
      "| Reward: -1579 | Episode: 651 | Qmax: 311.5913 | Exploration: 0.104167 | Step: 419 | LR: 0.00150000\n",
      "| Reward: -1263 | Episode: 652 | Qmax: 311.8647 | Exploration: 0.104062 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -1360 | Episode: 653 | Qmax: 311.0455 | Exploration: 0.103958 | Step: 290 | LR: 0.00150000\n",
      "| Reward: -1126 | Episode: 654 | Qmax: 313.0032 | Exploration: 0.103854 | Step: 137 | LR: 0.00150000\n",
      "| Reward: -1519 | Episode: 655 | Qmax: 309.7170 | Exploration: 0.103751 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1867 | Episode: 656 | Qmax: 309.2363 | Exploration: 0.103647 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -947 | Episode: 657 | Qmax: 310.1439 | Exploration: 0.103543 | Step: 165 | LR: 0.00150000\n",
      "| Reward: -1863 | Episode: 658 | Qmax: 309.0232 | Exploration: 0.103440 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1895 | Episode: 659 | Qmax: 307.8179 | Exploration: 0.103336 | Step: 276 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2117 | Episode: 660 | Qmax: 308.4309 | Exploration: 0.103233 | Step: 255 | LR: 0.00150000\n",
      "| Reward: -1170 | Episode: 661 | Qmax: 306.9044 | Exploration: 0.103130 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1772 | Episode: 662 | Qmax: 306.5704 | Exploration: 0.103026 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -1628 | Episode: 663 | Qmax: 306.8786 | Exploration: 0.102923 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -2040 | Episode: 664 | Qmax: 305.7816 | Exploration: 0.102820 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -2027 | Episode: 665 | Qmax: 304.8838 | Exploration: 0.102718 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -1675 | Episode: 666 | Qmax: 302.9523 | Exploration: 0.102615 | Step: 416 | LR: 0.00150000\n",
      "| Reward: -1285 | Episode: 667 | Qmax: 302.4545 | Exploration: 0.102512 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -1959 | Episode: 669 | Qmax: 301.5143 | Exploration: 0.102307 | Step: 367 | LR: 0.00150000\n",
      "| Reward: -916 | Episode: 670 | Qmax: 301.1004 | Exploration: 0.102205 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -1453 | Episode: 671 | Qmax: 300.0589 | Exploration: 0.102103 | Step: 320 | LR: 0.00150000\n",
      "| Reward: -1193 | Episode: 672 | Qmax: 299.5986 | Exploration: 0.102001 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1708 | Episode: 673 | Qmax: 299.2266 | Exploration: 0.101899 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -1489 | Episode: 674 | Qmax: 298.2338 | Exploration: 0.101797 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -1941 | Episode: 675 | Qmax: 297.0156 | Exploration: 0.101695 | Step: 421 | LR: 0.00150000\n",
      "| Reward: -1915 | Episode: 676 | Qmax: 296.0907 | Exploration: 0.101593 | Step: 332 | LR: 0.00150000\n",
      "| Reward: -1417 | Episode: 677 | Qmax: 296.9219 | Exploration: 0.101492 | Step: 239 | LR: 0.00150000\n",
      "| Reward: -1613 | Episode: 678 | Qmax: 295.6585 | Exploration: 0.101390 | Step: 264 | LR: 0.00150000\n",
      "| Reward: -2214 | Episode: 679 | Qmax: 293.9264 | Exploration: 0.101289 | Step: 361 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1771 | Episode: 680 | Qmax: 293.1219 | Exploration: 0.101188 | Step: 296 | LR: 0.00150000\n",
      "| Reward: -1735 | Episode: 681 | Qmax: 292.8675 | Exploration: 0.101086 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1157 | Episode: 682 | Qmax: 292.6728 | Exploration: 0.100985 | Step: 276 | LR: 0.00150000\n",
      "| Reward: -1839 | Episode: 683 | Qmax: 291.3010 | Exploration: 0.100884 | Step: 337 | LR: 0.00150000\n",
      "| Reward: -1295 | Episode: 684 | Qmax: 291.3337 | Exploration: 0.100783 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -2019 | Episode: 685 | Qmax: 289.8259 | Exploration: 0.100683 | Step: 373 | LR: 0.00150000\n",
      "| Reward: -1757 | Episode: 686 | Qmax: 289.3245 | Exploration: 0.100582 | Step: 255 | LR: 0.00150000\n",
      "| Reward: -1751 | Episode: 687 | Qmax: 288.9359 | Exploration: 0.100481 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1282 | Episode: 688 | Qmax: 287.7183 | Exploration: 0.100381 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -1359 | Episode: 689 | Qmax: 287.1742 | Exploration: 0.100281 | Step: 307 | LR: 0.00150000\n",
      "| Reward: -1653 | Episode: 690 | Qmax: 287.0884 | Exploration: 0.100180 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -2075 | Episode: 691 | Qmax: 286.1335 | Exploration: 0.100080 | Step: 339 | LR: 0.00150000\n",
      "| Reward: -1170 | Episode: 692 | Qmax: 286.9785 | Exploration: 0.099980 | Step: 172 | LR: 0.00150000\n",
      "| Reward: -1635 | Episode: 693 | Qmax: 284.6408 | Exploration: 0.099880 | Step: 376 | LR: 0.00150000\n",
      "| Reward: -2222 | Episode: 694 | Qmax: 283.6256 | Exploration: 0.099780 | Step: 495 | LR: 0.00150000\n",
      "| Reward: -2334 | Episode: 695 | Qmax: 283.1275 | Exploration: 0.099680 | Step: 373 | LR: 0.00150000\n",
      "| Reward: -1260 | Episode: 696 | Qmax: 282.6365 | Exploration: 0.099581 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1681 | Episode: 697 | Qmax: 281.8473 | Exploration: 0.099481 | Step: 332 | LR: 0.00150000\n",
      "| Reward: -1345 | Episode: 698 | Qmax: 280.9498 | Exploration: 0.099382 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -1602 | Episode: 699 | Qmax: 280.8732 | Exploration: 0.099282 | Step: 235 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1421 | Episode: 700 | Qmax: 279.8656 | Exploration: 0.099183 | Step: 288 | LR: 0.00150000\n",
      "| Reward: -1987 | Episode: 701 | Qmax: 278.9415 | Exploration: 0.099084 | Step: 377 | LR: 0.00150000\n",
      "| Reward: -1504 | Episode: 702 | Qmax: 278.7700 | Exploration: 0.098985 | Step: 353 | LR: 0.00150000\n",
      "| Reward: -2013 | Episode: 703 | Qmax: 278.4072 | Exploration: 0.098886 | Step: 349 | LR: 0.00150000\n",
      "| Reward: -1449 | Episode: 704 | Qmax: 278.3396 | Exploration: 0.098787 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1458 | Episode: 705 | Qmax: 276.7521 | Exploration: 0.098688 | Step: 334 | LR: 0.00150000\n",
      "| Reward: -2321 | Episode: 706 | Qmax: 276.8475 | Exploration: 0.098589 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1627 | Episode: 707 | Qmax: 276.5401 | Exploration: 0.098491 | Step: 350 | LR: 0.00150000\n",
      "| Reward: -2149 | Episode: 708 | Qmax: 275.8635 | Exploration: 0.098392 | Step: 269 | LR: 0.00150000\n",
      "| Reward: -1533 | Episode: 709 | Qmax: 276.4356 | Exploration: 0.098294 | Step: 274 | LR: 0.00150000\n",
      "| Reward: -2071 | Episode: 710 | Qmax: 275.1729 | Exploration: 0.098196 | Step: 353 | LR: 0.00150000\n",
      "| Reward: -1383 | Episode: 711 | Qmax: 274.0284 | Exploration: 0.098097 | Step: 457 | LR: 0.00150000\n",
      "| Reward: -1242 | Episode: 712 | Qmax: 272.6765 | Exploration: 0.097999 | Step: 478 | LR: 0.00150000\n",
      "| Reward: -1765 | Episode: 713 | Qmax: 272.2577 | Exploration: 0.097901 | Step: 398 | LR: 0.00150000\n",
      "| Reward: -1572 | Episode: 714 | Qmax: 270.9473 | Exploration: 0.097803 | Step: 502 | LR: 0.00150000\n",
      "| Reward: -1472 | Episode: 715 | Qmax: 271.4333 | Exploration: 0.097706 | Step: 294 | LR: 0.00150000\n",
      "| Reward: -1460 | Episode: 716 | Qmax: 270.2032 | Exploration: 0.097608 | Step: 327 | LR: 0.00150000\n",
      "| Reward: -1760 | Episode: 717 | Qmax: 269.0040 | Exploration: 0.097510 | Step: 375 | LR: 0.00150000\n",
      "| Reward: -2280 | Episode: 718 | Qmax: 268.0903 | Exploration: 0.097413 | Step: 427 | LR: 0.00150000\n",
      "| Reward: -1667 | Episode: 719 | Qmax: 268.5295 | Exploration: 0.097315 | Step: 183 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1523 | Episode: 720 | Qmax: 267.3084 | Exploration: 0.097218 | Step: 255 | LR: 0.00150000\n",
      "| Reward: -1771 | Episode: 721 | Qmax: 266.4321 | Exploration: 0.097121 | Step: 287 | LR: 0.00150000\n",
      "| Reward: -1589 | Episode: 722 | Qmax: 265.2318 | Exploration: 0.097024 | Step: 465 | LR: 0.00150000\n",
      "| Reward: -1887 | Episode: 723 | Qmax: 264.8995 | Exploration: 0.096927 | Step: 376 | LR: 0.00150000\n",
      "| Reward: -1997 | Episode: 724 | Qmax: 263.8653 | Exploration: 0.096830 | Step: 423 | LR: 0.00150000\n",
      "| Reward: -1564 | Episode: 725 | Qmax: 262.9393 | Exploration: 0.096733 | Step: 368 | LR: 0.00150000\n",
      "| Reward: -1295 | Episode: 726 | Qmax: 262.2126 | Exploration: 0.096636 | Step: 297 | LR: 0.00150000\n",
      "| Reward: -2325 | Episode: 727 | Qmax: 261.6190 | Exploration: 0.096540 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -1212 | Episode: 728 | Qmax: 261.5844 | Exploration: 0.096443 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -2370 | Episode: 729 | Qmax: 260.3553 | Exploration: 0.096347 | Step: 427 | LR: 0.00150000\n",
      "| Reward: -1472 | Episode: 730 | Qmax: 259.2627 | Exploration: 0.096250 | Step: 429 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1495 | Episode: 731 | Qmax: 259.1963 | Exploration: 0.096154 | Step: 227 | LR: 0.00150000\n",
      "| Reward: -1552 | Episode: 732 | Qmax: 259.1102 | Exploration: 0.096058 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -1774 | Episode: 733 | Qmax: 257.4386 | Exploration: 0.095962 | Step: 335 | LR: 0.00150000\n",
      "| Reward: -1788 | Episode: 734 | Qmax: 256.8932 | Exploration: 0.095866 | Step: 241 | LR: 0.00150000\n",
      "| Reward: -2274 | Episode: 735 | Qmax: 256.5508 | Exploration: 0.095770 | Step: 448 | LR: 0.00150000\n",
      "| Reward: -2303 | Episode: 736 | Qmax: 255.5041 | Exploration: 0.095674 | Step: 405 | LR: 0.00150000\n",
      "| Reward: -1964 | Episode: 737 | Qmax: 254.6213 | Exploration: 0.095579 | Step: 354 | LR: 0.00150000\n",
      "| Reward: -1301 | Episode: 738 | Qmax: 254.6712 | Exploration: 0.095483 | Step: 402 | LR: 0.00150000\n",
      "| Reward: -1812 | Episode: 739 | Qmax: 253.8170 | Exploration: 0.095387 | Step: 391 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1352 | Episode: 740 | Qmax: 252.8281 | Exploration: 0.095292 | Step: 282 | LR: 0.00150000\n",
      "| Reward: -1768 | Episode: 741 | Qmax: 252.1705 | Exploration: 0.095197 | Step: 365 | LR: 0.00150000\n",
      "| Reward: -1126 | Episode: 742 | Qmax: 251.7548 | Exploration: 0.095102 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -1694 | Episode: 743 | Qmax: 251.3098 | Exploration: 0.095006 | Step: 390 | LR: 0.00150000\n",
      "| Reward: -1695 | Episode: 744 | Qmax: 251.0137 | Exploration: 0.094911 | Step: 400 | LR: 0.00150000\n",
      "| Reward: -1464 | Episode: 745 | Qmax: 250.0186 | Exploration: 0.094817 | Step: 286 | LR: 0.00150000\n",
      "| Reward: -1380 | Episode: 746 | Qmax: 249.3110 | Exploration: 0.094722 | Step: 337 | LR: 0.00150000\n",
      "| Reward: -2392 | Episode: 747 | Qmax: 249.1479 | Exploration: 0.094627 | Step: 260 | LR: 0.00150000\n",
      "| Reward: -1644 | Episode: 748 | Qmax: 247.8125 | Exploration: 0.094532 | Step: 385 | LR: 0.00150000\n",
      "| Reward: -1454 | Episode: 749 | Qmax: 247.4546 | Exploration: 0.094438 | Step: 312 | LR: 0.00150000\n",
      "| Reward: -2015 | Episode: 750 | Qmax: 246.3704 | Exploration: 0.094343 | Step: 540 | LR: 0.00150000\n",
      "| Reward: -2146 | Episode: 751 | Qmax: 245.7964 | Exploration: 0.094249 | Step: 419 | LR: 0.00150000\n",
      "| Reward: -2326 | Episode: 752 | Qmax: 244.0778 | Exploration: 0.094155 | Step: 383 | LR: 0.00150000\n",
      "| Reward: -1379 | Episode: 753 | Qmax: 243.9667 | Exploration: 0.094061 | Step: 327 | LR: 0.00150000\n",
      "| Reward: -2037 | Episode: 754 | Qmax: 243.7711 | Exploration: 0.093967 | Step: 292 | LR: 0.00150000\n",
      "| Reward: -3030 | Episode: 755 | Qmax: 242.1377 | Exploration: 0.093873 | Step: 664 | LR: 0.00150000\n",
      "| Reward: -4636 | Episode: 756 | Qmax: 240.4996 | Exploration: 0.093873 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1526 | Episode: 757 | Qmax: 239.8730 | Exploration: 0.093779 | Step: 267 | LR: 0.00150000\n",
      "| Reward: -1724 | Episode: 758 | Qmax: 239.3653 | Exploration: 0.093685 | Step: 447 | LR: 0.00150000\n",
      "| Reward: -1679 | Episode: 759 | Qmax: 238.1110 | Exploration: 0.093591 | Step: 438 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -901 | Episode: 760 | Qmax: 237.5761 | Exploration: 0.093498 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1377 | Episode: 761 | Qmax: 237.4995 | Exploration: 0.093404 | Step: 298 | LR: 0.00150000\n",
      "| Reward: -1431 | Episode: 762 | Qmax: 237.6464 | Exploration: 0.093311 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -2769 | Episode: 763 | Qmax: 236.1370 | Exploration: 0.093218 | Step: 565 | LR: 0.00150000\n",
      "| Reward: -1993 | Episode: 764 | Qmax: 235.7345 | Exploration: 0.093124 | Step: 347 | LR: 0.00150000\n",
      "| Reward: -4673 | Episode: 765 | Qmax: 234.0215 | Exploration: 0.093031 | Step: 723 | LR: 0.00150000\n",
      "| Reward: -2484 | Episode: 766 | Qmax: 232.6502 | Exploration: 0.092938 | Step: 658 | LR: 0.00150000\n",
      "| Reward: -2728 | Episode: 767 | Qmax: 232.0710 | Exploration: 0.092845 | Step: 488 | LR: 0.00150000\n",
      "| Reward: -2192 | Episode: 768 | Qmax: 231.7004 | Exploration: 0.092752 | Step: 303 | LR: 0.00150000\n",
      "| Reward: -1275 | Episode: 769 | Qmax: 231.0214 | Exploration: 0.092660 | Step: 385 | LR: 0.00150000\n",
      "| Reward: -1876 | Episode: 770 | Qmax: 229.7815 | Exploration: 0.092567 | Step: 491 | LR: 0.00150000\n",
      "| Reward: -1734 | Episode: 771 | Qmax: 229.7096 | Exploration: 0.092474 | Step: 349 | LR: 0.00150000\n",
      "| Reward: -2929 | Episode: 772 | Qmax: 228.5989 | Exploration: 0.092382 | Step: 383 | LR: 0.00150000\n",
      "| Reward: -1862 | Episode: 773 | Qmax: 228.5472 | Exploration: 0.092290 | Step: 306 | LR: 0.00150000\n",
      "| Reward: -5095 | Episode: 774 | Qmax: 226.8575 | Exploration: 0.092290 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2043 | Episode: 775 | Qmax: 226.2012 | Exploration: 0.092197 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -2935 | Episode: 776 | Qmax: 224.8016 | Exploration: 0.092105 | Step: 641 | LR: 0.00150000\n",
      "| Reward: -2435 | Episode: 777 | Qmax: 223.4937 | Exploration: 0.092013 | Step: 546 | LR: 0.00150000\n",
      "| Reward: -3993 | Episode: 778 | Qmax: 222.4302 | Exploration: 0.091921 | Step: 952 | LR: 0.00150000\n",
      "| Reward: -2996 | Episode: 779 | Qmax: 220.9853 | Exploration: 0.091829 | Step: 702 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1823 | Episode: 780 | Qmax: 221.0420 | Exploration: 0.091737 | Step: 258 | LR: 0.00150000\n",
      "| Reward: -3777 | Episode: 781 | Qmax: 219.1474 | Exploration: 0.091645 | Step: 997 | LR: 0.00150000\n",
      "| Reward: -1747 | Episode: 782 | Qmax: 218.5109 | Exploration: 0.091554 | Step: 362 | LR: 0.00150000\n",
      "| Reward: -1622 | Episode: 783 | Qmax: 218.2691 | Exploration: 0.091462 | Step: 327 | LR: 0.00150000\n",
      "| Reward: -4501 | Episode: 784 | Qmax: 216.7134 | Exploration: 0.091462 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2109 | Episode: 785 | Qmax: 216.1029 | Exploration: 0.091371 | Step: 409 | LR: 0.00150000\n",
      "| Reward: -4420 | Episode: 786 | Qmax: 214.4895 | Exploration: 0.091371 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2842 | Episode: 787 | Qmax: 213.3496 | Exploration: 0.091279 | Step: 566 | LR: 0.00150000\n",
      "| Reward: -3243 | Episode: 788 | Qmax: 212.5666 | Exploration: 0.091188 | Step: 670 | LR: 0.00150000\n",
      "| Reward: -1450 | Episode: 789 | Qmax: 211.9890 | Exploration: 0.091097 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -2937 | Episode: 790 | Qmax: 210.7453 | Exploration: 0.091006 | Step: 616 | LR: 0.00150000\n",
      "| Reward: -1504 | Episode: 791 | Qmax: 210.4916 | Exploration: 0.090915 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -2714 | Episode: 792 | Qmax: 209.9822 | Exploration: 0.090824 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -4414 | Episode: 793 | Qmax: 208.5724 | Exploration: 0.090733 | Step: 941 | LR: 0.00150000\n",
      "| Reward: -2869 | Episode: 794 | Qmax: 207.3455 | Exploration: 0.090642 | Step: 539 | LR: 0.00150000\n",
      "| Reward: -3622 | Episode: 795 | Qmax: 206.5082 | Exploration: 0.090552 | Step: 590 | LR: 0.00150000\n",
      "| Reward: -1871 | Episode: 796 | Qmax: 206.6216 | Exploration: 0.090461 | Step: 288 | LR: 0.00150000\n",
      "| Reward: -1829 | Episode: 797 | Qmax: 205.9376 | Exploration: 0.090371 | Step: 282 | LR: 0.00150000\n",
      "| Reward: -1669 | Episode: 798 | Qmax: 205.5320 | Exploration: 0.090280 | Step: 338 | LR: 0.00150000\n",
      "| Reward: -1583 | Episode: 799 | Qmax: 205.1239 | Exploration: 0.090190 | Step: 198 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2920 | Episode: 800 | Qmax: 203.8022 | Exploration: 0.090100 | Step: 860 | LR: 0.00150000\n",
      "| Reward: -2717 | Episode: 801 | Qmax: 203.0438 | Exploration: 0.090010 | Step: 621 | LR: 0.00150000\n",
      "| Reward: -3060 | Episode: 802 | Qmax: 202.5105 | Exploration: 0.089920 | Step: 568 | LR: 0.00150000\n",
      "| Reward: -1212 | Episode: 803 | Qmax: 201.7650 | Exploration: 0.089830 | Step: 295 | LR: 0.00150000\n",
      "| Reward: -3580 | Episode: 804 | Qmax: 201.1239 | Exploration: 0.089740 | Step: 881 | LR: 0.00150000\n",
      "| Reward: -2190 | Episode: 805 | Qmax: 199.8001 | Exploration: 0.089650 | Step: 490 | LR: 0.00150000\n",
      "| Reward: -2041 | Episode: 806 | Qmax: 199.8828 | Exploration: 0.089561 | Step: 287 | LR: 0.00150000\n",
      "| Reward: -2146 | Episode: 807 | Qmax: 199.3884 | Exploration: 0.089471 | Step: 329 | LR: 0.00150000\n",
      "| Reward: -1468 | Episode: 808 | Qmax: 198.8714 | Exploration: 0.089382 | Step: 236 | LR: 0.00150000\n",
      "| Reward: -1726 | Episode: 809 | Qmax: 198.7344 | Exploration: 0.089292 | Step: 296 | LR: 0.00150000\n",
      "| Reward: -3596 | Episode: 810 | Qmax: 196.7589 | Exploration: 0.089203 | Step: 852 | LR: 0.00150000\n",
      "| Reward: -1927 | Episode: 811 | Qmax: 195.8723 | Exploration: 0.089114 | Step: 497 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1341 | Episode: 812 | Qmax: 195.3415 | Exploration: 0.089025 | Step: 370 | LR: 0.00150000\n",
      "| Reward: -1950 | Episode: 813 | Qmax: 194.5038 | Exploration: 0.088936 | Step: 331 | LR: 0.00150000\n",
      "| Reward: -2494 | Episode: 814 | Qmax: 193.8507 | Exploration: 0.088847 | Step: 488 | LR: 0.00150000\n",
      "| Reward: -1162 | Episode: 815 | Qmax: 194.0977 | Exploration: 0.088758 | Step: 209 | LR: 0.00150000\n",
      "| Reward: -1914 | Episode: 816 | Qmax: 192.5241 | Exploration: 0.088669 | Step: 493 | LR: 0.00150000\n",
      "| Reward: -4096 | Episode: 817 | Qmax: 190.8537 | Exploration: 0.088669 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1841 | Episode: 818 | Qmax: 190.3171 | Exploration: 0.088580 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -1359 | Episode: 819 | Qmax: 189.8210 | Exploration: 0.088492 | Step: 487 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1705 | Episode: 820 | Qmax: 188.7089 | Exploration: 0.088403 | Step: 392 | LR: 0.00150000\n",
      "| Reward: -1281 | Episode: 821 | Qmax: 188.2374 | Exploration: 0.088315 | Step: 409 | LR: 0.00150000\n",
      "| Reward: -1238 | Episode: 822 | Qmax: 187.2543 | Exploration: 0.088227 | Step: 285 | LR: 0.00150000\n",
      "| Reward: -1773 | Episode: 823 | Qmax: 186.2215 | Exploration: 0.088138 | Step: 451 | LR: 0.00150000\n",
      "| Reward: -2557 | Episode: 824 | Qmax: 185.4467 | Exploration: 0.088050 | Step: 389 | LR: 0.00150000\n",
      "| Reward: -3340 | Episode: 825 | Qmax: 183.7323 | Exploration: 0.088050 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3295 | Episode: 826 | Qmax: 181.5090 | Exploration: 0.088050 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1862 | Episode: 827 | Qmax: 180.5455 | Exploration: 0.087962 | Step: 513 | LR: 0.00150000\n",
      "| Reward: -2147 | Episode: 828 | Qmax: 179.2609 | Exploration: 0.087874 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -1855 | Episode: 829 | Qmax: 178.2166 | Exploration: 0.087786 | Step: 515 | LR: 0.00150000\n",
      "| Reward: -1625 | Episode: 830 | Qmax: 177.8431 | Exploration: 0.087699 | Step: 393 | LR: 0.00150000\n",
      "| Reward: -1419 | Episode: 831 | Qmax: 177.0347 | Exploration: 0.087611 | Step: 277 | LR: 0.00150000\n",
      "| Reward: -2034 | Episode: 832 | Qmax: 176.5130 | Exploration: 0.087523 | Step: 298 | LR: 0.00150000\n",
      "| Reward: -2767 | Episode: 833 | Qmax: 174.9613 | Exploration: 0.087436 | Step: 779 | LR: 0.00150000\n",
      "| Reward: -2194 | Episode: 834 | Qmax: 173.2936 | Exploration: 0.087348 | Step: 890 | LR: 0.00150000\n",
      "| Reward: -1546 | Episode: 835 | Qmax: 172.2207 | Exploration: 0.087261 | Step: 449 | LR: 0.00150000\n",
      "| Reward: -2996 | Episode: 836 | Qmax: 170.6509 | Exploration: 0.087174 | Step: 783 | LR: 0.00150000\n",
      "| Reward: -2386 | Episode: 837 | Qmax: 169.2281 | Exploration: 0.087086 | Step: 677 | LR: 0.00150000\n",
      "| Reward: -2998 | Episode: 838 | Qmax: 167.4499 | Exploration: 0.087086 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1149 | Episode: 839 | Qmax: 166.9467 | Exploration: 0.086999 | Step: 241 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1649 | Episode: 840 | Qmax: 165.4913 | Exploration: 0.086912 | Step: 408 | LR: 0.00150000\n",
      "| Reward: -1788 | Episode: 841 | Qmax: 164.7203 | Exploration: 0.086825 | Step: 457 | LR: 0.00150000\n",
      "| Reward: -2268 | Episode: 842 | Qmax: 163.5788 | Exploration: 0.086739 | Step: 451 | LR: 0.00150000\n",
      "| Reward: -2340 | Episode: 843 | Qmax: 162.4513 | Exploration: 0.086652 | Step: 640 | LR: 0.00150000\n",
      "| Reward: -1636 | Episode: 844 | Qmax: 161.8652 | Exploration: 0.086565 | Step: 368 | LR: 0.00150000\n",
      "| Reward: -1958 | Episode: 845 | Qmax: 160.7200 | Exploration: 0.086479 | Step: 420 | LR: 0.00150000\n",
      "| Reward: -2982 | Episode: 846 | Qmax: 159.4840 | Exploration: 0.086392 | Step: 859 | LR: 0.00150000\n",
      "| Reward: -2026 | Episode: 847 | Qmax: 158.4346 | Exploration: 0.086306 | Step: 434 | LR: 0.00150000\n",
      "| Reward: -2152 | Episode: 848 | Qmax: 157.6353 | Exploration: 0.086220 | Step: 443 | LR: 0.00150000\n",
      "| Reward: -4231 | Episode: 849 | Qmax: 156.2297 | Exploration: 0.086220 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2632 | Episode: 850 | Qmax: 154.8986 | Exploration: 0.086133 | Step: 545 | LR: 0.00150000\n",
      "| Reward: -1438 | Episode: 851 | Qmax: 154.0760 | Exploration: 0.086047 | Step: 386 | LR: 0.00150000\n",
      "| Reward: -2624 | Episode: 852 | Qmax: 152.9055 | Exploration: 0.085961 | Step: 726 | LR: 0.00150000\n",
      "| Reward: -2032 | Episode: 853 | Qmax: 151.4869 | Exploration: 0.085875 | Step: 494 | LR: 0.00150000\n",
      "| Reward: -2130 | Episode: 854 | Qmax: 150.8248 | Exploration: 0.085789 | Step: 448 | LR: 0.00150000\n",
      "| Reward: -3691 | Episode: 855 | Qmax: 149.5817 | Exploration: 0.085789 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2907 | Episode: 856 | Qmax: 147.9035 | Exploration: 0.085703 | Step: 793 | LR: 0.00150000\n",
      "| Reward: -2067 | Episode: 857 | Qmax: 146.6130 | Exploration: 0.085618 | Step: 556 | LR: 0.00150000\n",
      "| Reward: -2329 | Episode: 858 | Qmax: 145.4700 | Exploration: 0.085532 | Step: 593 | LR: 0.00150000\n",
      "| Reward: -2825 | Episode: 859 | Qmax: 144.2749 | Exploration: 0.085447 | Step: 549 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1629 | Episode: 860 | Qmax: 143.1847 | Exploration: 0.085361 | Step: 622 | LR: 0.00150000\n",
      "| Reward: -1537 | Episode: 861 | Qmax: 142.1944 | Exploration: 0.085276 | Step: 404 | LR: 0.00150000\n",
      "| Reward: -2418 | Episode: 862 | Qmax: 140.9722 | Exploration: 0.085191 | Step: 601 | LR: 0.00150000\n",
      "| Reward: -4033 | Episode: 863 | Qmax: 139.7688 | Exploration: 0.085191 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2560 | Episode: 864 | Qmax: 138.3595 | Exploration: 0.085105 | Step: 725 | LR: 0.00150000\n",
      "| Reward: -2245 | Episode: 865 | Qmax: 137.3097 | Exploration: 0.085020 | Step: 527 | LR: 0.00150000\n",
      "| Reward: -2588 | Episode: 866 | Qmax: 136.1471 | Exploration: 0.084935 | Step: 573 | LR: 0.00150000\n",
      "| Reward: -3771 | Episode: 867 | Qmax: 135.3004 | Exploration: 0.084850 | Step: 676 | LR: 0.00150000\n",
      "| Reward: -2062 | Episode: 868 | Qmax: 134.3811 | Exploration: 0.084765 | Step: 344 | LR: 0.00150000\n",
      "| Reward: -3034 | Episode: 869 | Qmax: 132.8995 | Exploration: 0.084765 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2911 | Episode: 870 | Qmax: 131.5944 | Exploration: 0.084681 | Step: 779 | LR: 0.00150000\n",
      "| Reward: -2989 | Episode: 871 | Qmax: 130.4823 | Exploration: 0.084596 | Step: 443 | LR: 0.00150000\n",
      "| Reward: -3475 | Episode: 872 | Qmax: 129.3029 | Exploration: 0.084596 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1741 | Episode: 873 | Qmax: 128.1621 | Exploration: 0.084511 | Step: 500 | LR: 0.00150000\n",
      "| Reward: -1581 | Episode: 874 | Qmax: 127.5192 | Exploration: 0.084427 | Step: 403 | LR: 0.00150000\n",
      "| Reward: -2981 | Episode: 875 | Qmax: 126.4046 | Exploration: 0.084342 | Step: 768 | LR: 0.00150000\n",
      "| Reward: -2782 | Episode: 876 | Qmax: 125.0107 | Exploration: 0.084342 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3466 | Episode: 877 | Qmax: 123.6215 | Exploration: 0.084342 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2080 | Episode: 878 | Qmax: 122.5028 | Exploration: 0.084258 | Step: 479 | LR: 0.00150000\n",
      "| Reward: -2296 | Episode: 879 | Qmax: 121.1658 | Exploration: 0.084258 | Step: 999 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2246 | Episode: 880 | Qmax: 119.3951 | Exploration: 0.084174 | Step: 843 | LR: 0.00150000\n",
      "| Reward: -1467 | Episode: 881 | Qmax: 118.7264 | Exploration: 0.084090 | Step: 442 | LR: 0.00150000\n",
      "| Reward: -2980 | Episode: 882 | Qmax: 117.1746 | Exploration: 0.084090 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2287 | Episode: 883 | Qmax: 115.5719 | Exploration: 0.084090 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2010 | Episode: 884 | Qmax: 114.6378 | Exploration: 0.084006 | Step: 598 | LR: 0.00150000\n",
      "| Reward: -2620 | Episode: 885 | Qmax: 113.1291 | Exploration: 0.084006 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2530 | Episode: 886 | Qmax: 111.9061 | Exploration: 0.084006 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3258 | Episode: 887 | Qmax: 110.4397 | Exploration: 0.083922 | Step: 739 | LR: 0.00150000\n",
      "| Reward: -1764 | Episode: 888 | Qmax: 110.0842 | Exploration: 0.083838 | Step: 370 | LR: 0.00150000\n",
      "| Reward: -2450 | Episode: 889 | Qmax: 108.6457 | Exploration: 0.083754 | Step: 741 | LR: 0.00150000\n",
      "| Reward: -3187 | Episode: 890 | Qmax: 107.3094 | Exploration: 0.083754 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3283 | Episode: 891 | Qmax: 106.0348 | Exploration: 0.083670 | Step: 773 | LR: 0.00150000\n",
      "| Reward: -2665 | Episode: 892 | Qmax: 104.8386 | Exploration: 0.083670 | Step: 999 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -2458 | Episode: 893 | Qmax: 103.3454 | Exploration: 0.083670 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2440 | Episode: 894 | Qmax: 102.1525 | Exploration: 0.083670 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2386 | Episode: 895 | Qmax: 101.0344 | Exploration: 0.083670 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2192 | Episode: 896 | Qmax: 100.1327 | Exploration: 0.083586 | Step: 771 | LR: 0.00150000\n",
      "| Reward: -1254 | Episode: 897 | Qmax: 99.6619 | Exploration: 0.083503 | Step: 256 | LR: 0.00150000\n",
      "| Reward: -2197 | Episode: 898 | Qmax: 98.6552 | Exploration: 0.083503 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2269 | Episode: 899 | Qmax: 97.8698 | Exploration: 0.083503 | Step: 999 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2917 | Episode: 900 | Qmax: 96.8789 | Exploration: 0.083503 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2836 | Episode: 901 | Qmax: 96.0803 | Exploration: 0.083503 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1671 | Episode: 902 | Qmax: 95.8946 | Exploration: 0.083419 | Step: 322 | LR: 0.00150000\n",
      "| Reward: -3493 | Episode: 903 | Qmax: 95.8187 | Exploration: 0.083419 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1929 | Episode: 904 | Qmax: 94.9897 | Exploration: 0.083336 | Step: 958 | LR: 0.00150000\n",
      "| Reward: -2503 | Episode: 905 | Qmax: 94.6996 | Exploration: 0.083336 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2053 | Episode: 906 | Qmax: 94.3290 | Exploration: 0.083253 | Step: 596 | LR: 0.00150000\n",
      "| Reward: -1911 | Episode: 907 | Qmax: 94.5253 | Exploration: 0.083169 | Step: 517 | LR: 0.00150000\n",
      "| Reward: -1793 | Episode: 908 | Qmax: 94.5601 | Exploration: 0.083086 | Step: 588 | LR: 0.00150000\n",
      "| Reward: -3439 | Episode: 909 | Qmax: 94.0842 | Exploration: 0.083086 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1835 | Episode: 910 | Qmax: 94.4814 | Exploration: 0.083003 | Step: 315 | LR: 0.00150000\n",
      "| Reward: -2728 | Episode: 911 | Qmax: 94.2690 | Exploration: 0.083003 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2989 | Episode: 913 | Qmax: 94.7992 | Exploration: 0.082920 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3394 | Episode: 914 | Qmax: 94.9369 | Exploration: 0.082920 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1928 | Episode: 915 | Qmax: 95.4686 | Exploration: 0.082837 | Step: 516 | LR: 0.00150000\n",
      "| Reward: -1663 | Episode: 916 | Qmax: 95.2756 | Exploration: 0.082754 | Step: 449 | LR: 0.00150000\n",
      "| Reward: -3700 | Episode: 917 | Qmax: 95.4417 | Exploration: 0.082754 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1619 | Episode: 918 | Qmax: 95.4656 | Exploration: 0.082672 | Step: 450 | LR: 0.00150000\n",
      "| Reward: -3268 | Episode: 919 | Qmax: 95.6716 | Exploration: 0.082672 | Step: 999 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1730 | Episode: 920 | Qmax: 96.3394 | Exploration: 0.082589 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1349 | Episode: 921 | Qmax: 96.1225 | Exploration: 0.082506 | Step: 279 | LR: 0.00150000\n",
      "| Reward: -3109 | Episode: 922 | Qmax: 96.2113 | Exploration: 0.082424 | Step: 995 | LR: 0.00150000\n",
      "| Reward: -1351 | Episode: 923 | Qmax: 96.5683 | Exploration: 0.082341 | Step: 452 | LR: 0.00150000\n",
      "| Reward: -1324 | Episode: 924 | Qmax: 97.1494 | Exploration: 0.082259 | Step: 380 | LR: 0.00150000\n",
      "| Reward: -3583 | Episode: 925 | Qmax: 96.9657 | Exploration: 0.082259 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1706 | Episode: 926 | Qmax: 97.1338 | Exploration: 0.082177 | Step: 474 | LR: 0.00150000\n",
      "| Reward: -1947 | Episode: 927 | Qmax: 97.5716 | Exploration: 0.082095 | Step: 490 | LR: 0.00150000\n",
      "| Reward: -3853 | Episode: 928 | Qmax: 97.3445 | Exploration: 0.082095 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1561 | Episode: 929 | Qmax: 97.7480 | Exploration: 0.082012 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -1713 | Episode: 930 | Qmax: 97.9700 | Exploration: 0.081930 | Step: 301 | LR: 0.00150000\n",
      "| Reward: -2462 | Episode: 931 | Qmax: 97.9281 | Exploration: 0.081849 | Step: 609 | LR: 0.00150000\n",
      "| Reward: -2859 | Episode: 932 | Qmax: 97.5952 | Exploration: 0.081767 | Step: 646 | LR: 0.00150000\n",
      "| Reward: -2807 | Episode: 933 | Qmax: 97.4986 | Exploration: 0.081685 | Step: 756 | LR: 0.00150000\n",
      "| Reward: -2007 | Episode: 934 | Qmax: 97.7819 | Exploration: 0.081603 | Step: 451 | LR: 0.00150000\n",
      "| Reward: -2418 | Episode: 935 | Qmax: 97.5309 | Exploration: 0.081522 | Step: 799 | LR: 0.00150000\n",
      "| Reward: -3763 | Episode: 936 | Qmax: 97.5601 | Exploration: 0.081522 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1471 | Episode: 937 | Qmax: 97.9447 | Exploration: 0.081440 | Step: 347 | LR: 0.00150000\n",
      "| Reward: -2267 | Episode: 938 | Qmax: 97.7081 | Exploration: 0.081359 | Step: 720 | LR: 0.00150000\n",
      "| Reward: -2046 | Episode: 939 | Qmax: 98.1262 | Exploration: 0.081277 | Step: 418 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2854 | Episode: 940 | Qmax: 97.6328 | Exploration: 0.081277 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2403 | Episode: 941 | Qmax: 97.7963 | Exploration: 0.081196 | Step: 838 | LR: 0.00150000\n",
      "| Reward: -3448 | Episode: 942 | Qmax: 97.9590 | Exploration: 0.081196 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3367 | Episode: 943 | Qmax: 97.8127 | Exploration: 0.081196 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3106 | Episode: 944 | Qmax: 97.4414 | Exploration: 0.081196 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3304 | Episode: 945 | Qmax: 97.7216 | Exploration: 0.081196 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2675 | Episode: 946 | Qmax: 98.3576 | Exploration: 0.081115 | Step: 678 | LR: 0.00150000\n",
      "| Reward: -2118 | Episode: 947 | Qmax: 98.5735 | Exploration: 0.081034 | Step: 607 | LR: 0.00150000\n",
      "| Reward: -2630 | Episode: 948 | Qmax: 98.7157 | Exploration: 0.080953 | Step: 480 | LR: 0.00150000\n",
      "| Reward: -3250 | Episode: 949 | Qmax: 98.6753 | Exploration: 0.080953 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1724 | Episode: 950 | Qmax: 99.0484 | Exploration: 0.080872 | Step: 447 | LR: 0.00150000\n",
      "| Reward: -3366 | Episode: 951 | Qmax: 98.8689 | Exploration: 0.080791 | Step: 856 | LR: 0.00150000\n",
      "| Reward: -3349 | Episode: 952 | Qmax: 99.0671 | Exploration: 0.080791 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2024 | Episode: 953 | Qmax: 99.3447 | Exploration: 0.080710 | Step: 522 | LR: 0.00150000\n",
      "| Reward: -3016 | Episode: 954 | Qmax: 98.9580 | Exploration: 0.080710 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1743 | Episode: 955 | Qmax: 98.6936 | Exploration: 0.080629 | Step: 718 | LR: 0.00150000\n",
      "| Reward: -1805 | Episode: 956 | Qmax: 98.9627 | Exploration: 0.080549 | Step: 339 | LR: 0.00150000\n",
      "| Reward: -3214 | Episode: 957 | Qmax: 98.7387 | Exploration: 0.080549 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1658 | Episode: 958 | Qmax: 99.1117 | Exploration: 0.080468 | Step: 588 | LR: 0.00150000\n",
      "| Reward: -2261 | Episode: 959 | Qmax: 99.5934 | Exploration: 0.080388 | Step: 264 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3808 | Episode: 960 | Qmax: 99.1370 | Exploration: 0.080388 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3203 | Episode: 961 | Qmax: 99.0468 | Exploration: 0.080307 | Step: 738 | LR: 0.00150000\n",
      "| Reward: -2557 | Episode: 962 | Qmax: 98.9005 | Exploration: 0.080307 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1184 | Episode: 963 | Qmax: 99.7964 | Exploration: 0.080227 | Step: 150 | LR: 0.00150000\n",
      "| Reward: -2845 | Episode: 964 | Qmax: 99.1125 | Exploration: 0.080147 | Step: 704 | LR: 0.00150000\n",
      "| Reward: -2821 | Episode: 965 | Qmax: 99.2425 | Exploration: 0.080067 | Step: 797 | LR: 0.00150000\n",
      "| Reward: -3068 | Episode: 966 | Qmax: 99.0573 | Exploration: 0.079987 | Step: 720 | LR: 0.00150000\n",
      "| Reward: -3970 | Episode: 967 | Qmax: 98.9353 | Exploration: 0.079987 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1268 | Episode: 968 | Qmax: 99.0065 | Exploration: 0.079907 | Step: 351 | LR: 0.00150000\n",
      "| Reward: -3070 | Episode: 969 | Qmax: 98.7367 | Exploration: 0.079907 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1556 | Episode: 970 | Qmax: 98.4133 | Exploration: 0.079827 | Step: 558 | LR: 0.00150000\n",
      "| Reward: -2640 | Episode: 971 | Qmax: 98.4195 | Exploration: 0.079747 | Step: 823 | LR: 0.00150000\n",
      "| Reward: -1572 | Episode: 972 | Qmax: 98.6619 | Exploration: 0.079667 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -3421 | Episode: 973 | Qmax: 98.1595 | Exploration: 0.079667 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1641 | Episode: 974 | Qmax: 98.0273 | Exploration: 0.079587 | Step: 535 | LR: 0.00150000\n",
      "| Reward: -3250 | Episode: 975 | Qmax: 97.9860 | Exploration: 0.079587 | Step: 999 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -3088 | Episode: 976 | Qmax: 97.8190 | Exploration: 0.079587 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3263 | Episode: 977 | Qmax: 97.8694 | Exploration: 0.079508 | Step: 744 | LR: 0.00150000\n",
      "| Reward: -3306 | Episode: 978 | Qmax: 98.1458 | Exploration: 0.079428 | Step: 985 | LR: 0.00150000\n",
      "| Reward: -3340 | Episode: 979 | Qmax: 98.1404 | Exploration: 0.079428 | Step: 999 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1423 | Episode: 980 | Qmax: 97.7591 | Exploration: 0.079349 | Step: 326 | LR: 0.00150000\n",
      "| Reward: -2904 | Episode: 981 | Qmax: 97.9998 | Exploration: 0.079270 | Step: 772 | LR: 0.00150000\n",
      "| Reward: -2764 | Episode: 982 | Qmax: 97.9575 | Exploration: 0.079270 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2206 | Episode: 983 | Qmax: 98.2791 | Exploration: 0.079270 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2353 | Episode: 984 | Qmax: 98.8606 | Exploration: 0.079190 | Step: 545 | LR: 0.00150000\n",
      "| Reward: -3997 | Episode: 985 | Qmax: 98.5702 | Exploration: 0.079190 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3538 | Episode: 986 | Qmax: 98.7984 | Exploration: 0.079190 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3263 | Episode: 987 | Qmax: 98.4586 | Exploration: 0.079111 | Step: 888 | LR: 0.00150000\n",
      "| Reward: -1292 | Episode: 988 | Qmax: 98.8942 | Exploration: 0.079032 | Step: 312 | LR: 0.00150000\n",
      "| Reward: -1934 | Episode: 989 | Qmax: 98.8337 | Exploration: 0.078953 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1433 | Episode: 990 | Qmax: 98.3869 | Exploration: 0.078874 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -1379 | Episode: 991 | Qmax: 98.5657 | Exploration: 0.078795 | Step: 300 | LR: 0.00150000\n",
      "| Reward: -3412 | Episode: 992 | Qmax: 98.4256 | Exploration: 0.078795 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2949 | Episode: 993 | Qmax: 98.5702 | Exploration: 0.078716 | Step: 844 | LR: 0.00150000\n",
      "| Reward: -2899 | Episode: 994 | Qmax: 98.6214 | Exploration: 0.078716 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2881 | Episode: 995 | Qmax: 98.0572 | Exploration: 0.078716 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1423 | Episode: 996 | Qmax: 98.0867 | Exploration: 0.078638 | Step: 263 | LR: 0.00150000\n",
      "| Reward: -2386 | Episode: 997 | Qmax: 97.9046 | Exploration: 0.078638 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3070 | Episode: 998 | Qmax: 97.9970 | Exploration: 0.078559 | Step: 857 | LR: 0.00150000\n",
      "| Reward: -1986 | Episode: 999 | Qmax: 98.3140 | Exploration: 0.078480 | Step: 295 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -4906 | Episode: 1000 | Qmax: 97.8705 | Exploration: 0.078480 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1912 | Episode: 1001 | Qmax: 97.9269 | Exploration: 0.078402 | Step: 653 | LR: 0.00150000\n",
      "| Reward: -1579 | Episode: 1002 | Qmax: 97.8777 | Exploration: 0.078324 | Step: 356 | LR: 0.00150000\n",
      "| Reward: -2493 | Episode: 1003 | Qmax: 97.6455 | Exploration: 0.078245 | Step: 793 | LR: 0.00150000\n",
      "| Reward: -2361 | Episode: 1004 | Qmax: 97.8563 | Exploration: 0.078167 | Step: 733 | LR: 0.00150000\n",
      "| Reward: -2841 | Episode: 1005 | Qmax: 97.9424 | Exploration: 0.078089 | Step: 448 | LR: 0.00150000\n",
      "| Reward: -4528 | Episode: 1006 | Qmax: 97.8681 | Exploration: 0.078089 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3466 | Episode: 1007 | Qmax: 97.7495 | Exploration: 0.078089 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2971 | Episode: 1008 | Qmax: 97.5844 | Exploration: 0.078089 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3439 | Episode: 1009 | Qmax: 97.4142 | Exploration: 0.078089 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2136 | Episode: 1010 | Qmax: 97.5302 | Exploration: 0.078011 | Step: 616 | LR: 0.00150000\n",
      "| Reward: -3016 | Episode: 1011 | Qmax: 97.6718 | Exploration: 0.078011 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1491 | Episode: 1012 | Qmax: 98.1172 | Exploration: 0.077933 | Step: 376 | LR: 0.00150000\n",
      "| Reward: -2305 | Episode: 1013 | Qmax: 97.8200 | Exploration: 0.077933 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1401 | Episode: 1014 | Qmax: 97.9985 | Exploration: 0.077855 | Step: 358 | LR: 0.00150000\n",
      "| Reward: -3133 | Episode: 1015 | Qmax: 98.0790 | Exploration: 0.077855 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3010 | Episode: 1016 | Qmax: 97.8973 | Exploration: 0.077777 | Step: 941 | LR: 0.00150000\n",
      "| Reward: -1774 | Episode: 1017 | Qmax: 98.3748 | Exploration: 0.077699 | Step: 299 | LR: 0.00150000\n",
      "| Reward: -2120 | Episode: 1018 | Qmax: 97.7546 | Exploration: 0.077621 | Step: 888 | LR: 0.00150000\n",
      "| Reward: -1244 | Episode: 1019 | Qmax: 98.3915 | Exploration: 0.077544 | Step: 237 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3268 | Episode: 1020 | Qmax: 97.6604 | Exploration: 0.077544 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2899 | Episode: 1021 | Qmax: 97.7420 | Exploration: 0.077544 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3222 | Episode: 1022 | Qmax: 97.4582 | Exploration: 0.077466 | Step: 991 | LR: 0.00150000\n",
      "| Reward: -3133 | Episode: 1023 | Qmax: 97.0963 | Exploration: 0.077466 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1546 | Episode: 1024 | Qmax: 97.1794 | Exploration: 0.077389 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -2710 | Episode: 1025 | Qmax: 97.2585 | Exploration: 0.077389 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1276 | Episode: 1026 | Qmax: 97.2739 | Exploration: 0.077311 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1194 | Episode: 1027 | Qmax: 97.6999 | Exploration: 0.077234 | Step: 160 | LR: 0.00150000\n",
      "| Reward: -1987 | Episode: 1028 | Qmax: 97.0067 | Exploration: 0.077157 | Step: 386 | LR: 0.00150000\n",
      "| Reward: -3206 | Episode: 1029 | Qmax: 97.2976 | Exploration: 0.077080 | Step: 597 | LR: 0.00150000\n",
      "| Reward: -2973 | Episode: 1030 | Qmax: 96.8800 | Exploration: 0.077003 | Step: 967 | LR: 0.00150000\n",
      "| Reward: -2647 | Episode: 1031 | Qmax: 96.6537 | Exploration: 0.077003 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2343 | Episode: 1032 | Qmax: 96.7263 | Exploration: 0.076926 | Step: 571 | LR: 0.00150000\n",
      "| Reward: -3691 | Episode: 1033 | Qmax: 96.8631 | Exploration: 0.076926 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1631 | Episode: 1034 | Qmax: 97.2139 | Exploration: 0.076849 | Step: 363 | LR: 0.00150000\n",
      "| Reward: -3376 | Episode: 1035 | Qmax: 96.5091 | Exploration: 0.076849 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -4060 | Episode: 1036 | Qmax: 96.4162 | Exploration: 0.076849 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2782 | Episode: 1037 | Qmax: 96.7913 | Exploration: 0.076849 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2612 | Episode: 1038 | Qmax: 96.9397 | Exploration: 0.076772 | Step: 498 | LR: 0.00150000\n",
      "| Reward: -2422 | Episode: 1039 | Qmax: 97.1406 | Exploration: 0.076772 | Step: 999 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1609 | Episode: 1040 | Qmax: 97.2518 | Exploration: 0.076695 | Step: 521 | LR: 0.00150000\n",
      "| Reward: -2522 | Episode: 1041 | Qmax: 97.2672 | Exploration: 0.076618 | Step: 516 | LR: 0.00150000\n",
      "| Reward: -1388 | Episode: 1042 | Qmax: 97.1480 | Exploration: 0.076542 | Step: 408 | LR: 0.00150000\n",
      "| Reward: -1876 | Episode: 1043 | Qmax: 96.9664 | Exploration: 0.076465 | Step: 302 | LR: 0.00150000\n",
      "| Reward: -2350 | Episode: 1044 | Qmax: 97.0244 | Exploration: 0.076465 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -3232 | Episode: 1045 | Qmax: 97.1742 | Exploration: 0.076465 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2674 | Episode: 1046 | Qmax: 97.3420 | Exploration: 0.076465 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1715 | Episode: 1047 | Qmax: 97.2831 | Exploration: 0.076389 | Step: 591 | LR: 0.00150000\n",
      "| Reward: -1490 | Episode: 1048 | Qmax: 97.1550 | Exploration: 0.076312 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -1509 | Episode: 1049 | Qmax: 97.7814 | Exploration: 0.076236 | Step: 160 | LR: 0.00150000\n",
      "| Reward: -2899 | Episode: 1050 | Qmax: 97.3154 | Exploration: 0.076236 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -2188 | Episode: 1051 | Qmax: 97.5596 | Exploration: 0.076160 | Step: 596 | LR: 0.00150000\n",
      "| Reward: -2974 | Episode: 1052 | Qmax: 97.1443 | Exploration: 0.076084 | Step: 563 | LR: 0.00150000\n",
      "| Reward: -1243 | Episode: 1053 | Qmax: 97.3778 | Exploration: 0.076008 | Step: 533 | LR: 0.00150000\n",
      "| Reward: -2954 | Episode: 1054 | Qmax: 97.4939 | Exploration: 0.075932 | Step: 660 | LR: 0.00150000\n",
      "| Reward: -975 | Episode: 1055 | Qmax: 97.8781 | Exploration: 0.075856 | Step: 310 | LR: 0.00150000\n",
      "| Reward: -2438 | Episode: 1056 | Qmax: 97.5084 | Exploration: 0.075780 | Step: 900 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1175 | Episode: 1057 | Qmax: 98.6424 | Exploration: 0.075704 | Step: 132 | LR: 0.00150000\n",
      "| Reward: -2127 | Episode: 1058 | Qmax: 97.3745 | Exploration: 0.075628 | Step: 436 | LR: 0.00150000\n",
      "| Reward: -2142 | Episode: 1059 | Qmax: 97.3615 | Exploration: 0.075553 | Step: 586 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -3637 | Episode: 1060 | Qmax: 97.3785 | Exploration: 0.075553 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1867 | Episode: 1061 | Qmax: 97.9289 | Exploration: 0.075477 | Step: 446 | LR: 0.00150000\n",
      "| Reward: -2278 | Episode: 1062 | Qmax: 97.6914 | Exploration: 0.075402 | Step: 947 | LR: 0.00150000\n",
      "| Reward: -1033 | Episode: 1063 | Qmax: 98.8213 | Exploration: 0.075326 | Step: 161 | LR: 0.00150000\n",
      "| Reward: -3367 | Episode: 1064 | Qmax: 98.3308 | Exploration: 0.075326 | Step: 999 | LR: 0.00150000\n",
      "| Reward: -1159 | Episode: 1065 | Qmax: 97.6620 | Exploration: 0.075251 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1425 | Episode: 1066 | Qmax: 98.3461 | Exploration: 0.075176 | Step: 274 | LR: 0.00150000\n",
      "| Reward: -1429 | Episode: 1067 | Qmax: 97.7564 | Exploration: 0.075101 | Step: 710 | LR: 0.00150000\n",
      "| Reward: -1558 | Episode: 1068 | Qmax: 97.1834 | Exploration: 0.075025 | Step: 587 | LR: 0.00150000\n",
      "| Reward: -1234 | Episode: 1069 | Qmax: 97.3036 | Exploration: 0.074950 | Step: 290 | LR: 0.00150000\n",
      "| Reward: -1341 | Episode: 1070 | Qmax: 97.1929 | Exploration: 0.074875 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1383 | Episode: 1071 | Qmax: 97.3877 | Exploration: 0.074801 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -939 | Episode: 1072 | Qmax: 97.4806 | Exploration: 0.074726 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1694 | Episode: 1073 | Qmax: 97.1263 | Exploration: 0.074651 | Step: 435 | LR: 0.00150000\n",
      "| Reward: -1589 | Episode: 1074 | Qmax: 97.0559 | Exploration: 0.074576 | Step: 330 | LR: 0.00150000\n",
      "| Reward: -1713 | Episode: 1075 | Qmax: 97.2223 | Exploration: 0.074502 | Step: 481 | LR: 0.00150000\n",
      "| Reward: -1434 | Episode: 1076 | Qmax: 97.5098 | Exploration: 0.074427 | Step: 364 | LR: 0.00150000\n",
      "| Reward: -1501 | Episode: 1077 | Qmax: 97.5053 | Exploration: 0.074353 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1158 | Episode: 1078 | Qmax: 97.8839 | Exploration: 0.074279 | Step: 169 | LR: 0.00150000\n",
      "| Reward: -1359 | Episode: 1079 | Qmax: 97.5662 | Exploration: 0.074204 | Step: 172 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2660 | Episode: 1080 | Qmax: 97.3345 | Exploration: 0.074130 | Step: 483 | LR: 0.00150000\n",
      "| Reward: -2828 | Episode: 1081 | Qmax: 97.1719 | Exploration: 0.074056 | Step: 777 | LR: 0.00150000\n",
      "| Reward: -2380 | Episode: 1082 | Qmax: 97.5035 | Exploration: 0.073982 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -1411 | Episode: 1083 | Qmax: 97.6470 | Exploration: 0.073908 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -1139 | Episode: 1084 | Qmax: 97.8428 | Exploration: 0.073834 | Step: 150 | LR: 0.00150000\n",
      "| Reward: -1203 | Episode: 1085 | Qmax: 98.0330 | Exploration: 0.073760 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -1003 | Episode: 1086 | Qmax: 97.1883 | Exploration: 0.073686 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -1290 | Episode: 1087 | Qmax: 97.6954 | Exploration: 0.073613 | Step: 202 | LR: 0.00150000\n",
      "| Reward: -1081 | Episode: 1088 | Qmax: 97.8289 | Exploration: 0.073539 | Step: 335 | LR: 0.00150000\n",
      "| Reward: -1075 | Episode: 1089 | Qmax: 97.4127 | Exploration: 0.073466 | Step: 320 | LR: 0.00150000\n",
      "| Reward: -1545 | Episode: 1090 | Qmax: 97.7154 | Exploration: 0.073392 | Step: 475 | LR: 0.00150000\n",
      "| Reward: -1448 | Episode: 1091 | Qmax: 98.0306 | Exploration: 0.073319 | Step: 369 | LR: 0.00150000\n",
      "| Reward: -1794 | Episode: 1092 | Qmax: 97.5779 | Exploration: 0.073245 | Step: 373 | LR: 0.00150000\n",
      "| Reward: -1130 | Episode: 1093 | Qmax: 97.4030 | Exploration: 0.073172 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1091 | Episode: 1094 | Qmax: 97.4885 | Exploration: 0.073099 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -1189 | Episode: 1095 | Qmax: 97.8664 | Exploration: 0.073026 | Step: 335 | LR: 0.00150000\n",
      "| Reward: -1098 | Episode: 1096 | Qmax: 97.4695 | Exploration: 0.072953 | Step: 154 | LR: 0.00150000\n",
      "| Reward: -1059 | Episode: 1097 | Qmax: 98.0470 | Exploration: 0.072880 | Step: 196 | LR: 0.00150000\n",
      "| Reward: -1317 | Episode: 1098 | Qmax: 97.1579 | Exploration: 0.072807 | Step: 274 | LR: 0.00150000\n",
      "| Reward: -1220 | Episode: 1099 | Qmax: 97.5663 | Exploration: 0.072734 | Step: 357 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1507 | Episode: 1100 | Qmax: 97.6059 | Exploration: 0.072661 | Step: 221 | LR: 0.00150000\n",
      "| Reward: -1192 | Episode: 1101 | Qmax: 96.9741 | Exploration: 0.072589 | Step: 284 | LR: 0.00150000\n",
      "| Reward: -1647 | Episode: 1102 | Qmax: 97.1537 | Exploration: 0.072516 | Step: 262 | LR: 0.00150000\n",
      "| Reward: -1122 | Episode: 1103 | Qmax: 96.8860 | Exploration: 0.072444 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -1005 | Episode: 1104 | Qmax: 97.9622 | Exploration: 0.072371 | Step: 169 | LR: 0.00150000\n",
      "| Reward: -1586 | Episode: 1105 | Qmax: 97.6670 | Exploration: 0.072299 | Step: 255 | LR: 0.00150000\n",
      "| Reward: -1217 | Episode: 1106 | Qmax: 97.8827 | Exploration: 0.072227 | Step: 165 | LR: 0.00150000\n",
      "| Reward: -1281 | Episode: 1107 | Qmax: 97.3795 | Exploration: 0.072154 | Step: 247 | LR: 0.00150000\n",
      "| Reward: -934 | Episode: 1108 | Qmax: 97.4117 | Exploration: 0.072082 | Step: 197 | LR: 0.00150000\n",
      "| Reward: -2027 | Episode: 1109 | Qmax: 97.2060 | Exploration: 0.072010 | Step: 192 | LR: 0.00150000\n",
      "| Reward: -1230 | Episode: 1110 | Qmax: 97.3344 | Exploration: 0.071938 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -1091 | Episode: 1111 | Qmax: 97.8539 | Exploration: 0.071866 | Step: 237 | LR: 0.00150000\n",
      "| Reward: -854 | Episode: 1112 | Qmax: 97.1405 | Exploration: 0.071794 | Step: 162 | LR: 0.00150000\n",
      "| Reward: -1942 | Episode: 1113 | Qmax: 97.7503 | Exploration: 0.071723 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1227 | Episode: 1114 | Qmax: 97.6440 | Exploration: 0.071651 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -1379 | Episode: 1115 | Qmax: 97.4688 | Exploration: 0.071579 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -1119 | Episode: 1116 | Qmax: 97.7694 | Exploration: 0.071508 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -685 | Episode: 1117 | Qmax: 98.2550 | Exploration: 0.071436 | Step: 146 | LR: 0.00150000\n",
      "| Reward: -1032 | Episode: 1118 | Qmax: 97.2507 | Exploration: 0.071365 | Step: 169 | LR: 0.00150000\n",
      "| Reward: -1037 | Episode: 1119 | Qmax: 98.2584 | Exploration: 0.071293 | Step: 183 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1414 | Episode: 1120 | Qmax: 98.1325 | Exploration: 0.071222 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -764 | Episode: 1121 | Qmax: 97.8865 | Exploration: 0.071151 | Step: 189 | LR: 0.00150000\n",
      "| Reward: -1478 | Episode: 1122 | Qmax: 97.7008 | Exploration: 0.071080 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -1103 | Episode: 1123 | Qmax: 97.7602 | Exploration: 0.071008 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -1093 | Episode: 1124 | Qmax: 97.7248 | Exploration: 0.070937 | Step: 284 | LR: 0.00150000\n",
      "| Reward: -1408 | Episode: 1125 | Qmax: 98.2484 | Exploration: 0.070867 | Step: 158 | LR: 0.00150000\n",
      "| Reward: -1266 | Episode: 1126 | Qmax: 97.8176 | Exploration: 0.070796 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -1388 | Episode: 1127 | Qmax: 97.8198 | Exploration: 0.070725 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -1035 | Episode: 1128 | Qmax: 98.2491 | Exploration: 0.070654 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1217 | Episode: 1129 | Qmax: 98.2116 | Exploration: 0.070584 | Step: 156 | LR: 0.00150000\n",
      "| Reward: -1091 | Episode: 1130 | Qmax: 97.8309 | Exploration: 0.070513 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -1090 | Episode: 1131 | Qmax: 98.0820 | Exploration: 0.070442 | Step: 227 | LR: 0.00150000\n",
      "| Reward: -1441 | Episode: 1132 | Qmax: 97.8790 | Exploration: 0.070372 | Step: 164 | LR: 0.00150000\n",
      "| Reward: -1289 | Episode: 1133 | Qmax: 97.5456 | Exploration: 0.070302 | Step: 219 | LR: 0.00150000\n",
      "| Reward: -1533 | Episode: 1134 | Qmax: 97.5927 | Exploration: 0.070231 | Step: 166 | LR: 0.00150000\n",
      "| Reward: -1473 | Episode: 1135 | Qmax: 97.4638 | Exploration: 0.070161 | Step: 187 | LR: 0.00150000\n",
      "| Reward: -797 | Episode: 1136 | Qmax: 97.7627 | Exploration: 0.070091 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -1433 | Episode: 1137 | Qmax: 97.4772 | Exploration: 0.070021 | Step: 273 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1107 | Episode: 1138 | Qmax: 97.9728 | Exploration: 0.069951 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -1009 | Episode: 1139 | Qmax: 98.0147 | Exploration: 0.069881 | Step: 137 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -824 | Episode: 1140 | Qmax: 97.9835 | Exploration: 0.069811 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -1174 | Episode: 1141 | Qmax: 97.8387 | Exploration: 0.069741 | Step: 185 | LR: 0.00150000\n",
      "| Reward: -947 | Episode: 1142 | Qmax: 97.7465 | Exploration: 0.069671 | Step: 138 | LR: 0.00150000\n",
      "| Reward: -944 | Episode: 1143 | Qmax: 98.7342 | Exploration: 0.069602 | Step: 144 | LR: 0.00150000\n",
      "| Reward: -1460 | Episode: 1144 | Qmax: 98.1558 | Exploration: 0.069532 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -1290 | Episode: 1145 | Qmax: 97.8357 | Exploration: 0.069463 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1230 | Episode: 1146 | Qmax: 97.8234 | Exploration: 0.069393 | Step: 277 | LR: 0.00150000\n",
      "| Reward: -1101 | Episode: 1147 | Qmax: 97.7086 | Exploration: 0.069324 | Step: 202 | LR: 0.00150000\n",
      "| Reward: -1067 | Episode: 1148 | Qmax: 97.8107 | Exploration: 0.069254 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1480 | Episode: 1149 | Qmax: 98.1705 | Exploration: 0.069185 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -1157 | Episode: 1150 | Qmax: 97.7719 | Exploration: 0.069116 | Step: 204 | LR: 0.00150000\n",
      "| Reward: -1310 | Episode: 1151 | Qmax: 98.2795 | Exploration: 0.069047 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -1273 | Episode: 1152 | Qmax: 97.9784 | Exploration: 0.068978 | Step: 158 | LR: 0.00150000\n",
      "| Reward: -1040 | Episode: 1153 | Qmax: 97.4427 | Exploration: 0.068909 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -882 | Episode: 1154 | Qmax: 97.9793 | Exploration: 0.068840 | Step: 181 | LR: 0.00150000\n",
      "| Reward: -1414 | Episode: 1155 | Qmax: 97.9184 | Exploration: 0.068771 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -1445 | Episode: 1156 | Qmax: 98.1577 | Exploration: 0.068702 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -1400 | Episode: 1157 | Qmax: 97.5021 | Exploration: 0.068634 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -1381 | Episode: 1158 | Qmax: 98.1724 | Exploration: 0.068565 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -1339 | Episode: 1159 | Qmax: 97.9565 | Exploration: 0.068496 | Step: 197 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1291 | Episode: 1160 | Qmax: 98.2883 | Exploration: 0.068428 | Step: 185 | LR: 0.00150000\n",
      "| Reward: -1008 | Episode: 1161 | Qmax: 97.6050 | Exploration: 0.068359 | Step: 172 | LR: 0.00150000\n",
      "| Reward: -1030 | Episode: 1162 | Qmax: 98.1467 | Exploration: 0.068291 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -1326 | Episode: 1163 | Qmax: 97.0955 | Exploration: 0.068223 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1080 | Episode: 1164 | Qmax: 98.2528 | Exploration: 0.068155 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -1116 | Episode: 1165 | Qmax: 97.5223 | Exploration: 0.068086 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -928 | Episode: 1166 | Qmax: 97.4602 | Exploration: 0.068018 | Step: 173 | LR: 0.00150000\n",
      "| Reward: -1065 | Episode: 1167 | Qmax: 97.6176 | Exploration: 0.067950 | Step: 166 | LR: 0.00150000\n",
      "| Reward: -1256 | Episode: 1168 | Qmax: 98.1776 | Exploration: 0.067882 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1066 | Episode: 1169 | Qmax: 97.8112 | Exploration: 0.067815 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -1173 | Episode: 1170 | Qmax: 97.5381 | Exploration: 0.067747 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -817 | Episode: 1171 | Qmax: 98.1106 | Exploration: 0.067679 | Step: 152 | LR: 0.00150000\n",
      "| Reward: -803 | Episode: 1172 | Qmax: 98.2026 | Exploration: 0.067611 | Step: 156 | LR: 0.00150000\n",
      "| Reward: -1505 | Episode: 1173 | Qmax: 97.4474 | Exploration: 0.067544 | Step: 291 | LR: 0.00150000\n",
      "| Reward: -794 | Episode: 1174 | Qmax: 98.0264 | Exploration: 0.067476 | Step: 147 | LR: 0.00150000\n",
      "| Reward: -1205 | Episode: 1175 | Qmax: 98.0652 | Exploration: 0.067409 | Step: 225 | LR: 0.00150000\n",
      "| Reward: -1176 | Episode: 1176 | Qmax: 97.6920 | Exploration: 0.067341 | Step: 151 | LR: 0.00150000\n",
      "| Reward: -1000 | Episode: 1177 | Qmax: 98.2750 | Exploration: 0.067274 | Step: 164 | LR: 0.00150000\n",
      "| Reward: -1282 | Episode: 1178 | Qmax: 98.0543 | Exploration: 0.067207 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -1919 | Episode: 1179 | Qmax: 98.1803 | Exploration: 0.067139 | Step: 174 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -928 | Episode: 1180 | Qmax: 97.8353 | Exploration: 0.067072 | Step: 164 | LR: 0.00150000\n",
      "| Reward: -1352 | Episode: 1181 | Qmax: 97.9479 | Exploration: 0.067005 | Step: 165 | LR: 0.00150000\n",
      "| Reward: -1536 | Episode: 1182 | Qmax: 98.1585 | Exploration: 0.066938 | Step: 196 | LR: 0.00150000\n",
      "| Reward: -831 | Episode: 1183 | Qmax: 98.2428 | Exploration: 0.066871 | Step: 157 | LR: 0.00150000\n",
      "| Reward: -1912 | Episode: 1184 | Qmax: 97.5421 | Exploration: 0.066804 | Step: 257 | LR: 0.00150000\n",
      "| Reward: -1086 | Episode: 1185 | Qmax: 97.4782 | Exploration: 0.066738 | Step: 205 | LR: 0.00150000\n",
      "| Reward: -1111 | Episode: 1186 | Qmax: 97.7355 | Exploration: 0.066671 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -1201 | Episode: 1187 | Qmax: 97.6584 | Exploration: 0.066604 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -1051 | Episode: 1188 | Qmax: 97.0472 | Exploration: 0.066538 | Step: 161 | LR: 0.00150000\n",
      "| Reward: -1107 | Episode: 1189 | Qmax: 96.6593 | Exploration: 0.066471 | Step: 226 | LR: 0.00150000\n",
      "| Reward: -1140 | Episode: 1190 | Qmax: 97.4418 | Exploration: 0.066405 | Step: 232 | LR: 0.00150000\n",
      "| Reward: -1102 | Episode: 1191 | Qmax: 97.4557 | Exploration: 0.066338 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -923 | Episode: 1192 | Qmax: 97.2821 | Exploration: 0.066272 | Step: 123 | LR: 0.00150000\n",
      "| Reward: -1375 | Episode: 1193 | Qmax: 97.0819 | Exploration: 0.066206 | Step: 197 | LR: 0.00150000\n",
      "| Reward: -808 | Episode: 1194 | Qmax: 97.5432 | Exploration: 0.066139 | Step: 134 | LR: 0.00150000\n",
      "| Reward: -1088 | Episode: 1195 | Qmax: 97.4574 | Exploration: 0.066073 | Step: 162 | LR: 0.00150000\n",
      "| Reward: -1468 | Episode: 1196 | Qmax: 97.3994 | Exploration: 0.066007 | Step: 227 | LR: 0.00150000\n",
      "| Reward: -1083 | Episode: 1197 | Qmax: 98.1355 | Exploration: 0.065941 | Step: 166 | LR: 0.00150000\n",
      "| Reward: -1124 | Episode: 1198 | Qmax: 97.6223 | Exploration: 0.065875 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -998 | Episode: 1199 | Qmax: 97.0058 | Exploration: 0.065809 | Step: 189 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1163 | Episode: 1200 | Qmax: 96.8427 | Exploration: 0.065744 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -1346 | Episode: 1201 | Qmax: 97.4538 | Exploration: 0.065678 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -1159 | Episode: 1202 | Qmax: 97.8282 | Exploration: 0.065612 | Step: 197 | LR: 0.00150000\n",
      "| Reward: -1063 | Episode: 1203 | Qmax: 97.6509 | Exploration: 0.065546 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -1586 | Episode: 1204 | Qmax: 97.2112 | Exploration: 0.065481 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -1178 | Episode: 1205 | Qmax: 97.2883 | Exploration: 0.065415 | Step: 162 | LR: 0.00150000\n",
      "| Reward: -967 | Episode: 1206 | Qmax: 97.4227 | Exploration: 0.065350 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -1204 | Episode: 1207 | Qmax: 98.0694 | Exploration: 0.065285 | Step: 224 | LR: 0.00150000\n",
      "| Reward: -872 | Episode: 1208 | Qmax: 97.4960 | Exploration: 0.065219 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -1030 | Episode: 1209 | Qmax: 98.1253 | Exploration: 0.065154 | Step: 185 | LR: 0.00150000\n",
      "| Reward: -1624 | Episode: 1210 | Qmax: 97.6441 | Exploration: 0.065089 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -1262 | Episode: 1211 | Qmax: 97.9343 | Exploration: 0.065024 | Step: 156 | LR: 0.00150000\n",
      "| Reward: -1026 | Episode: 1212 | Qmax: 97.8668 | Exploration: 0.064959 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -1364 | Episode: 1213 | Qmax: 97.5663 | Exploration: 0.064894 | Step: 240 | LR: 0.00150000\n",
      "| Reward: -1142 | Episode: 1214 | Qmax: 98.1047 | Exploration: 0.064829 | Step: 162 | LR: 0.00150000\n",
      "| Reward: -1393 | Episode: 1215 | Qmax: 97.9606 | Exploration: 0.064764 | Step: 152 | LR: 0.00150000\n",
      "| Reward: -1083 | Episode: 1216 | Qmax: 97.4962 | Exploration: 0.064699 | Step: 265 | LR: 0.00150000\n",
      "| Reward: -1272 | Episode: 1217 | Qmax: 97.1680 | Exploration: 0.064635 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1009 | Episode: 1218 | Qmax: 97.8606 | Exploration: 0.064570 | Step: 173 | LR: 0.00150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1286 | Episode: 1219 | Qmax: 98.2115 | Exploration: 0.064506 | Step: 198 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1126 | Episode: 1220 | Qmax: 98.1759 | Exploration: 0.064441 | Step: 182 | LR: 0.00150000\n",
      "| Reward: -1159 | Episode: 1221 | Qmax: 98.2865 | Exploration: 0.064377 | Step: 152 | LR: 0.00150000\n",
      "| Reward: -890 | Episode: 1222 | Qmax: 98.3582 | Exploration: 0.064312 | Step: 144 | LR: 0.00150000\n",
      "| Reward: -1452 | Episode: 1223 | Qmax: 97.7569 | Exploration: 0.064248 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -909 | Episode: 1224 | Qmax: 97.8394 | Exploration: 0.064184 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1171 | Episode: 1225 | Qmax: 97.9734 | Exploration: 0.064119 | Step: 191 | LR: 0.00150000\n",
      "| Reward: -1264 | Episode: 1226 | Qmax: 97.4974 | Exploration: 0.064055 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -1372 | Episode: 1227 | Qmax: 97.4867 | Exploration: 0.063991 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -745 | Episode: 1228 | Qmax: 97.3265 | Exploration: 0.063927 | Step: 143 | LR: 0.00150000\n",
      "| Reward: -1269 | Episode: 1229 | Qmax: 97.2996 | Exploration: 0.063863 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -1436 | Episode: 1230 | Qmax: 97.5395 | Exploration: 0.063800 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -1362 | Episode: 1231 | Qmax: 97.3425 | Exploration: 0.063736 | Step: 211 | LR: 0.00150000\n",
      "| Reward: -1536 | Episode: 1232 | Qmax: 97.3525 | Exploration: 0.063672 | Step: 268 | LR: 0.00150000\n",
      "| Reward: -998 | Episode: 1233 | Qmax: 97.2608 | Exploration: 0.063608 | Step: 180 | LR: 0.00150000\n",
      "| Reward: -790 | Episode: 1234 | Qmax: 97.5188 | Exploration: 0.063545 | Step: 170 | LR: 0.00150000\n",
      "| Reward: -1211 | Episode: 1235 | Qmax: 97.3826 | Exploration: 0.063481 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -1144 | Episode: 1236 | Qmax: 97.5226 | Exploration: 0.063418 | Step: 164 | LR: 0.00150000\n",
      "| Reward: -1045 | Episode: 1237 | Qmax: 97.1585 | Exploration: 0.063354 | Step: 164 | LR: 0.00150000\n",
      "| Reward: -763 | Episode: 1238 | Qmax: 97.5379 | Exploration: 0.063291 | Step: 161 | LR: 0.00150000\n",
      "| Reward: -828 | Episode: 1239 | Qmax: 97.2964 | Exploration: 0.063228 | Step: 145 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1381 | Episode: 1240 | Qmax: 97.5039 | Exploration: 0.063164 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -1072 | Episode: 1241 | Qmax: 97.5864 | Exploration: 0.063101 | Step: 173 | LR: 0.00150000\n",
      "| Reward: -1032 | Episode: 1242 | Qmax: 97.6353 | Exploration: 0.063038 | Step: 178 | LR: 0.00150000\n",
      "| Reward: -1096 | Episode: 1243 | Qmax: 97.1165 | Exploration: 0.062975 | Step: 170 | LR: 0.00150000\n",
      "| Reward: -1260 | Episode: 1244 | Qmax: 97.2127 | Exploration: 0.062912 | Step: 199 | LR: 0.00150000\n",
      "| Reward: -825 | Episode: 1245 | Qmax: 96.8437 | Exploration: 0.062849 | Step: 169 | LR: 0.00150000\n",
      "| Reward: -1044 | Episode: 1246 | Qmax: 96.9444 | Exploration: 0.062786 | Step: 154 | LR: 0.00150000\n",
      "| Reward: -1264 | Episode: 1247 | Qmax: 97.0228 | Exploration: 0.062724 | Step: 185 | LR: 0.00150000\n",
      "| Reward: -868 | Episode: 1248 | Qmax: 96.6611 | Exploration: 0.062661 | Step: 167 | LR: 0.00150000\n",
      "| Reward: -1139 | Episode: 1249 | Qmax: 97.5446 | Exploration: 0.062598 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -1245 | Episode: 1250 | Qmax: 97.2614 | Exploration: 0.062536 | Step: 166 | LR: 0.00150000\n",
      "| Reward: -1228 | Episode: 1251 | Qmax: 97.2584 | Exploration: 0.062473 | Step: 167 | LR: 0.00150000\n",
      "| Reward: -1029 | Episode: 1252 | Qmax: 97.5643 | Exploration: 0.062411 | Step: 229 | LR: 0.00150000\n",
      "| Reward: -1250 | Episode: 1253 | Qmax: 97.4626 | Exploration: 0.062348 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -931 | Episode: 1254 | Qmax: 97.4726 | Exploration: 0.062286 | Step: 194 | LR: 0.00150000\n",
      "| Reward: -1258 | Episode: 1255 | Qmax: 96.9648 | Exploration: 0.062224 | Step: 242 | LR: 0.00150000\n",
      "| Reward: -1017 | Episode: 1256 | Qmax: 96.6899 | Exploration: 0.062161 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1444 | Episode: 1257 | Qmax: 97.1402 | Exploration: 0.062099 | Step: 212 | LR: 0.00150000\n",
      "| Reward: -1073 | Episode: 1258 | Qmax: 96.7151 | Exploration: 0.062037 | Step: 165 | LR: 0.00150000\n",
      "| Reward: -933 | Episode: 1259 | Qmax: 97.2597 | Exploration: 0.061975 | Step: 286 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -794 | Episode: 1260 | Qmax: 97.9065 | Exploration: 0.061913 | Step: 174 | LR: 0.00150000\n",
      "| Reward: -1368 | Episode: 1261 | Qmax: 97.4413 | Exploration: 0.061851 | Step: 181 | LR: 0.00150000\n",
      "| Reward: -1502 | Episode: 1262 | Qmax: 97.0410 | Exploration: 0.061789 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -1079 | Episode: 1263 | Qmax: 97.3905 | Exploration: 0.061727 | Step: 135 | LR: 0.00150000\n",
      "| Reward: -1120 | Episode: 1264 | Qmax: 97.2667 | Exploration: 0.061666 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -1224 | Episode: 1265 | Qmax: 97.3428 | Exploration: 0.061604 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -829 | Episode: 1266 | Qmax: 97.5313 | Exploration: 0.061542 | Step: 209 | LR: 0.00150000\n",
      "| Reward: -1418 | Episode: 1267 | Qmax: 97.5728 | Exploration: 0.061481 | Step: 231 | LR: 0.00150000\n",
      "| Reward: -1171 | Episode: 1268 | Qmax: 97.1177 | Exploration: 0.061419 | Step: 272 | LR: 0.00150000\n",
      "| Reward: -1443 | Episode: 1269 | Qmax: 97.0768 | Exploration: 0.061358 | Step: 283 | LR: 0.00150000\n",
      "| Reward: -998 | Episode: 1270 | Qmax: 97.3996 | Exploration: 0.061297 | Step: 189 | LR: 0.00150000\n",
      "| Reward: -1480 | Episode: 1271 | Qmax: 97.1078 | Exploration: 0.061235 | Step: 230 | LR: 0.00150000\n",
      "| Reward: -1217 | Episode: 1272 | Qmax: 96.9607 | Exploration: 0.061174 | Step: 156 | LR: 0.00150000\n",
      "| Reward: -1398 | Episode: 1273 | Qmax: 96.9650 | Exploration: 0.061113 | Step: 193 | LR: 0.00150000\n",
      "| Reward: -1067 | Episode: 1274 | Qmax: 96.9378 | Exploration: 0.061052 | Step: 141 | LR: 0.00150000\n",
      "| Reward: -864 | Episode: 1275 | Qmax: 96.9852 | Exploration: 0.060991 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1079 | Episode: 1276 | Qmax: 97.3577 | Exploration: 0.060930 | Step: 288 | LR: 0.00150000\n",
      "| Reward: -1452 | Episode: 1277 | Qmax: 97.2532 | Exploration: 0.060869 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -1091 | Episode: 1278 | Qmax: 97.1831 | Exploration: 0.060808 | Step: 201 | LR: 0.00150000\n",
      "| Reward: -2478 | Episode: 1279 | Qmax: 96.6567 | Exploration: 0.060747 | Step: 247 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -1503 | Episode: 1280 | Qmax: 97.6570 | Exploration: 0.060686 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -864 | Episode: 1281 | Qmax: 97.4256 | Exploration: 0.060626 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1407 | Episode: 1282 | Qmax: 97.1445 | Exploration: 0.060565 | Step: 175 | LR: 0.00150000\n",
      "| Reward: -1323 | Episode: 1283 | Qmax: 96.8531 | Exploration: 0.060505 | Step: 271 | LR: 0.00150000\n",
      "| Reward: -1464 | Episode: 1284 | Qmax: 97.3700 | Exploration: 0.060444 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -1105 | Episode: 1285 | Qmax: 97.5908 | Exploration: 0.060384 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1245 | Episode: 1286 | Qmax: 96.7722 | Exploration: 0.060323 | Step: 220 | LR: 0.00150000\n",
      "| Reward: -990 | Episode: 1287 | Qmax: 97.6211 | Exploration: 0.060263 | Step: 253 | LR: 0.00150000\n",
      "| Reward: -965 | Episode: 1288 | Qmax: 97.7214 | Exploration: 0.060203 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -810 | Episode: 1289 | Qmax: 97.5281 | Exploration: 0.060142 | Step: 217 | LR: 0.00150000\n",
      "| Reward: -1021 | Episode: 1290 | Qmax: 98.1158 | Exploration: 0.060082 | Step: 158 | LR: 0.00150000\n",
      "| Reward: -713 | Episode: 1291 | Qmax: 97.9629 | Exploration: 0.060022 | Step: 147 | LR: 0.00150000\n",
      "| Reward: -972 | Episode: 1292 | Qmax: 97.3194 | Exploration: 0.059962 | Step: 181 | LR: 0.00150000\n",
      "| Reward: -1150 | Episode: 1293 | Qmax: 97.3556 | Exploration: 0.059902 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -1301 | Episode: 1294 | Qmax: 97.5256 | Exploration: 0.059842 | Step: 222 | LR: 0.00150000\n",
      "| Reward: -675 | Episode: 1295 | Qmax: 97.5008 | Exploration: 0.059783 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -1039 | Episode: 1296 | Qmax: 97.4484 | Exploration: 0.059723 | Step: 266 | LR: 0.00150000\n",
      "| Reward: -1352 | Episode: 1297 | Qmax: 97.5938 | Exploration: 0.059663 | Step: 228 | LR: 0.00150000\n",
      "| Reward: -826 | Episode: 1298 | Qmax: 96.7797 | Exploration: 0.059603 | Step: 161 | LR: 0.00150000\n",
      "| Reward: -1358 | Episode: 1299 | Qmax: 97.0441 | Exploration: 0.059544 | Step: 198 | LR: 0.00150000\n",
      "DDQN Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Reward: -1411 | Episode: 1300 | Qmax: 97.4353 | Exploration: 0.059484 | Step: 278 | LR: 0.00150000\n",
      "| Reward: -1014 | Episode: 1301 | Qmax: 97.4601 | Exploration: 0.059425 | Step: 223 | LR: 0.00150000\n",
      "| Reward: -772 | Episode: 1302 | Qmax: 97.9774 | Exploration: 0.059365 | Step: 161 | LR: 0.00150000\n",
      "| Reward: -858 | Episode: 1303 | Qmax: 97.8972 | Exploration: 0.059306 | Step: 166 | LR: 0.00150000\n",
      "| Reward: -815 | Episode: 1304 | Qmax: 97.5308 | Exploration: 0.059247 | Step: 168 | LR: 0.00150000\n",
      "| Reward: -1040 | Episode: 1305 | Qmax: 97.4720 | Exploration: 0.059187 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -1058 | Episode: 1306 | Qmax: 97.1680 | Exploration: 0.059128 | Step: 195 | LR: 0.00150000\n",
      "| Reward: -932 | Episode: 1307 | Qmax: 98.1309 | Exploration: 0.059069 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -761 | Episode: 1308 | Qmax: 97.9888 | Exploration: 0.059010 | Step: 141 | LR: 0.00150000\n",
      "| Reward: -951 | Episode: 1309 | Qmax: 97.2569 | Exploration: 0.058951 | Step: 277 | LR: 0.00150000\n",
      "| Reward: -1000 | Episode: 1310 | Qmax: 97.4352 | Exploration: 0.058892 | Step: 218 | LR: 0.00150000\n",
      "| Reward: -1491 | Episode: 1311 | Qmax: 98.1254 | Exploration: 0.058833 | Step: 214 | LR: 0.00150000\n",
      "| Reward: -1234 | Episode: 1312 | Qmax: 97.6290 | Exploration: 0.058774 | Step: 164 | LR: 0.00150000\n",
      "| Reward: -1584 | Episode: 1313 | Qmax: 97.8624 | Exploration: 0.058716 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -1025 | Episode: 1314 | Qmax: 97.0208 | Exploration: 0.058657 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -1138 | Episode: 1315 | Qmax: 98.0867 | Exploration: 0.058598 | Step: 203 | LR: 0.00150000\n",
      "| Reward: -1281 | Episode: 1316 | Qmax: 97.2568 | Exploration: 0.058540 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -878 | Episode: 1317 | Qmax: 97.6428 | Exploration: 0.058481 | Step: 213 | LR: 0.00150000\n",
      "| Reward: -1269 | Episode: 1318 | Qmax: 97.3900 | Exploration: 0.058423 | Step: 208 | LR: 0.00150000\n",
      "| Reward: -1117 | Episode: 1319 | Qmax: 97.7267 | Exploration: 0.058364 | Step: 200 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -872 | Episode: 1320 | Qmax: 98.3416 | Exploration: 0.058306 | Step: 171 | LR: 0.00150000\n",
      "| Reward: -804 | Episode: 1321 | Qmax: 97.8764 | Exploration: 0.058247 | Step: 148 | LR: 0.00150000\n",
      "| Reward: -1054 | Episode: 1322 | Qmax: 98.0953 | Exploration: 0.058189 | Step: 200 | LR: 0.00150000\n",
      "| Reward: -1086 | Episode: 1323 | Qmax: 97.7840 | Exploration: 0.058131 | Step: 169 | LR: 0.00150000\n",
      "| Reward: -890 | Episode: 1324 | Qmax: 97.4989 | Exploration: 0.058073 | Step: 207 | LR: 0.00150000\n",
      "| Reward: -1257 | Episode: 1325 | Qmax: 97.8149 | Exploration: 0.058015 | Step: 196 | LR: 0.00150000\n",
      "| Reward: -1411 | Episode: 1326 | Qmax: 98.5034 | Exploration: 0.057957 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -884 | Episode: 1327 | Qmax: 98.4826 | Exploration: 0.057899 | Step: 138 | LR: 0.00150000\n",
      "| Reward: -1212 | Episode: 1328 | Qmax: 98.0343 | Exploration: 0.057841 | Step: 205 | LR: 0.00150000\n",
      "| Reward: -930 | Episode: 1329 | Qmax: 98.2229 | Exploration: 0.057783 | Step: 166 | LR: 0.00150000\n",
      "| Reward: -1072 | Episode: 1330 | Qmax: 97.9478 | Exploration: 0.057725 | Step: 281 | LR: 0.00150000\n",
      "| Reward: -794 | Episode: 1331 | Qmax: 97.7535 | Exploration: 0.057668 | Step: 174 | LR: 0.00150000\n",
      "| Reward: -1021 | Episode: 1332 | Qmax: 98.2758 | Exploration: 0.057610 | Step: 167 | LR: 0.00150000\n",
      "| Reward: -888 | Episode: 1333 | Qmax: 97.4862 | Exploration: 0.057552 | Step: 124 | LR: 0.00150000\n",
      "| Reward: -999 | Episode: 1334 | Qmax: 97.9966 | Exploration: 0.057495 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1060 | Episode: 1335 | Qmax: 97.7922 | Exploration: 0.057437 | Step: 143 | LR: 0.00150000\n",
      "| Reward: -1708 | Episode: 1336 | Qmax: 98.4818 | Exploration: 0.057380 | Step: 215 | LR: 0.00150000\n",
      "| Reward: -963 | Episode: 1337 | Qmax: 97.5174 | Exploration: 0.057322 | Step: 235 | LR: 0.00150000\n",
      "| Reward: -1312 | Episode: 1338 | Qmax: 97.6333 | Exploration: 0.057265 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1218 | Episode: 1339 | Qmax: 97.5908 | Exploration: 0.057208 | Step: 175 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -2092 | Episode: 1340 | Qmax: 97.8790 | Exploration: 0.057151 | Step: 248 | LR: 0.00150000\n",
      "| Reward: -1031 | Episode: 1341 | Qmax: 97.3086 | Exploration: 0.057094 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -829 | Episode: 1342 | Qmax: 97.1932 | Exploration: 0.057036 | Step: 155 | LR: 0.00150000\n",
      "| Reward: -754 | Episode: 1343 | Qmax: 97.5766 | Exploration: 0.056979 | Step: 152 | LR: 0.00150000\n",
      "| Reward: -1037 | Episode: 1344 | Qmax: 97.6813 | Exploration: 0.056922 | Step: 165 | LR: 0.00150000\n",
      "| Reward: -787 | Episode: 1345 | Qmax: 97.0772 | Exploration: 0.056865 | Step: 176 | LR: 0.00150000\n",
      "| Reward: -779 | Episode: 1346 | Qmax: 97.8816 | Exploration: 0.056809 | Step: 150 | LR: 0.00150000\n",
      "| Reward: -1258 | Episode: 1347 | Qmax: 97.4494 | Exploration: 0.056752 | Step: 197 | LR: 0.00150000\n",
      "| Reward: -1652 | Episode: 1348 | Qmax: 96.6983 | Exploration: 0.056695 | Step: 186 | LR: 0.00150000\n",
      "| Reward: -793 | Episode: 1349 | Qmax: 97.0322 | Exploration: 0.056638 | Step: 173 | LR: 0.00150000\n",
      "| Reward: -749 | Episode: 1350 | Qmax: 96.9964 | Exploration: 0.056582 | Step: 165 | LR: 0.00150000\n",
      "| Reward: -1327 | Episode: 1351 | Qmax: 96.4605 | Exploration: 0.056525 | Step: 239 | LR: 0.00150000\n",
      "| Reward: -1253 | Episode: 1352 | Qmax: 97.0498 | Exploration: 0.056469 | Step: 210 | LR: 0.00150000\n",
      "| Reward: -1342 | Episode: 1353 | Qmax: 97.1766 | Exploration: 0.056412 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1043 | Episode: 1354 | Qmax: 96.8155 | Exploration: 0.056356 | Step: 153 | LR: 0.00150000\n",
      "| Reward: -1198 | Episode: 1355 | Qmax: 97.2483 | Exploration: 0.056299 | Step: 164 | LR: 0.00150000\n",
      "| Reward: -1430 | Episode: 1356 | Qmax: 97.0750 | Exploration: 0.056243 | Step: 180 | LR: 0.00150000\n",
      "| Reward: -1090 | Episode: 1357 | Qmax: 96.8029 | Exploration: 0.056187 | Step: 245 | LR: 0.00150000\n",
      "| Reward: -1308 | Episode: 1358 | Qmax: 97.0604 | Exploration: 0.056131 | Step: 184 | LR: 0.00150000\n",
      "| Reward: -909 | Episode: 1359 | Qmax: 96.7633 | Exploration: 0.056075 | Step: 181 | LR: 0.00150000\n",
      "DDQN Saved\n",
      "| Reward: -827 | Episode: 1360 | Qmax: 97.2806 | Exploration: 0.056018 | Step: 216 | LR: 0.00150000\n",
      "| Reward: -702 | Episode: 1361 | Qmax: 96.4162 | Exploration: 0.055962 | Step: 181 | LR: 0.00150000\n",
      "| Reward: -887 | Episode: 1362 | Qmax: 97.4121 | Exploration: 0.055906 | Step: 177 | LR: 0.00150000\n",
      "| Reward: -907 | Episode: 1363 | Qmax: 96.6815 | Exploration: 0.055851 | Step: 152 | LR: 0.00150000\n",
      "| Reward: -1203 | Episode: 1364 | Qmax: 96.4946 | Exploration: 0.055795 | Step: 259 | LR: 0.00150000\n",
      "| Reward: -781 | Episode: 1365 | Qmax: 97.1734 | Exploration: 0.055739 | Step: 188 | LR: 0.00150000\n",
      "| Reward: -1199 | Episode: 1366 | Qmax: 96.4482 | Exploration: 0.055683 | Step: 183 | LR: 0.00150000\n",
      "| Reward: -802 | Episode: 1367 | Qmax: 97.1125 | Exploration: 0.055627 | Step: 173 | LR: 0.00150000\n",
      "| Reward: -801 | Episode: 1368 | Qmax: 96.6139 | Exploration: 0.055572 | Step: 190 | LR: 0.00150000\n",
      "| Reward: -1614 | Episode: 1369 | Qmax: 96.4429 | Exploration: 0.055516 | Step: 238 | LR: 0.00150000\n",
      "| Reward: -1309 | Episode: 1370 | Qmax: 96.4055 | Exploration: 0.055461 | Step: 185 | LR: 0.00150000\n",
      "| Reward: -1088 | Episode: 1371 | Qmax: 96.8217 | Exploration: 0.055405 | Step: 252 | LR: 0.00150000\n",
      "| Reward: -675 | Episode: 1372 | Qmax: 97.0515 | Exploration: 0.055350 | Step: 163 | LR: 0.00150000\n",
      "| Reward: -1130 | Episode: 1373 | Qmax: 96.8668 | Exploration: 0.055295 | Step: 159 | LR: 0.00150000\n",
      "| Reward: -676 | Episode: 1374 | Qmax: 96.6841 | Exploration: 0.055239 | Step: 164 | LR: 0.00150000\n",
      "| Reward: -875 | Episode: 1375 | Qmax: 96.4176 | Exploration: 0.055184 | Step: 165 | LR: 0.00150000\n",
      "| Reward: -923 | Episode: 1376 | Qmax: 96.8613 | Exploration: 0.055129 | Step: 150 | LR: 0.00150000\n",
      "| Reward: -655 | Episode: 1377 | Qmax: 96.8241 | Exploration: 0.055074 | Step: 134 | LR: 0.00150000\n",
      "| Reward: -1163 | Episode: 1378 | Qmax: 96.5034 | Exploration: 0.055019 | Step: 237 | LR: 0.00150000\n"
     ]
    }
   ],
   "source": [
    "config=tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "       \n",
    "    state_dim = 3\n",
    "    action_dim = 5\n",
    "    \n",
    "    if RESTORE:\n",
    "        Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR, DEVICE)\n",
    "        Qnet.saver.restore(sess, RESTORE_PATH)\n",
    "        train(sess, env, Qnet, prod_planner)\n",
    "        \n",
    "    else:\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "        env.seed(RANDOM_SEED)\n",
    "    \n",
    "        Qnet = QNet(sess, state_dim, action_dim, LEARNING_RATE, TAU, MINIBATCH_SIZE, SAVE_DIR, DEVICE)\n",
    "\n",
    "        train(sess, env, Qnet, prod_planner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(prod_planner.opt_rabin) == 1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(env.s,(10,10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(env.s,(10,10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns,r,_,_ = env.step(1)\n",
    "print np.unravel_index(ns,(10,10,5)),r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_planner.get_global_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.last_ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.last_dynamic_coord_dict[(2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.coord_dict[(2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.dynamic_coord_dict[(2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.possible_states(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[env.rabin.graph[str(1)][str(0)][k][\"label\"] for k in range(len(env.rabin.graph[str(1)][str(0)]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.check_ap(\"C\", u' !A&!T&C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.graph[\"0\"][\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env._calculate_transition_prob((4, 3, 1), [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(221,(10,10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = (4,3,1)\n",
    "delta=[0,1]\n",
    "delta_list = [[-1, 0], [1, 0], [0, -1], [0, 1], [0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_position_candidates = [np.array(current[:2]) + np.array(delta)]\n",
    "new_position_candidates += [np.array(current[:2]) + np.array(i) for i in delta_list if i != delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_positions = [env._limit_coordinates(i).astype(int) for i in new_position_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_rabin_state = [env.rabin.next_state(current, tuple(i)) for i in new_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.next_state((4,3,1),(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.coord_dict[(2,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.next_state((4,3,1),[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rabin.deadlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(prod_planner.opt_rabin) == 8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CurrentWorld(LTL.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_planner = Prod_Planning(env, LTL.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_planner.update_wfts_ap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.dynamic_coord_dict[(5,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.last_dynamic_coord_dict[(5,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_planner.region_list[np.ravel_multi_index((5,5),(10,10))].ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.last_ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
